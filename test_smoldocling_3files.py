#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ SmolDocling –Ω–∞ 3 PDF —Ñ–∞–π–ª–∞—Ö —Ä–∞–∑–ª–∏—á–Ω–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
"""
import os
import sys
import json
import time
import base64
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime
from PIL import Image
import io

try:
    import openai
    OPENAI_SDK_AVAILABLE = True
except ImportError:
    OPENAI_SDK_AVAILABLE = False
    print("‚ö†Ô∏è  openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")

try:
    from pdf2image import convert_from_path
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False
    print("‚ö†Ô∏è  pdf2image –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pdf2image")
    print("   –¢–∞–∫–∂–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è: sudo apt-get install poppler-utils")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è SmolDocling (–∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω)
API_TOKEN = "ZDRhOWQ3OTAtZjU4MC00MzA2LThhNTgtMDU1NGFlMjE4OWRl.85a830f9340966e0ad1fd1642884c7c8"
BASE_URL = "https://d63e30af-085a-49f0-9724-8162da967af2.modelrun.inference.cloud.ru/v1"
MODEL_NAME = "model-run-4qigw-disease"  # –ò–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è SmolDocling

# –ü—É—Ç–∏ –∫ —Ç–µ—Å—Ç–æ–≤—ã–º —Ñ–∞–π–ª–∞–º
TEST_FILES = [
    {
        "id": "UNIT_13bd07b0fa0ef660",
        "path": "/root/winners_preprocessor/normalized/UNIT_13bd07b0fa0ef660/files/–ü—Ä–æ—Ç–æ–∫–æ–ª —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∫–∏ –∫–æ—Ç–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –∑–∞—è–≤–æ–∫ ‚Ññ 35 –æ—Ç 19.11.2025.pdf",
        "description": "–°–∫–∞–Ω –∫–Ω–∏–∂–Ω–æ–≥–æ —Ä–∞–∑–≤–æ—Ä–æ—Ç–∞"
    },
    {
        "id": "UNIT_11c6ba8e496155c1",
        "path": "/root/winners_preprocessor/normalized/UNIT_11c6ba8e496155c1/files/tmp1jp9rv31.pdf",
        "description": "–î–æ–∫—É–º–µ–Ω—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞"
    },
    {
        "id": "UNIT_6e44cf32b40a2035",
        "path": "/root/winners_preprocessor/normalized/UNIT_6e44cf32b40a2035/files/–ü—Ä–æ—Ç–æ–∫–æ–ª –¢—Ä—É–±–∞ –ü–≠ 560.pdf",
        "description": "–î–æ–∫—É–º–µ–Ω—Ç –Ω–∏–∑–∫–æ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞"
    }
]

# –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
OUTPUT_DIR = Path("/root/winners_preprocessor/output_smoldocling_3files")
OUTPUT_DIR.mkdir(exist_ok=True)

class SmolDoclingTester:
    def __init__(self):
        if not OPENAI_SDK_AVAILABLE:
            raise ImportError("openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OpenAI –∫–ª–∏–µ–Ω—Ç —Å –Ω–∞—à–∏–º —Ç–æ–∫–µ–Ω–æ–º
        self.client = openai.OpenAI(
            api_key=API_TOKEN,
            base_url=BASE_URL,
            timeout=120.0
        )
        self.model = MODEL_NAME
        self.results = []

    def wait_for_server_ready(self, max_wait_time: int = 300) -> bool:
        """Wait for the inference server to be ready"""
        print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ SmolDocling (–º–∞–∫—Å–∏–º—É–º {max_wait_time} —Å–µ–∫—É–Ω–¥)...")
        
        start_time = time.time()
        while time.time() - start_time < max_wait_time:
            try:
                # Send a wake-up request to the server
                print("    –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø—Ä–æ–±—É–∂–¥–µ–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞...")
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": "Hello, wake up!"}],
                    max_tokens=10,
                    temperature=0.5
                )
                
                if response.choices[0].message.content:
                    print("‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
                    return True
            except Exception as e:
                print(f"    –°–µ—Ä–≤–µ—Ä –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤... ({str(e)[:50]}...)")
                time.sleep(15)  # Wait 15 seconds before retrying
        
        print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ —Å—Ç–∞–ª –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ç–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏")
        return False

    def test_connection(self) -> bool:
        try:
            print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ SmolDocling...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç"}],
                max_tokens=10,
                temperature=0.5
            )
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ! –û—Ç–≤–µ—Ç: {response.choices[0].message.content.strip()}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return False

    def image_to_base64(self, image_path: Path) -> str:
        with open(image_path, "rb") as f:
            return base64.b64encode(f.read()).decode('utf-8')

    def pdf_to_all_pages_images_base64(self, pdf_path: Path, output_dir: Path) -> List[str]:
        if not PDF2IMAGE_AVAILABLE:
            raise ImportError("pdf2image not installed")
        
        try:
            # Convert all pages of PDF to PIL images
            pil_images = convert_from_path(str(pdf_path), dpi=200)
            if not pil_images:
                raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
            
            base64_images = []
            for i, img in enumerate(pil_images):
                # Save image to disk
                image_filename = f"{pdf_path.stem}_page_{i+1}.png"
                image_path = output_dir / image_filename
                img.save(image_path, format='PNG')
                print(f"         üñºÔ∏è  –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {i+1}: {image_path.name}")
                
                # Convert PIL image to base64
                img_byte_arr = io.BytesIO()
                img.save(img_byte_arr, format='PNG')
                base64_img = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')
                base64_images.append(base64_img)
                
            return base64_images
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")
            raise

    def create_structure_prompt(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–æ–∫—É–º–µ–Ω—Ç–∞ —á–µ—Ä–µ–∑ SmolDocling"""
        return """Convert this page to docling with focus on extracting procurement protocol information.
Key fields to extract:
- Procedure number
- Lot number
- Protocol date
- Winner name
- Winner INN/KPP
- Contract price
- Currency
- Procurement subject
- Customer
- Organizer
- Commission members
- Participants list with applications"""

    def create_metadata_prompt(self) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π"""
        return """Based on the extracted document structure, please provide the following information in JSON format:
{
  "procedure_number": "–Ω–æ–º–µ—Ä –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –∑–∞–∫—É–ø–∫–∏",
  "lot_number": "–Ω–æ–º–µ—Ä –ª–æ—Ç–∞",
  "protocol_date": "–¥–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞",
  "winner": "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è",
  "inn": "–ò–ù–ù –ø–æ–±–µ–¥–∏—Ç–µ–ª—è",
  "kpp": "–ö–ü–ü –ø–æ–±–µ–¥–∏—Ç–µ–ª—è",
  "price": "—Ü–µ–Ω–∞ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–∞",
  "currency": "–≤–∞–ª—é—Ç–∞",
  "subject": "–ø—Ä–µ–¥–º–µ—Ç –∑–∞–∫—É–ø–∫–∏",
  "customer": "–∑–∞–∫–∞–∑—á–∏–∫",
  "organizer": "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä",
  "commission": ["—á–ª–µ–Ω –∫–æ–º–∏—Å—Å–∏–∏ 1", "—á–ª–µ–Ω –∫–æ–º–∏—Å—Å–∏–∏ 2", ...],
  "participants": [
    {
      "application_number": "–Ω–æ–º–µ—Ä –∑–∞—è–≤–∫–∏",
      "name": "–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–∞",
      "price_without_vat": "—Å—É–º–º–∞ –±–µ–∑ –ù–î–°",
      "price_with_vat": "—Å—É–º–º–∞ —Å –ù–î–°",
      "status": "—Å—Ç–∞—Ç—É—Å"
    }
  ]
}"""

    def process_single_page(self, base64_image: str, prompt_text: str) -> Dict[str, Any]:
        """Process a single page/image with SmolDocling"""
        try:
            messages_content = [
                {"type": "text", "text": prompt_text},
                {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64_image}"}}
            ]
            
            print(f"      ‚û°Ô∏è  –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ SmolDocling...")
            response_start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": messages_content}],
                max_tokens=5000,
                temperature=0.0,  # –ë–æ–ª–µ–µ –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
                response_format={"type": "json_object"}  # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º JSON
            )
            response_time = time.time() - response_start_time
            tokens_used = response.usage.total_tokens if response.usage else 0
            
            print(f"      ‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –∑–∞ {response_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"         –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response.choices[0].message.content)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # Parse JSON response
            try:
                output = json.loads(response.choices[0].message.content)
                print(f"      üì¶ –ü–∞—Ä—Å–∏–Ω–≥ JSON...")
                return {
                    "success": True,
                    "data": output,
                    "response_time": response_time,
                    "tokens_used": tokens_used
                }
            except json.JSONDecodeError as e:
                print(f"      ‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
                return {
                    "success": False,
                    "error": f"JSON Decode Error: {e}",
                    "raw_response": response.choices[0].message.content,
                    "response_time": response_time,
                    "tokens_used": tokens_used
                }
                
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {e}")
            return {
                "success": False,
                "error": str(e)
            }

    def process_file(self, file_info: Dict[str, Any], file_index: int) -> Optional[Dict[str, Any]]:
        file_path = Path(file_info["path"])
        file_id = file_info["id"]
        description = file_info["description"]
        
        file_output_dir = OUTPUT_DIR / file_id
        file_output_dir.mkdir(parents=True, exist_ok=True)

        print(f"\n{'='*80}")
        print(f"[{file_index+1}/3] –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {file_path.name}")
        print(f"ID: {file_id}")
        print(f"–û–ø–∏—Å–∞–Ω–∏–µ: {description}")
        print(f"–ü—É—Ç—å: {file_path}")
        print(f"{'='*80}")

        file_start_time = time.time()
        file_tokens_used = 0
        
        file_result = {
            "file_id": file_id,
            "file_name": file_path.name,
            "description": description,
            "path": str(file_path),
            "processing_time": 0.0,
            "tokens_used": 0,
            "pages": [],
            "status": "failed",
            "error": None
        }

        try:
            if not file_path.exists():
                raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {file_path}")
            
            print(f"   üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF: {file_path.name}")
            print(f"      –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_path.stat().st_size / 1024:.1f} KB")
            if not PDF2IMAGE_AVAILABLE:
                raise ImportError("pdf2image not installed")
            
            print(f"      –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")
            base64_images = self.pdf_to_all_pages_images_base64(file_path, file_output_dir)
            print(f"      –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(base64_images)}")
            
            # Process each page
            page_results = []
            for i, base64_image in enumerate(base64_images):
                page_num = i + 1
                print(f"      üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num} –∏–∑ {len(base64_images)}")
                prompt_text = self.create_structure_prompt()
                page_result = self.process_single_page(base64_image, prompt_text)
                page_results.append(page_result)
                if page_result.get("success"):
                    file_tokens_used += page_result.get("tokens_used", 0)
            
            file_result["tokens_used"] = file_tokens_used
            
            # Save individual page results for reference
            page_results_path = file_output_dir / f"{file_path.stem}_page_results.json"
            with open(page_results_path, "w", encoding="utf-8") as f:
                json.dump(page_results, f, indent=2, ensure_ascii=False)
            print(f"      üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {page_results_path}")
            
            # Save raw results
            raw_results_path = file_output_dir / f"{file_path.stem}_raw_results.json"
            with open(raw_results_path, "w", encoding="utf-8") as f:
                json.dump(page_results, f, indent=2, ensure_ascii=False)
            print(f"      üíæ –°—ã—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {raw_results_path}")
            
            file_result["pages"] = page_results
            file_result["status"] = "success"
            
        except Exception as e:
            print(f"      ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            file_result["error"] = str(e)
        
        file_result["processing_time"] = time.time() - file_start_time
        self.results.append(file_result)
        
        return file_result

    def generate_markdown_report(self):
        """Generate a markdown report of the results"""
        print(f"\nüìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞...")
        report_path = OUTPUT_DIR / f"smoldocling_test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(f"# –û—Ç—á–µ—Ç –æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ SmolDocling –Ω–∞ 3 PDF —Ñ–∞–π–ª–∞—Ö\n\n")
            f.write(f"**–î–∞—Ç–∞ –æ—Ç—á–µ—Ç–∞:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
            f.write(f"- –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: 3\n")
            f.write(f"- –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {sum(1 for r in self.results if r['status'] == 'success')}\n")
            f.write(f"- –û–±—â–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {sum(r['processing_time'] for r in self.results):.2f} —Å–µ–∫—É–Ω–¥\n")
            f.write(f"- –í—Å–µ–≥–æ —Ç–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {sum(r['tokens_used'] for r in self.results)}\n\n")

            f.write(f"## –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ñ–∞–π–ª–∞–º\n\n")
            for file_result in self.results:
                f.write(f"### –§–∞–π–ª: `{file_result['file_name']}`\n")
                f.write(f"- ID: `{file_result['file_id']}`\n")
                f.write(f"- –û–ø–∏—Å–∞–Ω–∏–µ: {file_result['description']}\n")
                f.write(f"- –°—Ç–∞—Ç—É—Å: **{file_result['status'].upper()}**\n")
                f.write(f"- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {file_result['processing_time']:.2f} —Å–µ–∫—É–Ω–¥\n")
                f.write(f"- –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {file_result['tokens_used']}\n")
                if file_result['error']:
                    f.write(f"- –û—à–∏–±–∫–∞: `{file_result['error']}`\n")
                f.write(f"\n")

                if file_result['status'] == 'success':
                    f.write(f"#### –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º\n")
                    for i, page_result in enumerate(file_result['pages']):
                        f.write(f"**–°—Ç—Ä–∞–Ω–∏—Ü–∞ {i+1}:** ")
                        if page_result.get('success'):
                            f.write(f"‚úÖ –£—Å–ø–µ—à–Ω–æ ({page_result.get('response_time', 0):.2f} —Å–µ–∫, {page_result.get('tokens_used', 0)} —Ç–æ–∫–µ–Ω–æ–≤)\n")
                            # Show sample of extracted data
                            data = page_result.get('data', {})
                            if data:
                                f.write(f"```json\n")
                                # Limit output to first few keys for brevity
                                sample_data = {k: v for k, v in list(data.items())[:3]}
                                f.write(json.dumps(sample_data, ensure_ascii=False, indent=2))
                                f.write(f"\n```\n")
                        else:
                            f.write(f"‚ùå –û—à–∏–±–∫–∞: {page_result.get('error', 'Unknown error')}\n")
                        f.write(f"\n")
                f.write(f"---\n\n")
        
        print(f"‚úÖ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")

    def run(self):
        print(f"\n{'='*80}")
        print(f"–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï INTEGR–ê–¶–ò–ò SMOLDOCLING –ù–ê 3 PDF –§–ê–ô–õ–ê–•")
        print(f"{'='*80}")

        # Wait for server to be ready
        if not self.wait_for_server_ready():
            print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
            return

        if not self.test_connection():
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å.")
            return

        print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {len(TEST_FILES)}")
        print(f"üéØ –ë—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(TEST_FILES)} —Ñ–∞–π–ª–æ–≤")

        for i, file_info in enumerate(TEST_FILES):
            self.process_file(file_info, i)
        
        self.generate_markdown_report()

        print(f"\n{'='*80}")
        print(f"‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"{'='*80}")

if __name__ == "__main__":
    tester = SmolDoclingTester()
    tester.run()
