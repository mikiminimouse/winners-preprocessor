#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Qwen3-VL-8B –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç API key –¥–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è OCR.
"""
import os
import sys
import json
import time
import base64
from pathlib import Path
from typing import Dict, Any, Optional

# –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π OpenAI –∫–ª–∏–µ–Ω—Ç
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("‚ö†Ô∏è  openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")
    sys.exit(1)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
API_KEY = "ZDRhOWQ3OTAtZjU4MC00MzA2LThhNTgtMDU1NGFlMjE4OWRl.85a830f9340966e0ad1fd1642884c7c8"
BASE_URL = "https://92ad3238-81c6-4396-a02a-fb9cef99bce3.modelrun.inference.cloud.ru/v1"
MODEL_NAME = "qwen3-vl-8b-instruct"

# –ü—É—Ç–∏
NORMALIZED_DIR = Path("/root/winners_preprocessor/normalized")
OUTPUT_DIR = Path("/root/winners_preprocessor/output_qwen3_vision")
OUTPUT_DIR.mkdir(exist_ok=True)


def image_to_base64(image_path: Path) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64."""
    with open(image_path, "rb") as f:
        image_data = f.read()
    return base64.b64encode(image_data).decode('utf-8')


def create_docling_ocr_prompt() -> str:
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ Docling OCR."""
    return """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∏–∑–≤–ª–µ–∫–∏ –∏–∑ –Ω–µ–≥–æ –≤—Å—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –≤–∫–ª—é—á–∞—è —Ç–µ–∫—Å—Ç, —Ç–∞–±–ª–∏—Ü—ã, —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ.

–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Ç–æ–º—É, –∫–∞–∫ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç Docling OCR pipeline.

–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–≥–æ–≥–æ JSON —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ Docling):

{
  "text": "–ø–æ–ª–Ω—ã–π –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã (–∑–∞–≥–æ–ª–æ–≤–∫–∏, –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, —Å–ø–∏—Å–∫–∏)",
  "tables": [
    {
      "type": "table",
      "rows": [
        ["–ó–∞–≥–æ–ª–æ–≤–æ–∫ –∫–æ–ª–æ–Ω–∫–∏ 1", "–ó–∞–≥–æ–ª–æ–≤–æ–∫ –∫–æ–ª–æ–Ω–∫–∏ 2"],
        ["–î–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ 1 –∫–æ–ª–æ–Ω–∫–∞ 1", "–î–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ 1 –∫–æ–ª–æ–Ω–∫–∞ 2"],
        ["–î–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ 2 –∫–æ–ª–æ–Ω–∫–∞ 1", "–î–∞–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ 2 –∫–æ–ª–æ–Ω–∫–∞ 2"]
      ],
      "bbox": [x1, y1, x2, y2]
    }
  ],
  "layout": {
    "pages": [
      {
        "page_num": 1,
        "blocks": [
          {
            "type": "title" | "heading" | "paragraph" | "list" | "table",
            "text": "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –±–ª–æ–∫–∞",
            "bbox": [x1, y1, x2, y2],
            "level": 1
          }
        ]
      }
    ],
    "sections": [
      {
        "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —Å–µ–∫—Ü–∏–∏",
        "level": 1,
        "content": "—Ç–µ–∫—Å—Ç —Å–µ–∫—Ü–∏–∏"
      }
    ],
    "blocks": [
      {
        "type": "text" | "title" | "table",
        "text": "—Å–æ–¥–µ—Ä–∂–∏–º–æ–µ",
        "bbox": [x1, y1, x2, y2]
      }
    ]
  },
  "metadata": {
    "title": "–∑–∞–≥–æ–ª–æ–≤–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
    "author": "–∞–≤—Ç–æ—Ä (–µ—Å–ª–∏ –µ—Å—Ç—å)",
    "date": "–¥–∞—Ç–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å)",
    "pages_count": 1
  }
}

–í–ê–ñ–ù–û:
- –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–π JSON, –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–æ –∏–ª–∏ –ø–æ—Å–ª–µ
- –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞ (–∑–∞–≥–æ–ª–æ–≤–∫–∏ —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π, –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã, —Å–ø–∏—Å–∫–∏)
- –ò–∑–≤–ª–µ–∫–∏ –í–°–ï —Ç–∞–±–ª–∏—Ü—ã —Å –∏—Ö –¥–∞–Ω–Ω—ã–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å—Ç—Ä–æ–∫ –∏ –∫–æ–ª–æ–Ω–æ–∫
- –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã bbox –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ [x1, y1, x2, y2] –≤ –ø–∏–∫—Å–µ–ª—è—Ö
- –¢–µ–∫—Å—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
- –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤ []
- –ï—Å–ª–∏ –±–ª–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω, –≤–µ—Ä–Ω–∏ –ø—É—Å—Ç–æ–π –æ–±—ä–µ–∫—Ç {}"""


def test_connection(client: OpenAI) -> bool:
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ API."""
    print("üîç –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è...")
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {"role": "system", "content": "–í—ã –æ—á–µ–Ω—å –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç."},
                {"role": "user", "content": "–°–∫–∞–∂–∏ '–ü—Ä–∏–≤–µ—Ç' –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º"}
            ],
            max_tokens=10,
            temperature=0.5
        )
        
        if response.choices and response.choices[0].message.content:
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ! –û—Ç–≤–µ—Ç: {response.choices[0].message.content}")
            return True
        else:
            print("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API")
            return False
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
        return False


def process_image_ocr(client: OpenAI, image_path: Path) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ Qwen3-VL-8B –¥–ª—è OCR –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–∞–∑–º–µ—Ç–∫–∏."""
    print(f"\nüì∑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {image_path.name}")
    print(f"   –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {image_path.stat().st_size / 1024:.1f} KB")
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ base64
    print("   –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64...")
    base64_image = image_to_base64(image_path)
    print(f"   Base64 –¥–ª–∏–Ω–∞: {len(base64_image)} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –°–æ–∑–¥–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI API
    # –§–æ—Ä–º–∞—Ç: data:image/jpeg;base64,{base64_image}
    image_data_url = f"data:image/jpeg;base64,{base64_image}"
    
    messages = [
        {
            "role": "system",
            "content": "–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—é —Ä–∞–∑–º–µ—Ç–∫–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –∏–∑–≤–ª–µ—á—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ Docling OCR pipeline."
        },
        {
            "role": "user",
            "content": [
                {"type": "text", "text": create_docling_ocr_prompt()},
                {
                    "type": "image_url",
                    "image_url": {
                        "url": image_data_url
                    }
                }
            ]
        }
    ]
    
    # –í—ã–∑–æ–≤ API
    print("   –û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ Qwen3-VL-8B...")
    start_time = time.time()
    
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=8000,
            temperature=0.1,  # –ù–∏–∑–∫–∞—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            top_p=0.95,
            presence_penalty=0,
            timeout=120.0  # –¢–∞–π–º–∞—É—Ç 2 –º–∏–Ω—É—Ç—ã –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        )
        
        response_time = time.time() - start_time
        
        if not response.choices or not response.choices[0].message.content:
            raise ValueError("–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
        
        content = response.choices[0].message.content
        print(f"   ‚úÖ –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –∑–∞ {response_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ü–∞—Ä—Å–∏–º JSON –∏–∑ –æ—Ç–≤–µ—Ç–∞
        print("   –ü–∞—Ä—Å–∏–Ω–≥ JSON...")
        docling_result = parse_docling_response(content)
        
        return {
            "success": True,
            "result": docling_result,
            "raw_response": content,
            "response_time": response_time,
            "tokens_used": getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') else 0
        }
        
    except Exception as e:
        error_msg = str(e)
        print(f"   ‚ùå –û—à–∏–±–∫–∞: {error_msg}")
        return {
            "success": False,
            "error": error_msg,
            "response_time": time.time() - start_time
        }


def parse_docling_response(content: str) -> Dict[str, Any]:
    """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç Docling."""
    import re
    
    content = content.strip()
    
    # –£–¥–∞–ª—è–µ–º markdown code blocks –µ—Å–ª–∏ –µ—Å—Ç—å
    if content.startswith("```"):
        lines = content.split("\n")
        if len(lines) > 2:
            # –£–¥–∞–ª—è–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É —Å ``` –∏ –ø–æ—Å–ª–µ–¥–Ω—é—é —Å ```
            content = "\n".join(lines[1:-1])
    
    # –£–¥–∞–ª—è–µ–º markdown code blocks —Å —è–∑—ã–∫–æ–º
    content = re.sub(r'^```json\s*', '', content, flags=re.MULTILINE)
    content = re.sub(r'^```\s*', '', content, flags=re.MULTILINE)
    content = re.sub(r'\s*```$', '', content, flags=re.MULTILINE)
    content = content.strip()
    
    try:
        result = json.loads(content)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –ø–æ–¥ Docling —Ñ–æ—Ä–º–∞—Ç
        normalized = {
            "text": result.get("text", ""),
            "tables": result.get("tables", []),
            "layout": result.get("layout", {
                "pages": [],
                "sections": [],
                "blocks": []
            }),
            "metadata": result.get("metadata", {})
        }
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
        if not isinstance(normalized["tables"], list):
            normalized["tables"] = []
        if not isinstance(normalized["layout"], dict):
            normalized["layout"] = {"pages": [], "sections": [], "blocks": []}
        if not isinstance(normalized["metadata"], dict):
            normalized["metadata"] = {}
        
        return normalized
        
    except json.JSONDecodeError as e:
        print(f"   ‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")
        print(f"   –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞: {content[:500]}")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
        return {
            "text": "",
            "tables": [],
            "layout": {"pages": [], "sections": [], "blocks": []},
            "metadata": {},
            "parse_error": str(e),
            "raw_content": content[:2000]
        }


def save_results(image_path: Path, result: Dict[str, Any], output_data: Dict[str, Any]):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ Docling."""
    file_base = image_path.stem
    output_file = OUTPUT_DIR / f"{file_base}_docling_result.json"
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Docling
    docling_format = {
        "file": image_path.name,
        "route": "image_ocr",
        "detected_type": "image",
        "needs_ocr": True,
        "status": "processed",
        "processing_method": "qwen3-vl-8b-instruct",
        "text": output_data.get("text", ""),
        "tables": output_data.get("tables", []),
        "metadata": output_data.get("metadata", {}),
        "layout": output_data.get("layout", {
            "pages": [],
            "sections": [],
            "blocks": []
        }),
        "metrics": {
            "processing_times": {
                "ocr": result.get("response_time", 0),
                "total": result.get("response_time", 0)
            },
            "file_stats": {
                "text_length": len(output_data.get("text", "")),
                "tables_extracted": len(output_data.get("tables", [])),
                "pages_count": len(output_data.get("layout", {}).get("pages", []))
            },
            "tokens_used": result.get("tokens_used", 0)
        }
    }
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(docling_format, f, indent=2, ensure_ascii=False)
    
    print(f"   üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {output_file}")
    return output_file


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    print("=" * 70)
    print("–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï QWEN3-VL-8B: –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï –†–ê–ó–ú–ï–¢–ö–ò –î–û–ö–£–ú–ï–ù–¢–û–í")
    print("=" * 70)
    print()
    
    print(f"üîë API Key: {API_KEY[:30]}...")
    print(f"üåê Base URL: {BASE_URL}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {MODEL_NAME}")
    print()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI
    try:
        print("üîå –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–∞ OpenAI...")
        client = OpenAI(
            api_key=API_KEY,
            base_url=BASE_URL
        )
        print("‚úÖ –ö–ª–∏–µ–Ω—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–ª–∏–µ–Ω—Ç–∞: {e}")
        sys.exit(1)
    
    # –¢–µ—Å—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    if not test_connection(client):
        print("\n‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ API. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ:")
        print("   1. –ü—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å API key")
        print("   2. –î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å endpoint")
        print("   3. –ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∫–ª—é—á–∞")
        sys.exit(1)
    
    # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    print("\n" + "=" * 70)
    print("–ü–û–ò–°–ö –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ô –î–õ–Ø –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 70)
    
    # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ normalized
    image_files = []
    for unit_dir in NORMALIZED_DIR.glob("UNIT_*"):
        files_dir = unit_dir / "files"
        if files_dir.exists():
            for img_file in files_dir.glob("*.jpg"):
                image_files.append(img_file)
            for img_file in files_dir.glob("*.jpeg"):
                image_files.append(img_file)
            for img_file in files_dir.glob("*.png"):
                image_files.append(img_file)
    
    if not image_files:
        print("‚ùå –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ normalized/")
        print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ UNIT_03f63c4b3ab3b09e –¥–ª—è —Ç–µ—Å—Ç–∞")
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        test_image = NORMALIZED_DIR / "UNIT_03f63c4b3ab3b09e" / "files" / "–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ_2.jpg"
        if test_image.exists():
            image_files = [test_image]
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image}")
        else:
            sys.exit(1)
    
    print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(image_files)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–∞
    test_image = image_files[0]
    print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {test_image.name}")
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    result = process_image_ocr(client, test_image)
    
    if result["success"]:
        print("\n" + "=" * 70)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
        print("=" * 70)
        
        docling_result = result["result"]
        
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"   –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result['response_time']:.2f} —Å–µ–∫")
        print(f"   –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {result.get('tokens_used', 0)}")
        print(f"   –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(docling_result.get('text', ''))} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –¢–∞–±–ª–∏—Ü –Ω–∞–π–¥–µ–Ω–æ: {len(docling_result.get('tables', []))}")
        print(f"   –°—Ç—Ä–∞–Ω–∏—Ü: {len(docling_result.get('layout', {}).get('pages', []))}")
        print(f"   –ë–ª–æ–∫–æ–≤: {len(docling_result.get('layout', {}).get('blocks', []))}")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        output_file = save_results(test_image, result, docling_result)
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ —Ç–µ–∫—Å—Ç–∞
        text_preview = docling_result.get("text", "")[:500]
        if text_preview:
            print(f"\nüìù –ü—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:")
            print(f"   {text_preview}...")
        
    else:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result.get('error')}")
        sys.exit(1)
    
    print("\n" + "=" * 70)
    print("‚úÖ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    print("=" * 70)


if __name__ == "__main__":
    main()

