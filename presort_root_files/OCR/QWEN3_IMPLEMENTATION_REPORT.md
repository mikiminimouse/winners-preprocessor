# Отчет о реализации тестирования Qwen3-VL-8B для извлечения метаданных

## Выполнено

### 1. Сбор UNIT'ов для тестирования

**Скрипт**: `collect_ocr_units.py`
- Собрано 20 UNIT'ов с `needs_ocr: true` из `normalized/`
- Распределение: 18 PDF (pdf_scan), 1 изображение (image_ocr), 1 смешанный (mixed)
- Список сохранен в `test_ocr_units_list.json`

### 2. Скрипт тестирования с метриками

**Скрипт**: `test_qwen3_ocr_metrics.py`

#### Функциональность:
- ✅ Подключение к Qwen3-VL-8B через API key
- ✅ Обработка изображений (конвертация в base64)
- ✅ Обработка PDF (конвертация страниц в изображения через pdf2image)
- ✅ Извлечение метаданных протоколов закупок
- ✅ Сбор метрик производительности
- ✅ Экстраполяция времени на 100 и 500 UNIT'ов
- ✅ Статистика по извлечению полей

#### Извлекаемые метаданные:
1. номер_процедуры
2. номер_лота
3. дата_протокола
4. победитель
5. ИНН
6. КПП
7. цена_победителя
8. валюта
9. предмет_закупки
10. дата_начала_подачи
11. дата_окончания_подачи
12. дата_проведения
13. заказчик
14. организатор
15. состав_комиссии
16. полный_текст
17. таблицы

### 3. Формат результатов

Результаты сохраняются в `output_qwen3_ocr/`:
- Метаданные для каждого файла: `UNIT_*/filename_metadata.json`
- Итоговый отчет: `ocr_test_report_*.json`

## Как запустить тестирование

### Шаг 1: Установка зависимостей

```bash
pip install evolution-openai pdf2image
sudo apt-get install poppler-utils  # для pdf2image
```

### Шаг 2: Сбор UNIT'ов (уже выполнено)

```bash
python3 collect_ocr_units.py
```

### Шаг 3: Запуск тестирования

```bash
python3 test_qwen3_ocr_metrics.py
```

Скрипт по умолчанию тестирует первые 10 UNIT'ов. Для полного теста измените `test_limit` в коде.

## Ожидаемые метрики

После выполнения тестирования вы получите:

### 1. Производительность
- Среднее время обработки одного файла
- Общее время теста
- Количество успешных/неуспешных запросов
- Использование токенов

### 2. Экстраполяция
- **Оценка для 100 UNIT'ов**: время в минутах и часах
- **Оценка для 500 UNIT'ов**: время в минутах и часах

Расчет основан на формуле:
```
Время_100 = среднее_время_на_файл × 100 / 60 (минуты)
Время_500 = среднее_время_на_файл × 500 / 60 (минуты)
```

### 3. Качество извлечения
- Статистика по каждому полю метаданных
- Процент успешного извлечения
- Поля, требующие улучшения

## Пример отчета

```json
{
  "test_summary": {
    "total_units": 10,
    "successful_units": 9,
    "success_rate_units": "90.0%",
    "total_files": 10,
    "successful_files": 9,
    "success_rate_files": "90.0%"
  },
  "performance_metrics": {
    "avg_response_time_seconds": 15.23,
    "total_time_minutes": 2.54
  },
  "extrapolation": {
    "estimated_100_units_minutes": 25.4,
    "estimated_100_units_hours": 0.42,
    "estimated_500_units_minutes": 127.0,
    "estimated_500_units_hours": 2.12
  },
  "field_extraction_stats": {
    "номер_процедуры": {
      "extracted": 8,
      "total": 9,
      "success_rate": "88.9%"
    },
    ...
  }
}
```

## Важные замечания

### Ограничения текущей реализации:
1. **PDF**: Обрабатывается только первая страница (для полной обработки нужно изменить код)
2. **Тестовый режим**: По умолчанию тестируются первые 10 UNIT'ов
3. **Последовательная обработка**: Файлы обрабатываются последовательно (без параллелизма)

### Для более точных оценок:
1. Увеличьте количество тестируемых UNIT'ов до 20-50
2. Обрабатывайте все страницы PDF (не только первую)
3. Учтите, что реальное время может варьироваться в зависимости от:
   - Размера документов
   - Сложности структуры
   - Загрузки сервера ML inference
   - Сетевых задержек

### Рекомендации по масштабированию:
- Для 100 UNIT'ов: ~25-30 минут (при среднем времени 15 сек/файл)
- Для 500 UNIT'ов: ~2-2.5 часа (при среднем времени 15 сек/файл)
- При параллельной обработке (10 потоков): время сократится в ~5-8 раз

## Следующие шаги

1. **Запустите тестирование** на собранных UNIT'ах
2. **Проанализируйте отчет** для оценки производительности
3. **Проверьте качество извлечения** метаданных
4. **Настройте промпт** при необходимости для улучшения извлечения
5. **Масштабируйте** на полный объем данных

## Файлы проекта

- `collect_ocr_units.py` - сбор UNIT'ов с needs_ocr: true
- `test_qwen3_ocr_metrics.py` - основной скрипт тестирования
- `test_ocr_units_list.json` - список UNIT'ов для тестирования
- `output_qwen3_ocr/` - результаты тестирования
- `OCR_METRICS_README.md` - подробная документация

## Готово к использованию

Все скрипты готовы к запуску. После установки зависимостей можно сразу запускать тестирование и получать метрики производительности для оценки времени обработки 100 и 500 UNIT'ов.

