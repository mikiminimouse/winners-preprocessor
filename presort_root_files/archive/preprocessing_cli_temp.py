class PreprocessingCLI:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π CLI –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è preprocessing."""
    
    def __init__(self):
        self.state_manager = StateManager()
        self.limits = get_limits()
    
    def show_menu(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é."""
        print("\n" + "=" * 50)
        print("=== Winners223 Preprocessing CLI ===")
        print("=" * 50)
        
        print("\n=== –ó–ê–ì–†–£–ó–ö–ê –ò –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø ===")
        print("1. –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª—ã –∏–∑ MongoDB (—Å VPN)")
        print("2. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB")
        
        # print("\n=== –û–ë–†–ê–ë–û–¢–ö–ê (–°–¢–ê–†–ê–Ø –°–ò–°–¢–ï–ú–ê) ===")
        # print("3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ñ–∞–π–ª–∞(–æ–≤)")
        # print("4. –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤(—ã)")
        # print("5. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DOC ‚Üí DOCX")
        # print("6. –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª(—ã)")
        # print("7. –°–æ–∑–¥–∞—Ç—å manifest")
        # print("8. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ PDF –Ω–∞ text_pdf –∏ scan_pdf")
        # print("9. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí HTML/XML")
        # print("10. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω)")
        
        print("\n=== –ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê (PENDING) - –ü–û–®–ê–ì–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===")
        print("3. –®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤")
        print("4. –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
        print("5. –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        print("6. –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units")
        print("7. –®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º")
        print("8. –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (3-7)")
        
        print("\n=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ü–†–û–°–ú–û–¢–† ===")
        print("9. –ü—Ä–æ—Å–º–æ—Ç—Ä pending —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
        print("10. –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (+ mixed units)")
        print("11. –û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units")
        
        print("\n=== MERGE –í READY_DOCLING ===")
        print("12. Merge (DRY RUN)")
        print("13. Merge (–†–ï–ê–õ–¨–ù–´–ô)")
        
        print("\n=== –°–õ–£–ñ–ï–ë–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò ===")
        print("14. –ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
        print("15. –ü—Ä–æ—Å–º–æ—Ç—Ä –º–µ—Ç—Ä–∏–∫")
        print("16. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–∏–º–∏—Ç–æ–≤")
        print("17. –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π")
        print("18. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units")
        print("19. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤")
        
        print("\n0. –í—ã—Ö–æ–¥")
        print("\n" + "-" * 50)
    
    def handle_sync_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB."""
        print("\n=== –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB...")
        remote_client = get_remote_mongo_client()
        if not remote_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ .env:")
            print("    - mongoServer –∏–ª–∏ MONGO_SERVER")
            print("    - readAllUser –∏–ª–∏ MONGO_USER")
            print("    - readAllPassword –∏–ª–∏ MONGO_PASSWORD")
            print("    - sslCertPath –∏–ª–∏ MONGO_SSL_CERT")
            return
        
        remote_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB
        print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB...")
        local_client = get_local_mongo_client()
        if not local_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            print("    - LOCAL_MONGO_SERVER (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: localhost:27017)")
            print("    - MONGO_METADATA_USER")
            print("    - MONGO_METADATA_PASSWORD")
            return
        
        local_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –í—ã–±–æ—Ä –¥–∞—Ç—ã
        print("\n3. –í—ã–±–æ—Ä –¥–∞—Ç—ã –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:")
        print("  1. –í—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
        print("  2. –£–∫–∞–∑–∞—Ç—å –¥–∞—Ç—É –≤—Ä—É—á–Ω—É—é (YYYY-MM-DD)")
        choice = input("  –í—ã–±–µ—Ä–∏—Ç–µ [1-2] –∏–ª–∏ Enter –¥–ª—è –≤—á–µ—Ä–∞—à–Ω–µ–≥–æ –¥–Ω—è: ").strip()
        
        target_date = None
        if choice == "2":
            date_str = input("  –í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É (YYYY-MM-DD): ").strip()
            try:
                target_date = datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                print(f"‚úó –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}")
                return
        else:
            target_date = datetime.utcnow() - timedelta(days=1)
        
        # –õ–∏–º–∏—Ç
        limit_str = input(f"\n4. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        # –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        print(f"\n5. –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
        print(f"   –î–∞—Ç–∞: {target_date.date()}")
        print(f"   –õ–∏–º–∏—Ç: {limit}")
        
        result = sync_protocols_for_date(target_date, limit)
        
        if result.get("status") == "success":
            print("\n‚úì –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            print(f"   –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {result.get('scanned', 0)}")
            print(f"   –í—Å—Ç–∞–≤–ª–µ–Ω–æ: {result.get('inserted', 0)}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {result.get('skipped_existing', 0)}")
            if result.get("errors_count", 0) > 0:
                print(f"   –û—à–∏–±–æ–∫: {result.get('errors_count', 0)}")
        else:
            print(f"\n‚úó –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {result.get('message', 'Unknown error')}")
    
    def handle_download_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB —á–µ—Ä–µ–∑ VPN."""
        print("\n=== –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB (—Å VPN) ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ VPN –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ zakupki.gov.ru —á–µ—Ä–µ–∑ VPN...")
        if not check_zakupki_health():
            print("‚úó zakupki.gov.ru –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç VPN / –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)")
            print("  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ VPN –Ω–∞—Å—Ç—Ä–æ–µ–Ω —á–µ—Ä–µ–∑ route-up-zakupki.sh")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ OpenVPN —Ç—É–Ω–Ω–µ–ª—å –∞–∫—Ç–∏–≤–µ–Ω")
            return
        
        print("‚úì zakupki.gov.ru –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ VPN")
        
        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input(f"\n2. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/units –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        if limit <= 0:
            print("‚úó –õ–∏–º–∏—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return
        
        # –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        print(f"\n3. –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤...")
        print(f"   –õ–∏–º–∏—Ç: {limit} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {INPUT_DIR.absolute()}")
        
        try:
            downloader = ProtocolDownloader(output_dir=INPUT_DIR)
            start_time = time.time()
            result = downloader.process_pending_protocols(limit=limit)
            duration = time.time() - start_time
            
            if result.get("health_ok"):
                print("\n" + "=" * 80)
                print("‚úì –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
                print("=" * 80)
                print(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result.get('processed_ok', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –û—à–∏–±–æ–∫: {result.get('processed_error', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.get('downloaded_files_count', 0)}")
                print(f"  –û—à–∏–±–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {result.get('failed_files_count', 0)}")
                print(f"  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
                if result.get('processed_ok', 0) > 0:
                    avg_time = duration / result.get('processed_ok', 1)
                    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª: {avg_time:.2f} —Å–µ–∫")
            else:
                print("\n‚úó –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å VPN")
                
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_detect_type(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤ (–ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)."""
        print("\n=== –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ (–Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤) ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_DETECT_TYPE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_DETECT_TYPE
        
        print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ input/ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–§–∞–π–ª—ã –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞/—é–Ω–∏—Ç–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ –∏ –Ω–µ —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è.")
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
            from services.router.unit_distribution import distribute_unit_by_types
            from services.router.mongo import save_file_detection_metadata, save_unit_distribution_metadata
            from services.router.config import INPUT_DIR, ensure_directories
            from pathlib import Path
            import time
            from collections import defaultdict
            
            ensure_directories()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit > 0:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = {
                "processed_units": 0,
                "processed_files": 0,
                "mixed_units": 0,
                "duplicates_found": 0,
                "extension_mismatches": 0,
                "errors": 0,
                "file_types": defaultdict(int),
                "target_dirs": defaultdict(int),
                "unprocessed_units": [],  # Units –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏
                "extension_mismatch_details": []  # –î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            }
            
            start_time = time.time()
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units –±–µ–∑ —Ñ–∞–π–ª–æ–≤
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "no_files",
                        "message": "Unit –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–∞–π–ª–æ–≤"
                    })
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª(–æ–≤))...", end=" ", flush=True)
                
                try:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
                    files_list = [{"path": str(f)} for f in files]
                    
                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º unit
                    distribution_result = distribute_unit_by_types(
                        unit_id=unit_id,
                        files=files_list,
                        unit_metadata=None
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    for file_info in distribution_result["files"]:
                        try:
                            save_file_detection_metadata(
                                file_path=file_info["path"],
                                file_info=file_info,
                                unit_id=unit_id,
                                protocol_info=None
                            )
                        except Exception:
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MongoDB
                    
                    try:
                        save_unit_distribution_metadata(unit_id, distribution_result)
                    except Exception:
                        pass
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    stats["processed_units"] += 1
                    stats["processed_files"] += len(distribution_result["files"])
                    
                    if distribution_result["is_mixed"]:
                        stats["mixed_units"] += 1
                    
                    if distribution_result["duplicates_detected"]:
                        stats["duplicates_found"] += 1
                    
                    extension_mismatches = len(distribution_result["distribution_details"].get("extension_mismatches", []))
                    stats["extension_mismatches"] += extension_mismatches
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
                    for file_info in distribution_result["files"]:
                        if not file_info.get("extension_matches_content", True):
                            mismatch_detail = {
                                "unit_id": unit_id,
                                "file_name": file_info.get("original_name", "unknown"),
                                "extension": file_info.get("extension", "unknown"),
                                "expected_type": file_info.get("extension", "").replace(".", ""),
                                "detected_type": file_info.get("detected_type", "unknown"),
                                "mime_type": file_info.get("mime_type", "unknown")
                            }
                            stats["extension_mismatch_details"].append(mismatch_detail)
                    
                    for file_type in distribution_result["file_types"]:
                        stats["file_types"][file_type] += 1
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    target_dir = Path(distribution_result["target_dir"])
                    if "mixed" in str(target_dir):
                        stats["target_dirs"]["mixed"] += 1
                    else:
                        parent_name = target_dir.parent.name if target_dir.parent.name != "detected" else target_dir.name
                        stats["target_dirs"][parent_name] += 1
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    status_icon = "üîÄ" if distribution_result["is_mixed"] else "‚úì"
                    print(f"{status_icon} {', '.join(distribution_result['file_types'])}")
                
                except Exception as e:
                    stats["errors"] += 1
                    error_msg = str(e)
                    print(f"‚úó –û—à–∏–±–∫–∞: {error_msg[:50]}")
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units —Å –æ—à–∏–±–∫–∞–º–∏
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "error",
                        "message": error_msg,
                        "error_type": type(e).__name__
                    })
            
            duration = time.time() - start_time
            
            # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\n{'='*80}")
            print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ unit'–æ–≤: {stats['processed_units']}/{len(unit_dirs)}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {stats['processed_files']}")
            print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
            if stats['processed_units'] > 0:
                print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ unit: {duration/stats['processed_units']:.2f} —Å–µ–∫")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
            for file_type, count in sorted(stats['file_types'].items()):
                print(f"  {file_type}: {count}")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º:")
            for target_dir, count in sorted(stats['target_dirs'].items()):
                print(f"  {target_dir}: {count} unit'–æ–≤")
            
            print(f"\n–û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏:")
            print(f"  Mixed units: {stats['mixed_units']}")
            print(f"  –î—É–±–ª–∏–∫–∞—Ç—ã: {stats['duplicates_found']} unit'–æ–≤")
            print(f"  –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {stats['extension_mismatches']}")
            print(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö units
            unprocessed_count = len(stats.get("unprocessed_units", []))
            if unprocessed_count > 0:
                print(f"\n–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ units: {unprocessed_count}")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º
                by_reason = defaultdict(list)
                for unit in stats["unprocessed_units"]:
                    by_reason[unit["reason"]].append(unit)
                
                for reason, units in sorted(by_reason.items()):
                    reason_name = {
                        "no_files": "–ë–µ–∑ —Ñ–∞–π–ª–æ–≤",
                        "error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
                    }.get(reason, reason)
                    print(f"  {reason_name}: {len(units)} unit'–æ–≤")
                    if len(units) <= 10:
                        for unit_info in units:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                    else:
                        for unit_info in units[:5]:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                        print(f"    ... –∏ –µ—â–µ {len(units) - 5} unit'–æ–≤")
            
            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            if stats.get("extension_mismatch_details"):
                print(f"\n–î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π:")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                mismatch_groups = defaultdict(int)
                for detail in stats["extension_mismatch_details"]:
                    key = f"{detail['extension']} ‚Üí {detail['detected_type']}"
                    mismatch_groups[key] += 1
                
                for mismatch_type, count in sorted(mismatch_groups.items(), key=lambda x: x[1], reverse=True):
                    print(f"  {mismatch_type}: {count}")
            
            print(f"{'='*80}\n")
        
        except ImportError as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}")
            print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_extract_archive(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤."""
        print("\n=== –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_EXTRACT_ARCHIVE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_EXTRACT_ARCHIVE
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/extract_archive")
    
    
    def handle_normalize(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_NORMALIZE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_NORMALIZE
        
        print(f"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/normalize")
    
    def handle_create_manifest(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è manifest."""
        print("\n=== –°–æ–∑–¥–∞–Ω–∏–µ manifest ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_CREATE_MANIFEST}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_CREATE_MANIFEST
        
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ manifest —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/create_manifest")
    
    def show_statistics(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç—Ç–∞–ø–∞–º."""
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç—Ç–∞–ø–∞–º ===")
        stats = self.state_manager.get_statistics()
        
        print(f"\n–≠—Ç–∞–ø 1 (uploaded):     {len(list(INPUT_DIR.iterdir()))} —Ñ–∞–π–ª–æ–≤ –≤ input/")
        print(f"–≠—Ç–∞–ø 2 (detected):     {stats['detected']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"  –ü–æ —Ç–∏–ø–∞–º: {stats['detected']['by_type']}")
        print(f"–≠—Ç–∞–ø 3 (extracted):    {stats['extracted']['count']} —Ñ–∞–π–ª–æ–≤ (–∏–∑ {stats['extracted']['archives_processed']} –∞—Ä—Ö–∏–≤–æ–≤)")
        print(f"–≠—Ç–∞–ø 4 (converted):    {stats['converted']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"–≠—Ç–∞–ø 5 (normalized):   {stats['normalized']['count']} unit'–æ–≤")
        print(f"–≠—Ç–∞–ø 6 (ready):        {stats['ready']['count']} unit'–æ–≤ –≥–æ—Ç–æ–≤—ã –¥–ª—è Docling")
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        limits = get_limits()
        for stage, limit in limits.items():
            print(f"  {stage}: {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}")
    
    def show_metrics(self, stage: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        metrics = get_processing_summary()
        
        if not metrics:
            print("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        summary = metrics.get("summary", {})
        print(f"\n–°–µ—Å—Å–∏—è: {metrics.get('session_id', 'N/A')}")
        print(f"–ù–∞—á–∞–ª–æ: {metrics.get('started_at', 'N/A')}")
        print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: {metrics.get('completed_at', 'N/A')}")
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {summary.get('total_input_files', 0)}")
        print(f"  –í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {summary.get('total_archives', 0)}")
        print(f"  –í—Å–µ–≥–æ unit'–æ–≤: {summary.get('total_units', 0)}")
        print(f"  –û—à–∏–±–æ–∫: {summary.get('total_errors', 0)}")
    
    def show_logs(self, filter_by: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–≥–∏."""
        print("\n=== –õ–æ–≥–∏ ===")
        print("–õ–æ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ API endpoint: GET /metrics/processing")
        print("–ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å–µ—Ä–≤–∏—Å–∞ router")
    
    def configure_limits(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        limits = get_limits()
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        print("1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞:     ", limits.get("detect_type", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("2. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤:   ", limits.get("extract_archive", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC:      ", limits.get("convert_doc", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:         ", limits.get("normalize", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("5. –°–æ–∑–¥–∞–Ω–∏–µ manifest:    ", limits.get("create_manifest", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        
        choice = input("\n–ò–∑–º–µ–Ω–∏—Ç—å –ª–∏–º–∏—Ç [1-5] –∏–ª–∏ 0 –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞: ").strip()
        
        if choice == "0":
            return
        
        stage_map = {
            "1": "detect_type",
            "2": "extract_archive",
            "3": "convert_doc",
            "4": "normalize",
            "5": "create_manifest"
        }
        
        if choice in stage_map:
            stage = stage_map[choice]
            new_limit = input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            try:
                limit_value = int(new_limit)
                if update_limit(stage, limit_value):
                    print(f"–õ–∏–º–∏—Ç –¥–ª—è {stage} –æ–±–Ω–æ–≤–ª–µ–Ω: {limit_value}")
                else:
                    print("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞")
            except ValueError:
                print("–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ")
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
    
    def run_full_pipeline(self, limits: Optional[Dict[str, int]] = None):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞."""
        print("\n=== –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===")
        print("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ input/")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /process_now")
        print("–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç")
    
    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª CLI."""
        while True:
            try:
                self.show_menu()
                choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ [0-18]: ").strip()
                
                if choice == "0":
                    print("–í—ã—Ö–æ–¥...")
                    break
                elif choice == "1":
                    self.handle_download_protocols()
                elif choice == "2":
                    self.handle_detect_type()
                elif choice == "3":
                    self.handle_extract_archive()
                elif choice == "4":
                    self.handle_convert_doc()
                elif choice == "5":
                    self.handle_normalize()
                elif choice == "6":
                    self.handle_create_manifest()
                elif choice == "7":
                    self.show_statistics()
                elif choice == "8":
                    self.show_metrics()
                elif choice == "9":
                    self.show_logs()
                elif choice == "10":
                    self.configure_limits()
                elif choice == "11":
                    self.run_full_pipeline()
                else:
                    print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
            
            except KeyboardInterrupt:
                print("\n\n–í—ã—Ö–æ–¥...")
                break
            except Exception as e:
                print(f"\n–û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")


    def handle_sync_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB."""
        print("\n=== –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB...")
        remote_client = get_remote_mongo_client()
        if not remote_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ .env:")
            print("    - mongoServer –∏–ª–∏ MONGO_SERVER")
            print("    - readAllUser –∏–ª–∏ MONGO_USER")
            print("    - readAllPassword –∏–ª–∏ MONGO_PASSWORD")
            print("    - sslCertPath –∏–ª–∏ MONGO_SSL_CERT")
            return
        
        remote_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB
        print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB...")
        local_client = get_local_mongo_client()
        if not local_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            print("    - LOCAL_MONGO_SERVER (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: localhost:27017)")
            print("    - MONGO_METADATA_USER")
            print("    - MONGO_METADATA_PASSWORD")
            return
        
        local_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –í—ã–±–æ—Ä –¥–∞—Ç—ã
        print("\n3. –í—ã–±–æ—Ä –¥–∞—Ç—ã –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:")
        print("  1. –í—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
        print("  2. –£–∫–∞–∑–∞—Ç—å –¥–∞—Ç—É –≤—Ä—É—á–Ω—É—é (YYYY-MM-DD)")
        choice = input("  –í—ã–±–µ—Ä–∏—Ç–µ [1-2] –∏–ª–∏ Enter –¥–ª—è –≤—á–µ—Ä–∞—à–Ω–µ–≥–æ –¥–Ω—è: ").strip()
        
        target_date = None
        if choice == "2":
            date_str = input("  –í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É (YYYY-MM-DD): ").strip()
            try:
                target_date = datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                print(f"‚úó –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}")
                return
        else:
            target_date = datetime.utcnow() - timedelta(days=1)
        
        # –õ–∏–º–∏—Ç
        limit_str = input(f"\n4. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        # –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        print(f"\n5. –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
        print(f"   –î–∞—Ç–∞: {target_date.date()}")
        print(f"   –õ–∏–º–∏—Ç: {limit}")
        
        result = sync_protocols_for_date(target_date, limit)
        
        if result.get("status") == "success":
            print("\n‚úì –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            print(f"   –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {result.get('scanned', 0)}")
            print(f"   –í—Å—Ç–∞–≤–ª–µ–Ω–æ: {result.get('inserted', 0)}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {result.get('skipped_existing', 0)}")
            if result.get("errors_count", 0) > 0:
                print(f"   –û—à–∏–±–æ–∫: {result.get('errors_count', 0)}")
        else:
            print(f"\n‚úó –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {result.get('message', 'Unknown error')}")
    
    
    def handle_download_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB —á–µ—Ä–µ–∑ VPN."""
        print("\n=== –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB (—Å VPN) ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ VPN –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ zakupki.gov.ru —á–µ—Ä–µ–∑ VPN...")
        if not check_zakupki_health():
            print("‚úó zakupki.gov.ru –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç VPN / –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)")
            print("  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ VPN –Ω–∞—Å—Ç—Ä–æ–µ–Ω —á–µ—Ä–µ–∑ route-up-zakupki.sh")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ OpenVPN —Ç—É–Ω–Ω–µ–ª—å –∞–∫—Ç–∏–≤–µ–Ω")
            return
        
        print("‚úì zakupki.gov.ru –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ VPN")
        
        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input(f"\n2. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/units –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        if limit <= 0:
            print("‚úó –õ–∏–º–∏—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return
        
        # –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        print(f"\n3. –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤...")
        print(f"   –õ–∏–º–∏—Ç: {limit} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {INPUT_DIR.absolute()}")
        
        try:
            downloader = ProtocolDownloader(output_dir=INPUT_DIR)
            start_time = time.time()
            result = downloader.process_pending_protocols(limit=limit)
            duration = time.time() - start_time
            
            if result.get("health_ok"):
                print("\n" + "=" * 80)
                print("‚úì –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
                print("=" * 80)
                print(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result.get('processed_ok', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –û—à–∏–±–æ–∫: {result.get('processed_error', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.get('downloaded_files_count', 0)}")
                print(f"  –û—à–∏–±–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {result.get('failed_files_count', 0)}")
                print(f"  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
                if result.get('processed_ok', 0) > 0:
                    avg_time = duration / result.get('processed_ok', 1)
                    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª: {avg_time:.2f} —Å–µ–∫")
            else:
                print("\n‚úó –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å VPN")
                
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_detect_type(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤ (–ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)."""
        print("\n=== –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ (–Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤) ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_DETECT_TYPE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_DETECT_TYPE
        
        print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ input/ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–§–∞–π–ª—ã –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞/—é–Ω–∏—Ç–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ –∏ –Ω–µ —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è.")
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
            from services.router.unit_distribution import distribute_unit_by_types
            from services.router.mongo import save_file_detection_metadata, save_unit_distribution_metadata
            from services.router.config import INPUT_DIR, ensure_directories
            from pathlib import Path
            import time
            from collections import defaultdict
            
            ensure_directories()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit > 0:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = {
                "processed_units": 0,
                "processed_files": 0,
                "mixed_units": 0,
                "duplicates_found": 0,
                "extension_mismatches": 0,
                "errors": 0,
                "file_types": defaultdict(int),
                "target_dirs": defaultdict(int),
                "unprocessed_units": [],  # Units –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏
                "extension_mismatch_details": []  # –î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            }
            
            start_time = time.time()
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units –±–µ–∑ —Ñ–∞–π–ª–æ–≤
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "no_files",
                        "message": "Unit –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–∞–π–ª–æ–≤"
                    })
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª(–æ–≤))...", end=" ", flush=True)
                
                try:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
                    files_list = [{"path": str(f)} for f in files]
                    
                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º unit
                    distribution_result = distribute_unit_by_types(
                        unit_id=unit_id,
                        files=files_list,
                        unit_metadata=None
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    for file_info in distribution_result["files"]:
                        try:
                            save_file_detection_metadata(
                                file_path=file_info["path"],
                                file_info=file_info,
                                unit_id=unit_id,
                                protocol_info=None
                            )
                        except Exception:
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MongoDB
                    
                    try:
                        save_unit_distribution_metadata(unit_id, distribution_result)
                    except Exception:
                        pass
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    stats["processed_units"] += 1
                    stats["processed_files"] += len(distribution_result["files"])
                    
                    if distribution_result["is_mixed"]:
                        stats["mixed_units"] += 1
                    
                    if distribution_result["duplicates_detected"]:
                        stats["duplicates_found"] += 1
                    
                    extension_mismatches = len(distribution_result["distribution_details"].get("extension_mismatches", []))
                    stats["extension_mismatches"] += extension_mismatches
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
                    for file_info in distribution_result["files"]:
                        if not file_info.get("extension_matches_content", True):
                            mismatch_detail = {
                                "unit_id": unit_id,
                                "file_name": file_info.get("original_name", "unknown"),
                                "extension": file_info.get("extension", "unknown"),
                                "expected_type": file_info.get("extension", "").replace(".", ""),
                                "detected_type": file_info.get("detected_type", "unknown"),
                                "mime_type": file_info.get("mime_type", "unknown")
                            }
                            stats["extension_mismatch_details"].append(mismatch_detail)
                    
                    for file_type in distribution_result["file_types"]:
                        stats["file_types"][file_type] += 1
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    target_dir = Path(distribution_result["target_dir"])
                    if "mixed" in str(target_dir):
                        stats["target_dirs"]["mixed"] += 1
                    else:
                        parent_name = target_dir.parent.name if target_dir.parent.name != "detected" else target_dir.name
                        stats["target_dirs"][parent_name] += 1
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    status_icon = "üîÄ" if distribution_result["is_mixed"] else "‚úì"
                    print(f"{status_icon} {', '.join(distribution_result['file_types'])}")
                
                except Exception as e:
                    stats["errors"] += 1
                    error_msg = str(e)
                    print(f"‚úó –û—à–∏–±–∫–∞: {error_msg[:50]}")
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units —Å –æ—à–∏–±–∫–∞–º–∏
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "error",
                        "message": error_msg,
                        "error_type": type(e).__name__
                    })
            
            duration = time.time() - start_time
            
            # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\n{'='*80}")
            print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ unit'–æ–≤: {stats['processed_units']}/{len(unit_dirs)}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {stats['processed_files']}")
            print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
            if stats['processed_units'] > 0:
                print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ unit: {duration/stats['processed_units']:.2f} —Å–µ–∫")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
            for file_type, count in sorted(stats['file_types'].items()):
                print(f"  {file_type}: {count}")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º:")
            for target_dir, count in sorted(stats['target_dirs'].items()):
                print(f"  {target_dir}: {count} unit'–æ–≤")
            
            print(f"\n–û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏:")
            print(f"  Mixed units: {stats['mixed_units']}")
            print(f"  –î—É–±–ª–∏–∫–∞—Ç—ã: {stats['duplicates_found']} unit'–æ–≤")
            print(f"  –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {stats['extension_mismatches']}")
            print(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö units
            unprocessed_count = len(stats.get("unprocessed_units", []))
            if unprocessed_count > 0:
                print(f"\n–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ units: {unprocessed_count}")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º
                by_reason = defaultdict(list)
                for unit in stats["unprocessed_units"]:
                    by_reason[unit["reason"]].append(unit)
                
                for reason, units in sorted(by_reason.items()):
                    reason_name = {
                        "no_files": "–ë–µ–∑ —Ñ–∞–π–ª–æ–≤",
                        "error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
                    }.get(reason, reason)
                    print(f"  {reason_name}: {len(units)} unit'–æ–≤")
                    if len(units) <= 10:
                        for unit_info in units:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                    else:
                        for unit_info in units[:5]:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                        print(f"    ... –∏ –µ—â–µ {len(units) - 5} unit'–æ–≤")
            
            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            if stats.get("extension_mismatch_details"):
                print(f"\n–î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π:")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                mismatch_groups = defaultdict(int)
                for detail in stats["extension_mismatch_details"]:
                    key = f"{detail['extension']} ‚Üí {detail['detected_type']}"
                    mismatch_groups[key] += 1
                
                for mismatch_type, count in sorted(mismatch_groups.items(), key=lambda x: x[1], reverse=True):
                    print(f"  {mismatch_type}: {count}")
            
            print(f"{'='*80}\n")
        
        except ImportError as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}")
            print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_extract_archive(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤."""
        print("\n=== –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_EXTRACT_ARCHIVE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_EXTRACT_ARCHIVE
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/extract_archive")
    
    
    def handle_normalize(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_NORMALIZE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_NORMALIZE
        
        print(f"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/normalize")
    
    def handle_create_manifest(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è manifest."""
        print("\n=== –°–æ–∑–¥–∞–Ω–∏–µ manifest ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_CREATE_MANIFEST}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_CREATE_MANIFEST
        
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ manifest —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/create_manifest")
    
    def show_statistics(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç—Ç–∞–ø–∞–º."""
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç—Ç–∞–ø–∞–º ===")
        stats = self.state_manager.get_statistics()
        
        print(f"\n–≠—Ç–∞–ø 1 (uploaded):     {len(list(INPUT_DIR.iterdir()))} —Ñ–∞–π–ª–æ–≤ –≤ input/")
        print(f"–≠—Ç–∞–ø 2 (detected):     {stats['detected']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"  –ü–æ —Ç–∏–ø–∞–º: {stats['detected']['by_type']}")
        print(f"–≠—Ç–∞–ø 3 (extracted):    {stats['extracted']['count']} —Ñ–∞–π–ª–æ–≤ (–∏–∑ {stats['extracted']['archives_processed']} –∞—Ä—Ö–∏–≤–æ–≤)")
        print(f"–≠—Ç–∞–ø 4 (converted):    {stats['converted']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"–≠—Ç–∞–ø 5 (normalized):   {stats['normalized']['count']} unit'–æ–≤")
        print(f"–≠—Ç–∞–ø 6 (ready):        {stats['ready']['count']} unit'–æ–≤ –≥–æ—Ç–æ–≤—ã –¥–ª—è Docling")
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        limits = get_limits()
        for stage, limit in limits.items():
            print(f"  {stage}: {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}")
    
    def show_metrics(self, stage: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        metrics = get_processing_summary()
        
        if not metrics:
            print("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        summary = metrics.get("summary", {})
        print(f"\n–°–µ—Å—Å–∏—è: {metrics.get('session_id', 'N/A')}")
        print(f"–ù–∞—á–∞–ª–æ: {metrics.get('started_at', 'N/A')}")
        print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: {metrics.get('completed_at', 'N/A')}")
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {summary.get('total_input_files', 0)}")
        print(f"  –í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {summary.get('total_archives', 0)}")
        print(f"  –í—Å–µ–≥–æ unit'–æ–≤: {summary.get('total_units', 0)}")
        print(f"  –û—à–∏–±–æ–∫: {summary.get('total_errors', 0)}")
    
    def show_logs(self, filter_by: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–≥–∏."""
        print("\n=== –õ–æ–≥–∏ ===")
        print("–õ–æ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ API endpoint: GET /metrics/processing")
        print("–ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å–µ—Ä–≤–∏—Å–∞ router")
    
    def configure_limits(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        limits = get_limits()
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        print("1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞:     ", limits.get("detect_type", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("2. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤:   ", limits.get("extract_archive", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC:      ", limits.get("convert_doc", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:         ", limits.get("normalize", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("5. –°–æ–∑–¥–∞–Ω–∏–µ manifest:    ", limits.get("create_manifest", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        
        choice = input("\n–ò–∑–º–µ–Ω–∏—Ç—å –ª–∏–º–∏—Ç [1-5] –∏–ª–∏ 0 –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞: ").strip()
        
        if choice == "0":
            return
        
        stage_map = {
            "1": "detect_type",
            "2": "extract_archive",
            "3": "convert_doc",
            "4": "normalize",
            "5": "create_manifest"
        }
        
        if choice in stage_map:
            stage = stage_map[choice]
            new_limit = input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            try:
                limit_value = int(new_limit)
                if update_limit(stage, limit_value):
                    print(f"–õ–∏–º–∏—Ç –¥–ª—è {stage} –æ–±–Ω–æ–≤–ª–µ–Ω: {limit_value}")
                else:
                    print("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞")
            except ValueError:
                print("–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ")
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
    
    def run_full_pipeline(self, limits: Optional[Dict[str, int]] = None):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞."""
        print("\n=== –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===")
        print("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ input/")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /process_now")
        print("–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç")
    
    def handle_cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MongoDB."""
        print("\n=== –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MongoDB ===")
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è —É–¥–∞–ª–∏—Ç:")
        print("  - –í—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê)")
        print("  - –í—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–π MongoDB")
        print("\n–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏:")
        print(f"  - {INPUT_DIR}")
        print(f"  - {PENDING_DIR}")
        print(f"  - {READY_DOCLING_DIR}")
        print(f"  - {TEMP_DIR}")
        print("\n–ö–æ–ª–ª–µ–∫—Ü–∏–∏ MongoDB –¥–ª—è –æ—á–∏—Å—Ç–∫–∏:")
        print(f"  - {MONGO_METADATA_DB}.protocols")
        print(f"  - {MONGO_METADATA_DB}.file_detections")
        print(f"  - {MONGO_METADATA_DB}.unit_distributions")
        print(f"  - {MONGO_METADATA_DB}.{MONGO_METADATA_COLLECTION}")
        print(f"  - {MONGO_METADATA_DB}.{MONGO_METRICS_COLLECTION}")
        
        confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ—á–∏—Å—Ç–∫—É? (yes/no): ").strip().lower()
        if confirm != "yes":
            print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞.")
            return
        
        print("\n–ù–∞—á–∞–ª–æ –æ—á–∏—Å—Ç–∫–∏...")
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        directories = [
            INPUT_DIR, PENDING_DIR, READY_DOCLING_DIR, TEMP_DIR
        ]
        
        dirs_cleaned = 0
        files_removed = 0
        
        for directory in directories:
            if not directory.exists():
                continue
            
            try:
                file_count = sum(1 for _ in directory.rglob("*") if _.is_file())
                files_removed += file_count
                
                for item in directory.iterdir():
                    if item.is_dir():
                        shutil.rmtree(item)
                    else:
                        item.unlink()
                
                dirs_cleaned += 1
                print(f"  ‚úì –û—á–∏—â–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory.name} ({file_count} —Ñ–∞–π–ª–æ–≤)")
            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {directory.name}: {e}")
        
        # –û—á–∏—Å—Ç–∫–∞ MongoDB –∫–æ–ª–ª–µ–∫—Ü–∏–π
        client = None
        try:
            print("\n–û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π MongoDB...")
            client = get_metadata_client()
            if not client:
                print("  ‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MongoDB")
            else:
                db = client[MONGO_METADATA_DB]
                collections_to_clean = [
                    ("protocols", "–ü—Ä–æ—Ç–æ–∫–æ–ª—ã"),
                    ("file_detections", "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–æ–≤"),
                    ("unit_distributions", "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è unit'–æ–≤"),
                    (MONGO_METADATA_COLLECTION, "–ú–∞–Ω–∏—Ñ–µ—Å—Ç—ã"),
                    (MONGO_METRICS_COLLECTION, "–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"),
                ]
                
                for coll_name, description in collections_to_clean:
                    try:
                        coll = db[coll_name]
                        count = coll.count_documents({})
                        if count > 0:
                            coll.delete_many({})
                            print(f"  ‚úì –û—á–∏—â–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è {coll_name} ({description}): {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                        else:
                            print(f"  - –ö–æ–ª–ª–µ–∫—Ü–∏—è {coll_name} —É–∂–µ –ø—É—Å—Ç–∞")
                    except Exception as e:
                        print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {coll_name}: {e}")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ MongoDB: {e}")
        finally:
            if client:
                client.close()
        
        print("\n" + "=" * 80)
        print("‚úì –û–ß–ò–°–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print("=" * 80)
        print(f"  –û—á–∏—â–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {dirs_cleaned}")
        print(f"  –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {files_removed}")
        print("\n–í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã. –ú–æ–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å –Ω–æ–≤—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    
    def handle_check_sorted_units(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤."""
        print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units ===")
        
        try:
            import subprocess
            import sys
            from pathlib import Path
            
            script_path = Path(__file__).parent.parent.parent / "scripts" / "check_sorted_units.py"
            
            if not script_path.exists():
                print(f"‚úó –°–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {script_path}")
                return
            
            print("\n–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏...")
            result = subprocess.run(
                [sys.executable, str(script_path)],
                capture_output=False,
                text=True
            )
            
            if result.returncode != 0:
                print("\n‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ")
            else:
                print("\n‚úì –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
            import traceback
            traceback.print_exc()
    
    
    def handle_analyze_detection_issues(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ ===")
        
        session_id = input("ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (Enter = –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–µ—Å—Å–∏—è): ").strip()
        session_id = session_id if session_id else None
        
        try:
            import subprocess
            import sys
            from pathlib import Path
            
            script_path = Path(__file__).parent.parent.parent / "scripts" / "analyze_detection_issues.py"
            
            if not script_path.exists():
                print(f"‚úó –°–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {script_path}")
                return
            
            print("\n–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞...")
            cmd = [sys.executable, str(script_path)]
            if session_id:
                cmd.extend(["--session-id", session_id])
            
            result = subprocess.run(
                cmd,
                capture_output=False,
                text=True
            )
            
            if result.returncode != 0:
                print("\n‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ")
            else:
                print("\n‚úì –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_convert_doc_to_html(self):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí HTML (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ detected/htmlDOC/)."""
        print("\n=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí HTML ===")
        
        html_doc_dir = DETECTED_DIR / "htmlDOC"
        if not html_doc_dir.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {html_doc_dir}")
            return
        
        from .html_processor import process_fake_doc_html
        
        unit_dirs = [d for d in html_doc_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
        if not unit_dirs:
            print("‚úì –ù–µ—Ç units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(unit_dirs)} units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed = 0
        errors = 0
        
        for unit_dir in unit_dirs:
            unit_id = unit_dir.name
            files_dir = unit_dir / "files"
            
            if not files_dir.exists():
                continue
            
            doc_files = list(files_dir.glob("*.doc"))
            for doc_file in doc_files:
                try:
                    new_path, metadata = process_fake_doc_html(doc_file, unit_id)
                    print(f"‚úì {doc_file.name} ‚Üí {new_path.name}")
                    processed += 1
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {doc_file.name}: {e}")
                    errors += 1
        
        print(f"\n‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}, –æ—à–∏–±–æ–∫: {errors}")
    
    def handle_convert_doc_to_xml(self):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí XML (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ detected/xmlDOC/)."""
        print("\n=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí XML ===")
        
        xml_doc_dir = DETECTED_DIR / "xmlDOC"
        if not xml_doc_dir.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {xml_doc_dir}")
            return
        
        from .xml_processor import process_fake_doc_xml
        
        unit_dirs = [d for d in xml_doc_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
        if not unit_dirs:
            print("‚úì –ù–µ—Ç units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(unit_dirs)} units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed = 0
        errors = 0
        
        for unit_dir in unit_dirs:
            unit_id = unit_dir.name
            files_dir = unit_dir / "files"
            
            if not files_dir.exists():
                continue
            
            doc_files = list(files_dir.glob("*.doc"))
            for doc_file in doc_files:
                try:
                    new_path, metadata = process_fake_doc_xml(doc_file, unit_id)
                    print(f"‚úì {doc_file.name} ‚Üí {new_path.name}")
                    processed += 1
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {doc_file.name}: {e}")
                    errors += 1
        
        print(f"\n‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}, –æ—à–∏–±–æ–∫: {errors}")
    
    def handle_sort_pdf(self):
        """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ PDF –Ω–∞ text_pdf –∏ scan_pdf."""
        print("\n=== –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ PDF –Ω–∞ text_pdf –∏ scan_pdf ===")
        
        limit_str = input("–õ–∏–º–∏—Ç units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Enter = –≤—Å–µ): ").strip()
        limit = int(limit_str) if limit_str else None
        
        from .pdf_sorter import sort_pdf_units, cleanup_already_sorted_units
        
        try:
            result = sort_pdf_units(limit=limit)
            
            if result.get("success"):
                stats = result["statistics"]
                print(f"\n‚úì –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"  –í—Å–µ–≥–æ units: {stats['total_units']}")
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_units']}")
                if stats.get('skipped_units', 0) > 0:
                    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped_units']}")
                print(f"  text_pdf: {stats['text_pdf_units']} ({stats['text_pdf_percentage']:.1f}%)")
                print(f"  scan_pdf: {stats['scan_pdf_units']} ({stats['scan_pdf_percentage']:.1f}%)")
                print(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
                
                # –û—á–∏—â–∞–µ–º —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                print(f"\n–û—á–∏—Å—Ç–∫–∞ —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units...")
                cleanup_result = cleanup_already_sorted_units()
                if cleanup_result.get("success"):
                    removed = cleanup_result.get("removed_count", 0)
                    if removed > 0:
                        print(f"  ‚úì –£–¥–∞–ª–µ–Ω–æ —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units: {removed}")
                    else:
                        print(f"  ‚úì –ù–µ—Ç —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
                    if cleanup_result.get("errors"):
                        print(f"  ‚ö† –û—à–∏–±–æ–∫ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {len(cleanup_result['errors'])}")
                
                # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö units
                if stats.get('skipped_details'):
                    print(f"\n–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ units:")
                    by_reason = {}
                    for skipped in stats['skipped_details']:
                        reason = skipped.get('reason', 'unknown')
                        if reason not in by_reason:
                            by_reason[reason] = []
                        by_reason[reason].append(skipped['unit_id'])
                    
                    for reason, unit_ids in sorted(by_reason.items()):
                        reason_name = {
                            "no_files_dir": "–ë–µ–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ files/",
                            "no_pdf_files": "–ë–µ–∑ PDF —Ñ–∞–π–ª–æ–≤"
                        }.get(reason, reason)
                        print(f"  {reason_name}: {len(unit_ids)} unit'–æ–≤")
                        if len(unit_ids) <= 10:
                            for uid in unit_ids:
                                print(f"    - {uid}")
                        else:
                            for uid in unit_ids[:5]:
                                print(f"    - {uid}")
                            print(f"    ... –∏ –µ—â–µ {len(unit_ids) - 5} unit'–æ–≤")
            else:
                print(f"\n‚úó –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_pending_directories(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        print("\n=== –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ===")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        pending_dirs = {
            "PENDING_NORMALIZE_DIR": PENDING_NORMALIZE_DIR,
            "PENDING_CONVERT_DIR": PENDING_CONVERT_DIR,
            "PENDING_EXTRACT_DIR": PENDING_EXTRACT_DIR
        }
        
        for dir_name, dir_path in pending_dirs.items():
            print(f"\n{dir_name}: {dir_path}")
            if not dir_path.exists():
                print("  ‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                continue
            
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ unit'–æ–≤
            unit_dirs = [d for d in dir_path.rglob("UNIT_*") if d.is_dir()]
            print(f"  –ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {len(unit_dirs)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 unit'–æ–≤
            if unit_dirs:
                print("  –ü–µ—Ä–≤—ã–µ unit'—ã:")
                for unit_dir in sorted(unit_dirs)[:5]:
                    files_dir = unit_dir / "files"
                    if files_dir.exists():
                        files = [f for f in files_dir.iterdir() if f.is_file()]
                        print(f"    {unit_dir.name}: {len(files)} —Ñ–∞–π–ª–æ–≤")
                    else:
                        print(f"    {unit_dir.name}: –Ω–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ files/")
                
                if len(unit_dirs) > 5:
                    print(f"    ... –∏ –µ—â–µ {len(unit_dirs) - 5} unit'–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ ReadyDocling
        print(f"\nREADY_DOCLING_DIR: {READY_DOCLING_DIR}")
        if READY_DOCLING_DIR.exists():
            # –°—á–∏—Ç–∞–µ–º PDF —Ñ–∞–π–ª—ã
            text_pdf_dir = READY_DOCLING_DIR / "pdf" / "text"
            scan_pdf_dir = READY_DOCLING_DIR / "pdf" / "scan"
            
            text_units = []
            scan_units = []
            
            if text_pdf_dir.exists():
                text_units = [d for d in text_pdf_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            if scan_pdf_dir.exists():
                scan_units = [d for d in scan_pdf_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            
            print(f"  PDF —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º —Å–ª–æ–µ–º: {len(text_units)} unit'–æ–≤")
            print(f"  PDF —Å–∫–∞–Ω—ã (—Ç—Ä–µ–±—É—é—Ç OCR): {len(scan_units)} unit'–æ–≤")
            
            # –°—á–∏—Ç–∞–µ–º –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã —Ñ–∞–π–ª–æ–≤
            other_types = ["docx", "html", "excel", "rtf", "doc", "zip", "rar", "7z", "unknown", "signature"]
            for file_type in other_types:
                type_dir = READY_DOCLING_DIR / file_type
                if type_dir.exists():
                    units = [d for d in type_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
                    if units:
                        print(f"  {file_type.upper()}: {len(units)} unit'–æ–≤")
        else:
            print("  ‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    def handle_detailed_metrics(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫."""
        print("\n=== –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ===")
        
        try:
            from .metrics import get_current_metrics, get_processing_summary
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            current_metrics = get_current_metrics()
            if current_metrics:
                print("\n–¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
                print(f"  Session ID: {current_metrics.get('session_id', 'N/A')}")
                started_at = current_metrics.get('started_at')
                if started_at:
                    print(f"  –ù–∞—á–∞–ª–æ: {started_at}")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
                pending_processing = current_metrics.get("pending_processing", {})
                if pending_processing:
                    print("\n  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
                    for stage, items in pending_processing.items():
                        print(f"    {stage}: {len(items)} —Ñ–∞–π–ª–æ–≤")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
                duplicates = current_metrics.get("duplicates", [])
                if duplicates:
                    print(f"\n  –î—É–±–ª–∏–∫–∞—Ç—ã:")
                    print(f"    –ì—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
                    total_dups = sum(d.get('duplicate_count', 0) for d in duplicates)
                    print(f"    –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_dups}")
            else:
                print("  –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            print("\n–ü–æ—Å–ª–µ–¥–Ω—è—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è:")
            last_metrics = get_processing_summary()
            if last_metrics:
                print(f"  Session ID: {last_metrics.get('session_id', 'N/A')}")
                started_at = last_metrics.get('started_at')
                completed_at = last_metrics.get('completed_at')
                if started_at:
                    print(f"  –ù–∞—á–∞–ª–æ: {started_at}")
                if completed_at:
                    print(f"  –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: {completed_at}")
                
                # Summary —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                summary = last_metrics.get("summary", {})
                if summary:
                    print(f"\n  –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                    print(f"    –í—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {summary.get('total_input_files', 0)}")
                    print(f"    –ê—Ä—Ö–∏–≤–æ–≤: {summary.get('total_archives', 0)}")
                    print(f"    –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {summary.get('total_extracted', 0)}")
                    print(f"    Unit'–æ–≤: {summary.get('total_units', 0)}")
                    print(f"    –û—à–∏–±–æ–∫: {summary.get('total_errors', 0)}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
                    pending_stats = summary.get("pending_statistics", {})
                    if pending_stats:
                        print(f"\n  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
                        print(f"    –í pending/normalize: {pending_stats.get('files_in_pending_normalize', 0)}")
                        print(f"    –í pending/convert: {pending_stats.get('files_in_pending_convert', 0)}")
                        print(f"    –í pending/extract: {pending_stats.get('files_in_pending_extract', 0)}")
                        print(f"    –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑ pending: {pending_stats.get('files_processed_from_pending', 0)}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
                    duplicate_stats = summary.get("duplicate_statistics", {})
                    if duplicate_stats:
                        print(f"\n  –î—É–±–ª–∏–∫–∞—Ç—ã:")
                        print(f"    –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_stats.get('total_duplicate_files', 0)}")
                        print(f"    –ì—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_stats.get('duplicate_groups_count', 0)}")
            else:
                print("  –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫")
                
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_force_cleanup(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        print("\n=== –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ===")
        
        try:
            from .utils import cleanup_all_empty_unit_directories
            
            # –°–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
            base_directories = [
                PENDING_NORMALIZE_DIR,
                PENDING_CONVERT_DIR,
                PENDING_EXTRACT_DIR,
                DETECTED_DIR,
                EXTRACTED_DIR,
                CONVERTED_DIR,
                NORMALIZED_DIR
            ]
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö unit'–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
            unit_ids = set()
            for base_dir in base_directories:
                if base_dir.exists():
                    for unit_dir in base_dir.rglob("UNIT_*"):
                        if unit_dir.is_dir():
                            unit_ids.add(unit_dir.name)
            
            print(f"–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(unit_ids)}")
            
            if not unit_ids:
                print("–ù–µ—Ç unit'–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏")
                return
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            confirm = input(f"–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è {len(unit_ids)} unit'–æ–≤? (y/N): ").strip().lower()
            if confirm != 'y':
                print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                return
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ unit'–∞
            total_removed = 0
            errors = []
            
            for i, unit_id in enumerate(sorted(unit_ids), 1):
                if i % 100 == 0:
                    print(f"[{i}/{len(unit_ids)}] –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ...")
                try:
                    result = cleanup_all_empty_unit_directories(unit_id, base_directories)
                    if result["success"]:
                        total_removed += result["total_removed"]
                    else:
                        errors.extend(result["errors"])
                except Exception as e:
                    errors.append(f"{unit_id}: {e}")
            
            print(f"\n–ò—Ç–æ–≥–∏ –æ—á–∏—Å—Ç–∫–∏:")
            print(f"  –£–¥–∞–ª–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {total_removed}")
            print(f"  –û—à–∏–±–æ–∫: {len(errors)}")
            
            if errors:
                print("–ü–µ—Ä–≤—ã–µ –æ—à–∏–±–∫–∏:")
                for error in errors[:10]:
                    print(f"  {error}")
                if len(errors) > 10:
                    print(f"  ... –∏ –µ—â–µ {len(errors) - 10} –æ—à–∏–±–æ–∫")
                    
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_view_pending_structure(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –Ω–æ–≤–æ–π pending —Å—Ç—Ä—É–∫—Ç—É—Ä—ã."""
        print("\n=== –ù–æ–≤–∞—è Pending –°—Ç—Ä—É–∫—Ç—É—Ä–∞ ===")
        
        try:
            from .unit_distribution_new import get_unit_statistics
            
            stats = get_unit_statistics()
            
            print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for category, data in stats.items():
                if data["units"] > 0 or data["files"] > 0:
                    print(f"\n{category.upper()}:")
                    print(f"  Unit'–æ–≤: {data['units']}")
                    print(f"  –§–∞–π–ª–æ–≤: {data['files']}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            from .config import (
                PENDING_DIRECT_DIR, PENDING_NORMALIZE_DIR, PENDING_CONVERT_DIR,
                PENDING_EXTRACT_DIR, PENDING_SPECIAL_DIR
            )
            
            dirs = {
                "DIRECT": PENDING_DIRECT_DIR,
                "NORMALIZE": PENDING_NORMALIZE_DIR,
                "CONVERT": PENDING_CONVERT_DIR,
                "EXTRACT": PENDING_EXTRACT_DIR,
                "SPECIAL": PENDING_SPECIAL_DIR
            }
            
            print("\n\n–ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º:")
            for name, path in dirs.items():
                exists = "‚úì" if path.exists() else "‚úó"
                print(f"{exists} {name}: {path}")
                
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_category_statistics(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ===")
        
        try:
            from .unit_distribution_new import get_unit_statistics
            from .mixed_unit_handler import get_mixed_units_statistics
            from .merge import get_ready_docling_statistics
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ pending
            print("\nüìÅ PENDING (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞):")
            pending_stats = get_unit_statistics()
            
            # –î–æ–±–∞–≤–ª—è–µ–º mixed —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            mixed_stats = get_mixed_units_statistics(include_extraction=True)
            
            total_pending_units = sum(cat["units"] for cat in pending_stats.values())
            total_pending_files = sum(cat["files"] for cat in pending_stats.values())
            
            print(f"\n  –í—Å–µ–≥–æ unit'–æ–≤: {total_pending_units}")
            print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_pending_files}")
            
            print("\n  –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for category in ["direct", "normalize", "convert", "extract", "special", "mixed"]:
                data = pending_stats.get(category, {"units": 0, "files": 0})
                if data["units"] > 0:
                    print(f"    {category:12} - {data['units']:4} unit'–æ–≤, {data['files']:5} —Ñ–∞–π–ª–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º mixed units –¥–µ—Ç–∞–ª—å–Ω–æ –µ—Å–ª–∏ –µ—Å—Ç—å
            if mixed_stats["total_mixed"]["units"] > 0:
                print(f"\n  üîÄ Mixed units (–¥–µ—Ç–∞–ª—å–Ω–æ):")
                if mixed_stats["detection_mixed"]["units"] > 0:
                    print(f"    ‚îî‚îÄ –∏–∑ detection:  {mixed_stats['detection_mixed']['units']:4} unit'–æ–≤, {mixed_stats['detection_mixed']['files']:5} —Ñ–∞–π–ª–æ–≤")
                if mixed_stats["extraction_mixed"]["units"] > 0:
                    print(f"    ‚îî‚îÄ –∏–∑ extraction: {mixed_stats['extraction_mixed']['units']:4} unit'–æ–≤, {mixed_stats['extraction_mixed']['files']:5} —Ñ–∞–π–ª–æ–≤")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ready_docling
            print("\n\n‚úÖ READY_DOCLING (–≥–æ—Ç–æ–≤–æ –¥–ª—è Docling):")
            ready_stats = get_ready_docling_statistics()
            
            print(f"\n  –í—Å–µ–≥–æ unit'–æ–≤: {ready_stats['total_units']}")
            print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {ready_stats['total_files']}")
            
            if ready_stats['by_type']:
                print("\n  –ü–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤:")
                for file_type, data in sorted(ready_stats['by_type'].items()):
                    print(f"    {file_type:12} - {data['units']:4} unit'–æ–≤, {data['files']:5} —Ñ–∞–π–ª–æ–≤")
            
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_merge_dry_run(self):
        """Merge –≤ ready_docling (DRY RUN —Ä–µ–∂–∏–º)."""
        print("\n=== Merge –≤ ready_docling (DRY RUN) ===")
        print("–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏ - —Ñ–∞–π–ª—ã –ù–ï –±—É–¥—É—Ç –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã\n")
        
        try:
            from .merge import merge_to_ready_docling, print_merge_summary
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
            limit_input = input("–õ–∏–º–∏—Ç unit'–æ–≤ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_input) if limit_input else None
            
            print("\n–í—ã–ø–æ–ª–Ω—è—é merge –≤ —Ä–µ–∂–∏–º–µ DRY RUN...")
            result = merge_to_ready_docling(dry_run=True, limit=limit)
            
            print_merge_summary(result)
            
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_merge_real(self):
        """Merge –≤ ready_docling (–†–ï–ê–õ–¨–ù–´–ô —Ä–µ–∂–∏–º)."""
        print("\n=== Merge –≤ ready_docling (–†–ï–ê–õ–¨–ù–´–ô –†–ï–ñ–ò–ú) ===")
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –§–∞–π–ª—ã –±—É–¥—É—Ç –†–ï–ê–õ–¨–ù–û –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã!\n")
        
        try:
            from .merge import merge_to_ready_docling, print_merge_summary
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
            limit_input = input("–õ–∏–º–∏—Ç unit'–æ–≤ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_input) if limit_input else None
            
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            confirm = input(f"\n–ü–µ—Ä–µ–º–µ—â–∞—Ç—å —Ñ–∞–π–ª—ã –≤ ready_docling? (y/N): ").strip().lower()
            if confirm != 'y':
                print("–û—Ç–º–µ–Ω–µ–Ω–æ")
                return
            
            print("\n–í—ã–ø–æ–ª–Ω—è—é –†–ï–ê–õ–¨–ù–´–ô merge...")
            result = merge_to_ready_docling(dry_run=False, limit=limit)
            
            print_merge_summary(result)
            
            if result['files_moved'] > 0:
                print("\n‚úì Merge –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                
                # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ—á–∏—Å—Ç–∫—É
                cleanup = input("\n–û—á–∏—Å—Ç–∏—Ç—å pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ—Å–ª–µ merge? (y/N): ").strip().lower()
                if cleanup == 'y':
                    from .merge import cleanup_pending_after_merge
                    unit_ids = [f["unit_id"] for f in result.get("distributed_files", [])]
                    cleanup_result = cleanup_pending_after_merge(unit_ids, dry_run=False)
                    print(f"–û—á–∏—â–µ–Ω–æ unit'–æ–≤: {cleanup_result['cleaned_units']}")
                    print(f"–£–¥–∞–ª–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {cleanup_result['cleaned_directories']}")
            
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step1_scan_and_detect(self, limit: Optional[int] = None):
        """–®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ input/ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_detection import detect_file_type
            from pathlib import Path
            from collections import defaultdict
            import time
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = {
                "units_scanned": 0,
                "files_scanned": 0,
                "by_extension": defaultdict(int),
                "by_detected_type": defaultdict(int),
                "extension_mismatches": 0,
                "empty_units": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    stats["empty_units"] += 1
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª(–æ–≤)):")
                stats["units_scanned"] += 1
                
                for file_path in files:
                    try:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø
                        detection = detect_file_type(file_path)
                        
                        ext = file_path.suffix.lower()
                        detected_type = detection.get("detected_type", "unknown")
                        mime = detection.get("mime_type", "unknown")
                        
                        stats["files_scanned"] += 1
                        stats["by_extension"][ext or ".no_ext"] += 1
                        stats["by_detected_type"][detected_type] += 1
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                        mismatch = not detection.get("extension_matches_content", True)
                        if mismatch:
                            stats["extension_mismatches"] += 1
                        
                        # –í—ã–≤–æ–¥
                        mismatch_flag = " ‚ö† MISMATCH" if mismatch else ""
                        print(f"  {file_path.name:40} | {ext:8} ‚Üí {detected_type:12} | {mime:30}{mismatch_flag}")
                        
                    except Exception as e:
                        print(f"  ‚úó {file_path.name}: {str(e)[:40]}")
                
                print()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É units
            
            duration = time.time() - start_time
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–Ø:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['units_scanned']}")
            print(f"Units –ø—É—Å—Ç—ã—Ö: {stats['empty_units']}")
            print(f"–§–∞–π–ª–æ–≤ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: {stats['files_scanned']}")
            print(f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {stats['extension_mismatches']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            print(f"\n–ü–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º:")
            for ext, count in sorted(stats["by_extension"].items(), key=lambda x: -x[1])[:10]:
                print(f"  {ext:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
            
            print(f"\n–ü–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ç–∏–ø–∞–º:")
            for dtype, count in sorted(stats["by_detected_type"].items(), key=lambda x: -x[1])[:10]:
                print(f"  {dtype:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step2_classify(self, limit: Optional[int] = None):
        """–®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
        print("\n=== –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_detection import detect_file_type
            from .file_classifier import classify_file
            from collections import defaultdict
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_classified": 0,
                "files_classified": 0,
                "by_category": defaultdict(int),
                "by_action": defaultdict(int)
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id}:")
                stats["units_classified"] += 1
                
                for file_path in files:
                    try:
                        detection = detect_file_type(file_path)
                        classification = classify_file(file_path, detection)
                        
                        category = classification["category"]
                        action = classification["action"]
                        reason = classification.get("reason", "")
                        
                        stats["files_classified"] += 1
                        stats["by_category"][category] += 1
                        stats["by_action"][action] += 1
                        
                        print(f"  {file_path.name:40} ‚Üí {category:12} | {action:15} | {reason}")
                        
                    except Exception as e:
                        print(f"  ‚úó {file_path.name}: {str(e)[:40]}")
                
                print()
            
            duration = time.time() - start_time
            
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['units_classified']}")
            print(f"–§–∞–π–ª–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {stats['files_classified']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            print(f"\n–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for cat, count in sorted(stats["by_category"].items(), key=lambda x: -x[1]):
                print(f"  {cat:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
            
            print(f"\n–ü–æ –¥–µ–π—Å—Ç–≤–∏—è–º:")
            for act, count in sorted(stats["by_action"].items(), key=lambda x: -x[1]):
                print(f"  {act:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step3_check_duplicates(self, limit: Optional[int] = None):
        """–®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤."""
        print("\n=== –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_detection import detect_file_type
            from .file_classifier import classify_file
            from .duplicate_detection import detect_duplicates_in_unit
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_checked": 0,
                "units_with_duplicates": 0,
                "total_duplicate_groups": 0,
                "total_duplicate_files": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id}:")
                stats["units_checked"] += 1
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                classified_files = []
                for file_path in files:
                    try:
                        detection = detect_file_type(file_path)
                        classification = classify_file(file_path, detection)
                        classified_files.append({
                            "path": str(file_path),
                            "original_name": file_path.name,
                            **detection,
                            "classification": classification
                        })
                    except Exception as e:
                        print(f"  ‚úó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path.name}: {e}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                duplicates_map = detect_duplicates_in_unit(classified_files)
                
                if duplicates_map:
                    stats["units_with_duplicates"] += 1
                    stats["total_duplicate_groups"] += len(duplicates_map)
                    
                    print(f"  ‚ö† –ù–∞–π–¥–µ–Ω–æ {len(duplicates_map)} –≥—Ä—É–ø–ø(—ã) –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
                    
                    for hash_value, dup_files in duplicates_map.items():
                        stats["total_duplicate_files"] += len(dup_files)
                        print(f"\n    –ì—Ä—É–ø–ø–∞ (hash: {hash_value[:12]}...):")
                        for dup_file in dup_files:
                            print(f"      - {dup_file.get('original_name')}")
                else:
                    print(f"  ‚úì –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
                print()
            
            duration = time.time() - start_time
            
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –ü–†–û–í–ï–†–ö–ò –î–£–ë–õ–ò–ö–ê–¢–û–í:")
            print(f"{'='*80}")
            print(f"Units –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['units_checked']}")
            print(f"Units —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {stats['units_with_duplicates']}")
            print(f"–í—Å–µ–≥–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['total_duplicate_groups']}")
            print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['total_duplicate_files']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step4_check_mixed(self, limit: Optional[int] = None):
        """–®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units."""
        print("\n=== –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_classifier import classify_unit_files
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_checked": 0,
                "mixed_units": 0,
                "homogeneous_units": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                stats["units_checked"] += 1
                
                # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º unit
                unit_classification = classify_unit_files(files, unit_id)
                
                is_mixed = unit_classification["is_mixed"]
                unit_category = unit_classification["unit_category"]
                type_dist = unit_classification["type_distribution"]
                
                if is_mixed:
                    stats["mixed_units"] += 1
                    print(f"[{idx}/{len(unit_dirs)}] {unit_id}: üîÄ MIXED")
                    print(f"  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                    for cat, count in type_dist.items():
                        print(f"    {cat:15} - {count} —Ñ–∞–π–ª(–æ–≤)")
                else:
                    stats["homogeneous_units"] += 1
                    print(f"[{idx}/{len(unit_dirs)}] {unit_id}: ‚úì –û–¥–Ω–æ—Ä–æ–¥–Ω—ã–π ({unit_category})")
                
                print()
            
            duration = time.time() - start_time
            
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø MIXED UNITS:")
            print(f"{'='*80}")
            print(f"Units –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['units_checked']}")
            print(f"Mixed units: {stats['mixed_units']}")
            print(f"–û–¥–Ω–æ—Ä–æ–¥–Ω—ã—Ö units: {stats['homogeneous_units']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step5_distribute(self, limit: Optional[int] = None):
        """–®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º."""
        print("\n=== –®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .unit_distribution_new import distribute_unit_by_new_structure
            from .mixed_unit_handler import get_mixed_units_statistics
            from collections import defaultdict
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_processed": 0,
                "files_moved": 0,
                "by_category": defaultdict(int),
                "mixed_units": 0,
                "errors": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª–æ–≤)...", end=" ", flush=True)
                
                try:
                    files_list = [{"path": str(f)} for f in files]
                    result = distribute_unit_by_new_structure(unit_id, files_list)
                    
                    stats["units_processed"] += 1
                    stats["files_moved"] += result["files_processed"]
                    
                    if result.get("is_mixed"):
                        stats["mixed_units"] += 1
                        print(f"üîÄ MIXED ‚Üí pending/mixed/")
                    else:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                        main_cat = max(result["files_by_category"].items(), key=lambda x: x[1])[0] if result["files_by_category"] else "unknown"
                        stats["by_category"][main_cat] += 1
                        print(f"‚úì ‚Üí pending/{main_cat}/")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏
                    if result.get("errors"):
                        print(f"     ‚ö† –û—à–∏–±–æ–∫: {len(result['errors'])}")
                    if result.get("duplicates_detected"):
                        print(f"     ‚ö† –î—É–±–ª–∏–∫–∞—Ç—ã: {result['duplicate_count']} –≥—Ä—É–ø–ø")
                    
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞: {str(e)[:50]}")
                    stats["errors"] += 1
            
            duration = time.time() - start_time
            
            print(f"\n{'='*80}")
            print(f"–ò–¢–û–ì–ò –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['units_processed']}")
            print(f"–§–∞–π–ª–æ–≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {stats['files_moved']}")
            print(f"Mixed units: {stats['mixed_units']}")
            print(f"–û—à–∏–±–æ–∫: {stats['errors']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for cat, count in sorted(stats["by_category"].items(), key=lambda x: -x[1]):
                print(f"  {cat:15} - {count:4} unit(–æ–≤)")
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ mixed units
            mixed_stats = get_mixed_units_statistics(include_extraction=False)
            if mixed_stats["total_mixed"]["units"] > 0:
                print(f"\nüîÄ Mixed units (–¥–µ—Ç–∞–ª—å–Ω–æ):")
                print(f"  Units: {mixed_stats['total_mixed']['units']}")
                print(f"  –§–∞–π–ª–æ–≤: {mixed_stats['total_mixed']['files']}")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_full_processing(self, limit: Optional[int] = None):
        """–ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (3-7)."""
        print("\n=== –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ) ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        print(f"\n{'='*80}")
        print("–ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò")
        print(f"{'='*80}\n")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —à–∞–≥–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (—Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–∂–µ –≤–∫–ª—é—á–µ–Ω—ã)
        self.handle_step5_distribute(limit=limit)
    
    def handle_units_report(self):
        """–û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units."""
        print("\n=== –û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units ===")
        
        try:
            from .config import PENDING_DIR
            import json
            
            categories = {
                "direct": PENDING_DIRECT_DIR,
                "normalize": PENDING_NORMALIZE_DIR,
                "convert": PENDING_CONVERT_DIR,
                "extract": PENDING_EXTRACT_DIR,
                "special": PENDING_SPECIAL_DIR,
                "mixed": PENDING_MIXED_DIR
            }
            
            total_units = 0
            total_files = 0
            
            for category, cat_dir in categories.items():
                if not cat_dir.exists():
                    continue
                
                units = [d for d in cat_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
                
                if not units:
                    continue
                
                print(f"\n{'='*80}")
                print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category.upper()}")
                print(f"{'='*80}")
                print(f"Units: {len(units)}\n")
                
                for unit_dir in units[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    unit_id = unit_dir.name
                    files_dir = unit_dir / "files"
                    metadata_file = unit_dir / "metadata.json"
                    
                    files_count = 0
                    if files_dir.exists():
                        files = [f for f in files_dir.iterdir() if f.is_file()]
                        files_count = len(files)
                        total_files += files_count
                    
                    total_units += 1
                    
                    print(f"  {unit_id}: {files_count} —Ñ–∞–π–ª(–æ–≤)")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                    if metadata_file.exists():
                        try:
                            with open(metadata_file, 'r') as f:
                                metadata = json.load(f)
                                dist_result = metadata.get("distribution_result", {})
                                if dist_result.get("duplicates_detected"):
                                    print(f"    ‚ö† –î—É–±–ª–∏–∫–∞—Ç—ã: {dist_result.get('duplicate_count', 0)} –≥—Ä—É–ø–ø")
                                if dist_result.get("errors"):
                                    print(f"    ‚úó –û—à–∏–±–æ–∫: {len(dist_result['errors'])}")
                        except:
                            pass
                
                if len(units) > 10:
                    print(f"  ... –∏ –µ—â–µ {len(units) - 10} unit(–æ–≤)")
            
            print(f"\n{'='*80}")
            print(f"–ò–¢–û–ì–û:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_units}")
            print(f"–§–∞–π–ª–æ–≤ –≤—Å–µ–≥–æ: {total_files}")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_new_structure_detection(self, limit: Optional[int] = None):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–π pending —Å—Ç—Ä—É–∫—Ç—É—Ä—ã."""
        print("\n=== –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ (–ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê —Å pending/) ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .unit_distribution_new import distribute_unit_by_new_structure, print_distribution_summary
            from .mixed_unit_handler import get_mixed_units_statistics
            from pathlib import Path
            import time
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            processed = 0
            errors = 0
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª–æ–≤)...", end=" ", flush=True)
                
                try:
                    files_list = [{"path": str(f)} for f in files]
                    result = distribute_unit_by_new_structure(unit_id, files_list)
                    
                    if result.get("is_mixed"):
                        print(f"üîÄ MIXED")
                    else:
                        print(f"‚úì")
                    
                    processed += 1
                except Exception as e:
                    print(f"‚úó {str(e)[:30]}")
                    errors += 1
            
            duration = time.time() - start_time
            
            print(f"\n{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{len(unit_dirs)}")
            print(f"–û—à–∏–±–æ–∫: {errors}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            # –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É mixed units
            mixed_stats = get_mixed_units_statistics(include_extraction=False)
            if mixed_stats["total_mixed"]["units"] > 0:
                print(f"\nüîÄ Mixed units –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {mixed_stats['total_mixed']['units']}")
                print(f"  –§–∞–π–ª–æ–≤ –≤ mixed units: {mixed_stats['total_mixed']['files']}")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª CLI."""
        while True:
            try:
                self.show_menu()
                choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ [0-19]: ").strip()
                
                if choice == "0":
                    print("–í—ã—Ö–æ–¥...")
                    break
                
                # === –ó–ê–ì–†–£–ó–ö–ê –ò –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø ===
                elif choice == "1":
                    self.handle_download_protocols()
                elif choice == "2":
                    self.handle_sync_protocols()
                
                # === –ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê (PENDING) - –ü–û–®–ê–ì–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===
                elif choice == "3":
                    self.handle_step1_scan_and_detect()
                elif choice == "4":
                    self.handle_step2_classify()
                elif choice == "5":
                    self.handle_step3_check_duplicates()
                elif choice == "6":
                    self.handle_step4_check_mixed()
                elif choice == "7":
                    self.handle_step5_distribute()
                elif choice == "8":
                    self.handle_full_processing()
                
                # === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ü–†–û–°–ú–û–¢–† ===
                elif choice == "9":
                    self.handle_view_pending_structure()
                elif choice == "10":
                    self.handle_category_statistics()
                elif choice == "11":
                    self.handle_units_report()
                
                # === MERGE –í READY_DOCLING ===
                elif choice == "12":
                    self.handle_merge_dry_run()
                elif choice == "13":
                    self.handle_merge_real()
                
                # === –°–õ–£–ñ–ï–ë–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò ===
                elif choice == "14":
                    self.show_statistics()
                elif choice == "15":
                    self.show_metrics()
                elif choice == "16":
                    self.configure_limits()
                elif choice == "17":
                    self.handle_cleanup()
                elif choice == "18":
                    self.handle_check_sorted_units()
                elif choice == "19":
                    self.handle_analyze_detection_issues()
                
                else:
                    print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
            
            except KeyboardInterrupt:
                print("\n\n–í—ã—Ö–æ–¥...")
                break
            except Exception as e:
                print(f"\n–û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                input("\–Ω–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")


    def handle_convert_doc(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ DOC ‚Üí DOCX."""
        print("\n=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí DOCX ===")

        limit_str = input("–õ–∏–º–∏—Ç units –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (Enter = –≤—Å–µ): ").strip()
        limit = int(limit_str) if limit_str else None

        try:
            from services.router.doc_conversion import convert_doc_to_docx, validate_docx
            from services.router.file_detection import detect_file_type
            from services.router.config import DETECTED_DIR, CONVERTED_DIR
            from services.router.mongo import save_conversion_metric
            from pathlib import Path
            import time
            from collections import defaultdict

            # –†–∞–±–æ—á–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å DOC —Ñ–∞–π–ª–∞–º–∏
            doc_dir = DETECTED_DIR / "doc"
            if not doc_dir.exists():
                print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å DOC —Ñ–∞–π–ª–∞–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {doc_dir}")
                return

            # –°–∫–∞–Ω–∏—Ä—É–µ–º –≤—Å–µ units –∏ —Å–æ–±–∏—Ä–∞–µ–º —Ñ–∞–π–ª—ã –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
            doc_files_to_convert = []
            stats = {
                "processed_units": 0,
                "total_files": 0,
                "successful": 0,
                "failed": 0,
                "skipped_fake": 0,
                "skipped_no_conv": 0,
                "errors": defaultdict(int)
            }

            print("–°–±–æ—Ä —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏...")

            unit_dirs = [d for d in doc_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            if limit:
                unit_dirs = unit_dirs[:limit]

            for unit_dir in unit_dirs:
                unit_id = unit_dir.name
                files_dir = unit_dir / "files"

                if not files_dir.exists():
                    continue

                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ .doc —Ñ–∞–π–ª—ã –≤ unit'–µ
                doc_files = [f for f in files_dir.iterdir() if f.is_file() and f.suffix.lower() == ".doc"]

                for doc_file in doc_files:
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
                    file_info = detect_file_type(doc_file)
                    detected_type = file_info.get("detected_type", "unknown")
                    is_fake_doc = file_info.get("is_fake_doc", False)
                    requires_conversion = file_info.get("requires_conversion", False)

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–µ DOC
                    if is_fake_doc:
                        stats["skipped_fake"] += 1
                        continue

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ç—Ä–µ–±—É—é—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
                    if not requires_conversion or detected_type != "doc":
                        stats["skipped_no_conv"] += 1
                        continue

                    doc_files_to_convert.append((doc_file, unit_id))
                    stats["total_files"] += 1

            if not doc_files_to_convert:
                print("‚úì –ù–µ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")
                return

            print(f"\n–ù–∞–π–¥–µ–Ω–æ units: {len(unit_dirs)}")
            print(f"–§–∞–π–ª–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {len(doc_files_to_convert)}")
            print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–µ–π–∫–æ–≤—ã—Ö: {stats['skipped_fake']}")
            print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –Ω–µ–ø–æ–¥—Ö–æ–¥—è—â–∏—Ö: {stats['skipped_no_conv']}")
            print(f"{'='*80}\n")

            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤
            workers_str = input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ (1 = –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, 2+ = –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ, Enter = 1): ").strip()
            max_workers = int(workers_str) if workers_str else 1

            if max_workers < 1:
                max_workers = 1

            start_time = time.time()
            from services.router.doc_conversion import (
                convert_doc_files_sequential,
                convert_doc_files_parallel,
                _cleanup_empty_directories
            )
            from services.router.config import CONVERTED_DIR, DETECTED_DIR

            # –í—ã–±–∏—Ä–∞–µ–º —Ä–µ–∂–∏–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
            if max_workers == 1:
                print(f"–†–µ–∂–∏–º: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (1 –ø–æ—Ç–æ–∫)")
                conversion_results = convert_doc_files_sequential(doc_files_to_convert)
            else:
                print(f"–†–µ–∂–∏–º: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ({max_workers} –ø–æ—Ç–æ–∫–æ–≤)")
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
                max_workers = min(max_workers, len(doc_files_to_convert), 5)
                conversion_results = convert_doc_files_parallel(doc_files_to_convert, max_workers=max_workers)

            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            for result in conversion_results["results"]:
                if result["success"]:
                    stats["successful"] += 1
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫—É
                    try:
                        save_conversion_metric({
                            "unit_id": result["unit_id"],
                            "original_file": Path(result["doc_path"]).name,
                            "success": True,
                            "conversion_time": result["details"].get("conversion_time", 0),
                            "total_time": result["details"].get("conversion_time", 0)
                        })
                    except:
                        pass
                else:
                    stats["failed"] += 1
                    error_msg = result["details"].get("error", "unknown error")
                    stats["errors"][error_msg] += 1

            # –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            print("\n–û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π...")
            removed_converted = _cleanup_empty_directories(CONVERTED_DIR, "docx")
            removed_detected = _cleanup_empty_directories(DETECTED_DIR, "doc")
            if removed_converted > 0:
                print(f"  ‚úì –£–¥–∞–ª–µ–Ω–æ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –≤ converted/docx: {removed_converted}")
            if removed_detected > 0:
                print(f"  ‚úì –£–¥–∞–ª–µ–Ω–æ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –≤ detected/doc: {removed_detected}")

            duration = time.time() - start_time

            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            print(f"\n{'='*80}")
            print("–û–¢–ß–ï–¢ –û –ö–û–ù–í–ï–†–¢–ê–¶–ò–ò DOC ‚Üí DOCX")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {stats['total_files']}")
            print(f"–£—Å–ø–µ—à–Ω–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ: {stats['successful']}")
            print(f"–û—à–∏–±–æ–∫: {stats['failed']}")
            print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ —Ñ–µ–π–∫–æ–≤—ã—Ö: {stats['skipped_fake']}")
            print(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ –Ω–µ —Ç—Ä–µ–±—É—é—â–∏—Ö: {stats['skipped_no_conv']}")
            print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {conversion_results['total_time']:.2f} —Å–µ–∫")
            if max_workers == 1:
                print(f"–†–µ–∂–∏–º: –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
            else:
                print(f"–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤: {max_workers}")

            if stats["successful"] > 0:
                avg_time = conversion_results['total_time'] / stats["successful"]
                print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Ñ–∞–π–ª: {avg_time:.2f} —Å–µ–∫")

            if stats["errors"]:
                print(f"\n–û—à–∏–±–∫–∏ –ø–æ —Ç–∏–ø–∞–º:")
                for error_type, count in sorted(stats["errors"].items(), key=lambda x: x[1], reverse=True):
                    print(f"  {error_type}: {count}")

            print(f"{'='*80}\n")

            if stats["successful"] > 0:
                print("‚úì –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            else:
                print("‚ö† –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")

        except ImportError as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}")
            import traceback
            traceback.print_exc()


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è CLI."""
    cli = PreprocessingCLI()
    cli.run()


if __name__ == "__main__":
    main()


```

–ü—Ä–æ–≤–µ—Ä—é linter:

–û—Ç–ª–∏—á–Ω–æ! –¢–µ–ø–µ—Ä—å –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º:

–û—Ç–ª–∏—á–Ω–æ! –ú–µ–Ω—é —Ä–∞–±–æ—Ç–∞–µ—Ç! –í–∏–∂—É –æ–ø–µ—á–∞—Ç–∫—É –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å—Ç—Ä–æ–∫–µ (`\–Ω` –≤–º–µ—Å—Ç–æ `\n`). –ò—Å–ø—Ä–∞–≤–ª—é:

```python
"""
CLI –¥–ª—è –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ–º preprocessing.
"""
import sys
import json
from pathlib import Path
from typing import Optional, Dict, Any

from .config import (
    INPUT_DIR, TEMP_DIR,
    PENDING_DIR, PENDING_NORMALIZE_DIR, PENDING_CONVERT_DIR, PENDING_EXTRACT_DIR,
    PENDING_DIRECT_DIR, PENDING_SPECIAL_DIR, PENDING_MIXED_DIR,
    READY_DOCLING_DIR,
    get_limits, update_limit, LIMIT_DETECT_TYPE, LIMIT_EXTRACT_ARCHIVE,
    LIMIT_CONVERT_DOC, LIMIT_NORMALIZE, LIMIT_CREATE_MANIFEST,
    MONGO_METADATA_DB, MONGO_METADATA_COLLECTION, MONGO_METRICS_COLLECTION
)
from .state_manager import StateManager

# –ó–∞–≥–ª—É—à–∫–∏ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π (–¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º–∏ —Ñ—É–Ω–∫—Ü–∏—è–º–∏)
DETECTED_DIR = PENDING_DIR / "_legacy_detected"
EXTRACTED_DIR = PENDING_DIR / "_legacy_extracted"
CONVERTED_DIR = PENDING_DIR / "_legacy_converted"
NORMALIZED_DIR = PENDING_DIR / "_legacy_normalized"
READY_DIR = PENDING_DIR / "_legacy_ready"
MIXED_DIR = PENDING_DIR / "_legacy_mixed"
ARCHIVE_DIR = PENDING_DIR / "_legacy_archive"

from .metrics import get_processing_summary
from .protocol_sync import (
    get_remote_mongo_client, get_local_mongo_client, sync_protocols_for_date
)
from ..downloader import ProtocolDownloader, check_zakupki_health
from ..downloader.manager import get_metadata_client, MONGO_METADATA_PROTOCOLS_COLLECTION
from .mongo import get_mongo_metadata_client
from datetime import datetime, timedelta
import time
import shutil
from pymongo.errors import PyMongoError


class PreprocessingCLI:
    """–ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π CLI –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è preprocessing."""
    
    def __init__(self):
        self.state_manager = StateManager()
        self.limits = get_limits()
    
    def show_menu(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é."""
        print("\n" + "=" * 50)
        print("=== Winners223 Preprocessing CLI ===")
        print("=" * 50)
        
        print("\n=== –ó–ê–ì–†–£–ó–ö–ê –ò –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø ===")
        print("1. –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª—ã –∏–∑ MongoDB (—Å VPN)")
        print("2. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB")
        
        # print("\n=== –û–ë–†–ê–ë–û–¢–ö–ê (–°–¢–ê–†–ê–Ø –°–ò–°–¢–ï–ú–ê) ===")
        # print("3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ñ–∞–π–ª–∞(–æ–≤)")
        # print("4. –†–∞—Å–ø–∞–∫–æ–≤–∞—Ç—å –∞—Ä—Ö–∏–≤(—ã)")
        # print("5. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å DOC ‚Üí DOCX")
        # print("6. –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ–∞–π–ª(—ã)")
        # print("7. –°–æ–∑–¥–∞—Ç—å manifest")
        # print("8. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ PDF –Ω–∞ text_pdf –∏ scan_pdf")
        # print("9. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí HTML/XML")
        # print("10. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ (–ø–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω)")
        
        print("\n=== –ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê (PENDING) - –ü–û–®–ê–ì–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===")
        print("3. –®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤")
        print("4. –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
        print("5. –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        print("6. –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units")
        print("7. –®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º")
        print("8. –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (3-7)")
        
        print("\n=== –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ü–†–û–°–ú–û–¢–† ===")
        print("9. –ü—Ä–æ—Å–º–æ—Ç—Ä pending —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
        print("10. –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º (+ mixed units)")
        print("11. –û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units")
        
        print("\n=== MERGE –í READY_DOCLING ===")
        print("12. Merge (DRY RUN)")
        print("13. Merge (–†–ï–ê–õ–¨–ù–´–ô)")
        
        print("\n=== –°–õ–£–ñ–ï–ë–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò ===")
        print("14. –ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
        print("15. –ü—Ä–æ—Å–º–æ—Ç—Ä –º–µ—Ç—Ä–∏–∫")
        print("16. –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–∏–º–∏—Ç–æ–≤")
        print("17. –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π")
        print("18. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units")
        print("19. –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤")
        
        print("\n0. –í—ã—Ö–æ–¥")
        print("\n" + "-" * 50)
    
    def handle_sync_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB."""
        print("\n=== –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB...")
        remote_client = get_remote_mongo_client()
        if not remote_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ .env:")
            print("    - mongoServer –∏–ª–∏ MONGO_SERVER")
            print("    - readAllUser –∏–ª–∏ MONGO_USER")
            print("    - readAllPassword –∏–ª–∏ MONGO_PASSWORD")
            print("    - sslCertPath –∏–ª–∏ MONGO_SSL_CERT")
            return
        
        remote_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB
        print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB...")
        local_client = get_local_mongo_client()
        if not local_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            print("    - LOCAL_MONGO_SERVER (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: localhost:27017)")
            print("    - MONGO_METADATA_USER")
            print("    - MONGO_METADATA_PASSWORD")
            return
        
        local_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –í—ã–±–æ—Ä –¥–∞—Ç—ã
        print("\n3. –í—ã–±–æ—Ä –¥–∞—Ç—ã –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:")
        print("  1. –í—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
        print("  2. –£–∫–∞–∑–∞—Ç—å –¥–∞—Ç—É –≤—Ä—É—á–Ω—É—é (YYYY-MM-DD)")
        choice = input("  –í—ã–±–µ—Ä–∏—Ç–µ [1-2] –∏–ª–∏ Enter –¥–ª—è –≤—á–µ—Ä–∞—à–Ω–µ–≥–æ –¥–Ω—è: ").strip()
        
        target_date = None
        if choice == "2":
            date_str = input("  –í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É (YYYY-MM-DD): ").strip()
            try:
                target_date = datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                print(f"‚úó –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}")
                return
        else:
            target_date = datetime.utcnow() - timedelta(days=1)
        
        # –õ–∏–º–∏—Ç
        limit_str = input(f"\n4. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        # –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        print(f"\n5. –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
        print(f"   –î–∞—Ç–∞: {target_date.date()}")
        print(f"   –õ–∏–º–∏—Ç: {limit}")
        
        result = sync_protocols_for_date(target_date, limit)
        
        if result.get("status") == "success":
            print("\n‚úì –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            print(f"   –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {result.get('scanned', 0)}")
            print(f"   –í—Å—Ç–∞–≤–ª–µ–Ω–æ: {result.get('inserted', 0)}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {result.get('skipped_existing', 0)}")
            if result.get("errors_count", 0) > 0:
                print(f"   –û—à–∏–±–æ–∫: {result.get('errors_count', 0)}")
        else:
            print(f"\n‚úó –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {result.get('message', 'Unknown error')}")
    
    def handle_download_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB —á–µ—Ä–µ–∑ VPN."""
        print("\n=== –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB (—Å VPN) ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ VPN –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ zakupki.gov.ru —á–µ—Ä–µ–∑ VPN...")
        if not check_zakupki_health():
            print("‚úó zakupki.gov.ru –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç VPN / –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)")
            print("  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ VPN –Ω–∞—Å—Ç—Ä–æ–µ–Ω —á–µ—Ä–µ–∑ route-up-zakupki.sh")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ OpenVPN —Ç—É–Ω–Ω–µ–ª—å –∞–∫—Ç–∏–≤–µ–Ω")
            return
        
        print("‚úì zakupki.gov.ru –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ VPN")
        
        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input(f"\n2. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/units –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        if limit <= 0:
            print("‚úó –õ–∏–º–∏—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return
        
        # –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        print(f"\n3. –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤...")
        print(f"   –õ–∏–º–∏—Ç: {limit} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {INPUT_DIR.absolute()}")
        
        try:
            downloader = ProtocolDownloader(output_dir=INPUT_DIR)
            start_time = time.time()
            result = downloader.process_pending_protocols(limit=limit)
            duration = time.time() - start_time
            
            if result.get("health_ok"):
                print("\n" + "=" * 80)
                print("‚úì –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
                print("=" * 80)
                print(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result.get('processed_ok', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –û—à–∏–±–æ–∫: {result.get('processed_error', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.get('downloaded_files_count', 0)}")
                print(f"  –û—à–∏–±–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {result.get('failed_files_count', 0)}")
                print(f"  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
                if result.get('processed_ok', 0) > 0:
                    avg_time = duration / result.get('processed_ok', 1)
                    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª: {avg_time:.2f} —Å–µ–∫")
            else:
                print("\n‚úó –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å VPN")
                
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_detect_type(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤ (–ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)."""
        print("\n=== –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ (–Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤) ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_DETECT_TYPE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_DETECT_TYPE
        
        print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ input/ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–§–∞–π–ª—ã –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞/—é–Ω–∏—Ç–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ –∏ –Ω–µ —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è.")
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
            from services.router.unit_distribution import distribute_unit_by_types
            from services.router.mongo import save_file_detection_metadata, save_unit_distribution_metadata
            from services.router.config import INPUT_DIR, ensure_directories
            from pathlib import Path
            import time
            from collections import defaultdict
            
            ensure_directories()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit > 0:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = {
                "processed_units": 0,
                "processed_files": 0,
                "mixed_units": 0,
                "duplicates_found": 0,
                "extension_mismatches": 0,
                "errors": 0,
                "file_types": defaultdict(int),
                "target_dirs": defaultdict(int),
                "unprocessed_units": [],  # Units –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏
                "extension_mismatch_details": []  # –î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            }
            
            start_time = time.time()
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units –±–µ–∑ —Ñ–∞–π–ª–æ–≤
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "no_files",
                        "message": "Unit –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–∞–π–ª–æ–≤"
                    })
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª(–æ–≤))...", end=" ", flush=True)
                
                try:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
                    files_list = [{"path": str(f)} for f in files]
                    
                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º unit
                    distribution_result = distribute_unit_by_types(
                        unit_id=unit_id,
                        files=files_list,
                        unit_metadata=None
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    for file_info in distribution_result["files"]:
                        try:
                            save_file_detection_metadata(
                                file_path=file_info["path"],
                                file_info=file_info,
                                unit_id=unit_id,
                                protocol_info=None
                            )
                        except Exception:
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MongoDB
                    
                    try:
                        save_unit_distribution_metadata(unit_id, distribution_result)
                    except Exception:
                        pass
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    stats["processed_units"] += 1
                    stats["processed_files"] += len(distribution_result["files"])
                    
                    if distribution_result["is_mixed"]:
                        stats["mixed_units"] += 1
                    
                    if distribution_result["duplicates_detected"]:
                        stats["duplicates_found"] += 1
                    
                    extension_mismatches = len(distribution_result["distribution_details"].get("extension_mismatches", []))
                    stats["extension_mismatches"] += extension_mismatches
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
                    for file_info in distribution_result["files"]:
                        if not file_info.get("extension_matches_content", True):
                            mismatch_detail = {
                                "unit_id": unit_id,
                                "file_name": file_info.get("original_name", "unknown"),
                                "extension": file_info.get("extension", "unknown"),
                                "expected_type": file_info.get("extension", "").replace(".", ""),
                                "detected_type": file_info.get("detected_type", "unknown"),
                                "mime_type": file_info.get("mime_type", "unknown")
                            }
                            stats["extension_mismatch_details"].append(mismatch_detail)
                    
                    for file_type in distribution_result["file_types"]:
                        stats["file_types"][file_type] += 1
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    target_dir = Path(distribution_result["target_dir"])
                    if "mixed" in str(target_dir):
                        stats["target_dirs"]["mixed"] += 1
                    else:
                        parent_name = target_dir.parent.name if target_dir.parent.name != "detected" else target_dir.name
                        stats["target_dirs"][parent_name] += 1
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    status_icon = "üîÄ" if distribution_result["is_mixed"] else "‚úì"
                    print(f"{status_icon} {', '.join(distribution_result['file_types'])}")
                
                except Exception as e:
                    stats["errors"] += 1
                    error_msg = str(e)
                    print(f"‚úó –û—à–∏–±–∫–∞: {error_msg[:50]}")
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units —Å –æ—à–∏–±–∫–∞–º–∏
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "error",
                        "message": error_msg,
                        "error_type": type(e).__name__
                    })
            
            duration = time.time() - start_time
            
            # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\n{'='*80}")
            print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ unit'–æ–≤: {stats['processed_units']}/{len(unit_dirs)}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {stats['processed_files']}")
            print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
            if stats['processed_units'] > 0:
                print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ unit: {duration/stats['processed_units']:.2f} —Å–µ–∫")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
            for file_type, count in sorted(stats['file_types'].items()):
                print(f"  {file_type}: {count}")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º:")
            for target_dir, count in sorted(stats['target_dirs'].items()):
                print(f"  {target_dir}: {count} unit'–æ–≤")
            
            print(f"\n–û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏:")
            print(f"  Mixed units: {stats['mixed_units']}")
            print(f"  –î—É–±–ª–∏–∫–∞—Ç—ã: {stats['duplicates_found']} unit'–æ–≤")
            print(f"  –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {stats['extension_mismatches']}")
            print(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö units
            unprocessed_count = len(stats.get("unprocessed_units", []))
            if unprocessed_count > 0:
                print(f"\n–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ units: {unprocessed_count}")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º
                by_reason = defaultdict(list)
                for unit in stats["unprocessed_units"]:
                    by_reason[unit["reason"]].append(unit)
                
                for reason, units in sorted(by_reason.items()):
                    reason_name = {
                        "no_files": "–ë–µ–∑ —Ñ–∞–π–ª–æ–≤",
                        "error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
                    }.get(reason, reason)
                    print(f"  {reason_name}: {len(units)} unit'–æ–≤")
                    if len(units) <= 10:
                        for unit_info in units:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                    else:
                        for unit_info in units[:5]:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                        print(f"    ... –∏ –µ—â–µ {len(units) - 5} unit'–æ–≤")
            
            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            if stats.get("extension_mismatch_details"):
                print(f"\n–î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π:")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                mismatch_groups = defaultdict(int)
                for detail in stats["extension_mismatch_details"]:
                    key = f"{detail['extension']} ‚Üí {detail['detected_type']}"
                    mismatch_groups[key] += 1
                
                for mismatch_type, count in sorted(mismatch_groups.items(), key=lambda x: x[1], reverse=True):
                    print(f"  {mismatch_type}: {count}")
            
            print(f"{'='*80}\n")
        
        except ImportError as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}")
            print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_extract_archive(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤."""
        print("\n=== –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_EXTRACT_ARCHIVE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_EXTRACT_ARCHIVE
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/extract_archive")
    
    
    def handle_normalize(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_NORMALIZE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_NORMALIZE
        
        print(f"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/normalize")
    
    def handle_create_manifest(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è manifest."""
        print("\n=== –°–æ–∑–¥–∞–Ω–∏–µ manifest ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_CREATE_MANIFEST}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_CREATE_MANIFEST
        
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ manifest —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/create_manifest")
    
    def show_statistics(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç—Ç–∞–ø–∞–º."""
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç—Ç–∞–ø–∞–º ===")
        stats = self.state_manager.get_statistics()
        
        print(f"\n–≠—Ç–∞–ø 1 (uploaded):     {len(list(INPUT_DIR.iterdir()))} —Ñ–∞–π–ª–æ–≤ –≤ input/")
        print(f"–≠—Ç–∞–ø 2 (detected):     {stats['detected']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"  –ü–æ —Ç–∏–ø–∞–º: {stats['detected']['by_type']}")
        print(f"–≠—Ç–∞–ø 3 (extracted):    {stats['extracted']['count']} —Ñ–∞–π–ª–æ–≤ (–∏–∑ {stats['extracted']['archives_processed']} –∞—Ä—Ö–∏–≤–æ–≤)")
        print(f"–≠—Ç–∞–ø 4 (converted):    {stats['converted']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"–≠—Ç–∞–ø 5 (normalized):   {stats['normalized']['count']} unit'–æ–≤")
        print(f"–≠—Ç–∞–ø 6 (ready):        {stats['ready']['count']} unit'–æ–≤ –≥–æ—Ç–æ–≤—ã –¥–ª—è Docling")
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        limits = get_limits()
        for stage, limit in limits.items():
            print(f"  {stage}: {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}")
    
    def show_metrics(self, stage: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        metrics = get_processing_summary()
        
        if not metrics:
            print("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        summary = metrics.get("summary", {})
        print(f"\n–°–µ—Å—Å–∏—è: {metrics.get('session_id', 'N/A')}")
        print(f"–ù–∞—á–∞–ª–æ: {metrics.get('started_at', 'N/A')}")
        print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: {metrics.get('completed_at', 'N/A')}")
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {summary.get('total_input_files', 0)}")
        print(f"  –í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {summary.get('total_archives', 0)}")
        print(f"  –í—Å–µ–≥–æ unit'–æ–≤: {summary.get('total_units', 0)}")
        print(f"  –û—à–∏–±–æ–∫: {summary.get('total_errors', 0)}")
    
    def show_logs(self, filter_by: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–≥–∏."""
        print("\n=== –õ–æ–≥–∏ ===")
        print("–õ–æ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ API endpoint: GET /metrics/processing")
        print("–ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å–µ—Ä–≤–∏—Å–∞ router")
    
    def configure_limits(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        limits = get_limits()
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        print("1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞:     ", limits.get("detect_type", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("2. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤:   ", limits.get("extract_archive", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC:      ", limits.get("convert_doc", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:         ", limits.get("normalize", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("5. –°–æ–∑–¥–∞–Ω–∏–µ manifest:    ", limits.get("create_manifest", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        
        choice = input("\n–ò–∑–º–µ–Ω–∏—Ç—å –ª–∏–º–∏—Ç [1-5] –∏–ª–∏ 0 –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞: ").strip()
        
        if choice == "0":
            return
        
        stage_map = {
            "1": "detect_type",
            "2": "extract_archive",
            "3": "convert_doc",
            "4": "normalize",
            "5": "create_manifest"
        }
        
        if choice in stage_map:
            stage = stage_map[choice]
            new_limit = input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            try:
                limit_value = int(new_limit)
                if update_limit(stage, limit_value):
                    print(f"–õ–∏–º–∏—Ç –¥–ª—è {stage} –æ–±–Ω–æ–≤–ª–µ–Ω: {limit_value}")
                else:
                    print("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞")
            except ValueError:
                print("–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ")
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
    
    def run_full_pipeline(self, limits: Optional[Dict[str, int]] = None):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞."""
        print("\n=== –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===")
        print("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ input/")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /process_now")
        print("–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç")
    
    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª CLI."""
        while True:
            try:
                self.show_menu()
                choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ [0-18]: ").strip()
                
                if choice == "0":
                    print("–í—ã—Ö–æ–¥...")
                    break
                elif choice == "1":
                    self.handle_download_protocols()
                elif choice == "2":
                    self.handle_detect_type()
                elif choice == "3":
                    self.handle_extract_archive()
                elif choice == "4":
                    self.handle_convert_doc()
                elif choice == "5":
                    self.handle_normalize()
                elif choice == "6":
                    self.handle_create_manifest()
                elif choice == "7":
                    self.show_statistics()
                elif choice == "8":
                    self.show_metrics()
                elif choice == "9":
                    self.show_logs()
                elif choice == "10":
                    self.configure_limits()
                elif choice == "11":
                    self.run_full_pipeline()
                else:
                    print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
            
            except KeyboardInterrupt:
                print("\n\n–í—ã—Ö–æ–¥...")
                break
            except Exception as e:
                print(f"\n–û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")


    def handle_sync_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB."""
        print("\n=== –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB...")
        remote_client = get_remote_mongo_client()
        if not remote_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ .env:")
            print("    - mongoServer –∏–ª–∏ MONGO_SERVER")
            print("    - readAllUser –∏–ª–∏ MONGO_USER")
            print("    - readAllPassword –∏–ª–∏ MONGO_PASSWORD")
            print("    - sslCertPath –∏–ª–∏ MONGO_SSL_CERT")
            return
        
        remote_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB
        print("\n2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB...")
        local_client = get_local_mongo_client()
        if not local_client:
            print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏:")
            print("    - LOCAL_MONGO_SERVER (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: localhost:27017)")
            print("    - MONGO_METADATA_USER")
            print("    - MONGO_METADATA_PASSWORD")
            return
        
        local_client.close()
        print("‚úì –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB —É—Å–ø–µ—à–Ω–æ")
        
        # –í—ã–±–æ—Ä –¥–∞—Ç—ã
        print("\n3. –í—ã–±–æ—Ä –¥–∞—Ç—ã –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:")
        print("  1. –í—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
        print("  2. –£–∫–∞–∑–∞—Ç—å –¥–∞—Ç—É –≤—Ä—É—á–Ω—É—é (YYYY-MM-DD)")
        choice = input("  –í—ã–±–µ—Ä–∏—Ç–µ [1-2] –∏–ª–∏ Enter –¥–ª—è –≤—á–µ—Ä–∞—à–Ω–µ–≥–æ –¥–Ω—è: ").strip()
        
        target_date = None
        if choice == "2":
            date_str = input("  –í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É (YYYY-MM-DD): ").strip()
            try:
                target_date = datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                print(f"‚úó –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}")
                return
        else:
            target_date = datetime.utcnow() - timedelta(days=1)
        
        # –õ–∏–º–∏—Ç
        limit_str = input(f"\n4. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        # –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        print(f"\n5. –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
        print(f"   –î–∞—Ç–∞: {target_date.date()}")
        print(f"   –õ–∏–º–∏—Ç: {limit}")
        
        result = sync_protocols_for_date(target_date, limit)
        
        if result.get("status") == "success":
            print("\n‚úì –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
            print(f"   –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {result.get('scanned', 0)}")
            print(f"   –í—Å—Ç–∞–≤–ª–µ–Ω–æ: {result.get('inserted', 0)}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {result.get('skipped_existing', 0)}")
            if result.get("errors_count", 0) > 0:
                print(f"   –û—à–∏–±–æ–∫: {result.get('errors_count', 0)}")
        else:
            print(f"\n‚úó –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {result.get('message', 'Unknown error')}")
    
    
    def handle_download_protocols(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB —á–µ—Ä–µ–∑ VPN."""
        print("\n=== –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB (—Å VPN) ===")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ VPN –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ zakupki.gov.ru —á–µ—Ä–µ–∑ VPN...")
        if not check_zakupki_health():
            print("‚úó zakupki.gov.ru –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç VPN / –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)")
            print("  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ VPN –Ω–∞—Å—Ç—Ä–æ–µ–Ω —á–µ—Ä–µ–∑ route-up-zakupki.sh")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ OpenVPN —Ç—É–Ω–Ω–µ–ª—å –∞–∫—Ç–∏–≤–µ–Ω")
            return
        
        print("‚úì zakupki.gov.ru –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ VPN")
        
        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input(f"\n2. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/units –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200
        
        if limit <= 0:
            print("‚úó –õ–∏–º–∏—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return
        
        # –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        print(f"\n3. –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤...")
        print(f"   –õ–∏–º–∏—Ç: {limit} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {INPUT_DIR.absolute()}")
        
        try:
            downloader = ProtocolDownloader(output_dir=INPUT_DIR)
            start_time = time.time()
            result = downloader.process_pending_protocols(limit=limit)
            duration = time.time() - start_time
            
            if result.get("health_ok"):
                print("\n" + "=" * 80)
                print("‚úì –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
                print("=" * 80)
                print(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result.get('processed_ok', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –û—à–∏–±–æ–∫: {result.get('processed_error', 0)} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
                print(f"  –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.get('downloaded_files_count', 0)}")
                print(f"  –û—à–∏–±–æ–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤: {result.get('failed_files_count', 0)}")
                print(f"  –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
                if result.get('processed_ok', 0) > 0:
                    avg_time = duration / result.get('processed_ok', 1)
                    print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª: {avg_time:.2f} —Å–µ–∫")
            else:
                print("\n‚úó –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å VPN")
                
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_detect_type(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤ (–ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤)."""
        print("\n=== –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞ (–Ω–∞ —É—Ä–æ–≤–Ω–µ unit'–æ–≤) ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_DETECT_TYPE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_DETECT_TYPE
        
        print(f"\n–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∏–∑ input/ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–§–∞–π–ª—ã –æ–¥–Ω–æ–≥–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞/—é–Ω–∏—Ç–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –≤–º–µ—Å—Ç–µ –∏ –Ω–µ —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è.")
        
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–æ–¥—É–ª–∏
            from services.router.unit_distribution import distribute_unit_by_types
            from services.router.mongo import save_file_detection_metadata, save_unit_distribution_metadata
            from services.router.config import INPUT_DIR, ensure_directories
            from pathlib import Path
            import time
            from collections import defaultdict
            
            ensure_directories()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit > 0:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = {
                "processed_units": 0,
                "processed_files": 0,
                "mixed_units": 0,
                "duplicates_found": 0,
                "extension_mismatches": 0,
                "errors": 0,
                "file_types": defaultdict(int),
                "target_dirs": defaultdict(int),
                "unprocessed_units": [],  # Units –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –±—ã–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã —Å –ø—Ä–∏—á–∏–Ω–∞–º–∏
                "extension_mismatch_details": []  # –î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            }
            
            start_time = time.time()
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units –±–µ–∑ —Ñ–∞–π–ª–æ–≤
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "no_files",
                        "message": "Unit –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ–∞–π–ª–æ–≤"
                    })
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª(–æ–≤))...", end=" ", flush=True)
                
                try:
                    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤
                    files_list = [{"path": str(f)} for f in files]
                    
                    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º unit
                    distribution_result = distribute_unit_by_types(
                        unit_id=unit_id,
                        files=files_list,
                        unit_metadata=None
                    )
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                    for file_info in distribution_result["files"]:
                        try:
                            save_file_detection_metadata(
                                file_path=file_info["path"],
                                file_info=file_info,
                                unit_id=unit_id,
                                protocol_info=None
                            )
                        except Exception:
                            pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ MongoDB
                    
                    try:
                        save_unit_distribution_metadata(unit_id, distribution_result)
                    except Exception:
                        pass
                    
                    # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                    stats["processed_units"] += 1
                    stats["processed_files"] += len(distribution_result["files"])
                    
                    if distribution_result["is_mixed"]:
                        stats["mixed_units"] += 1
                    
                    if distribution_result["duplicates_detected"]:
                        stats["duplicates_found"] += 1
                    
                    extension_mismatches = len(distribution_result["distribution_details"].get("extension_mismatches", []))
                    stats["extension_mismatches"] += extension_mismatches
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
                    for file_info in distribution_result["files"]:
                        if not file_info.get("extension_matches_content", True):
                            mismatch_detail = {
                                "unit_id": unit_id,
                                "file_name": file_info.get("original_name", "unknown"),
                                "extension": file_info.get("extension", "unknown"),
                                "expected_type": file_info.get("extension", "").replace(".", ""),
                                "detected_type": file_info.get("detected_type", "unknown"),
                                "mime_type": file_info.get("mime_type", "unknown")
                            }
                            stats["extension_mismatch_details"].append(mismatch_detail)
                    
                    for file_type in distribution_result["file_types"]:
                        stats["file_types"][file_type] += 1
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    target_dir = Path(distribution_result["target_dir"])
                    if "mixed" in str(target_dir):
                        stats["target_dirs"]["mixed"] += 1
                    else:
                        parent_name = target_dir.parent.name if target_dir.parent.name != "detected" else target_dir.name
                        stats["target_dirs"][parent_name] += 1
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    status_icon = "üîÄ" if distribution_result["is_mixed"] else "‚úì"
                    print(f"{status_icon} {', '.join(distribution_result['file_types'])}")
                
                except Exception as e:
                    stats["errors"] += 1
                    error_msg = str(e)
                    print(f"‚úó –û—à–∏–±–∫–∞: {error_msg[:50]}")
                    # –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ–º units —Å –æ—à–∏–±–∫–∞–º–∏
                    stats["unprocessed_units"].append({
                        "unit_id": unit_id,
                        "reason": "error",
                        "message": error_msg,
                        "error_type": type(e).__name__
                    })
            
            duration = time.time() - start_time
            
            # –í—ã–≤–æ–¥–∏–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\n{'='*80}")
            print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–ë–†–ê–ë–û–¢–ö–ò")
            print(f"{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ unit'–æ–≤: {stats['processed_units']}/{len(unit_dirs)}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {stats['processed_files']}")
            print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {duration:.2f} —Å–µ–∫")
            if stats['processed_units'] > 0:
                print(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ unit: {duration/stats['processed_units']:.2f} —Å–µ–∫")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º:")
            for file_type, count in sorted(stats['file_types'].items()):
                print(f"  {file_type}: {count}")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º:")
            for target_dir, count in sorted(stats['target_dirs'].items()):
                print(f"  {target_dir}: {count} unit'–æ–≤")
            
            print(f"\n–û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏:")
            print(f"  Mixed units: {stats['mixed_units']}")
            print(f"  –î—É–±–ª–∏–∫–∞—Ç—ã: {stats['duplicates_found']} unit'–æ–≤")
            print(f"  –ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {stats['extension_mismatches']}")
            print(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
            
            # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö units
            unprocessed_count = len(stats.get("unprocessed_units", []))
            if unprocessed_count > 0:
                print(f"\n–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ units: {unprocessed_count}")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –ø—Ä–∏—á–∏–Ω–∞–º
                by_reason = defaultdict(list)
                for unit in stats["unprocessed_units"]:
                    by_reason[unit["reason"]].append(unit)
                
                for reason, units in sorted(by_reason.items()):
                    reason_name = {
                        "no_files": "–ë–µ–∑ —Ñ–∞–π–ª–æ–≤",
                        "error": "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏"
                    }.get(reason, reason)
                    print(f"  {reason_name}: {len(units)} unit'–æ–≤")
                    if len(units) <= 10:
                        for unit_info in units:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                    else:
                        for unit_info in units[:5]:
                            uid = unit_info["unit_id"]
                            diagnosis = unit_info.get("diagnosis", {})
                            if diagnosis:
                                reasons = diagnosis.get("possible_reasons", [])
                                if reasons:
                                    print(f"    - {uid}: {reasons[0]}")
                                else:
                                    print(f"    - {uid}")
                            else:
                                print(f"    - {uid}")
                        print(f"    ... –∏ –µ—â–µ {len(units) - 5} unit'–æ–≤")
            
            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π
            if stats.get("extension_mismatch_details"):
                print(f"\n–î–µ—Ç–∞–ª–∏ –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π:")
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ç–∏–ø–∞–º –Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π
                mismatch_groups = defaultdict(int)
                for detail in stats["extension_mismatch_details"]:
                    key = f"{detail['extension']} ‚Üí {detail['detected_type']}"
                    mismatch_groups[key] += 1
                
                for mismatch_type, count in sorted(mismatch_groups.items(), key=lambda x: x[1], reverse=True):
                    print(f"  {mismatch_type}: {count}")
            
            print(f"{'='*80}\n")
        
        except ImportError as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –º–æ–¥—É–ª–µ–π: {e}")
            print("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã.")
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_extract_archive(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤."""
        print("\n=== –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_EXTRACT_ARCHIVE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_EXTRACT_ARCHIVE
        
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/extract_archive")
    
    
    def handle_normalize(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_NORMALIZE}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_NORMALIZE
        
        print(f"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/normalize")
    
    def handle_create_manifest(self, limit: Optional[int] = None):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è manifest."""
        print("\n=== –°–æ–∑–¥–∞–Ω–∏–µ manifest ===")
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (0 = –≤—Å–µ, —Ç–µ–∫—É—â–∏–π: {LIMIT_CREATE_MANIFEST}): ").strip()
            limit = int(limit_str) if limit_str else LIMIT_CREATE_MANIFEST
        
        print(f"–°–æ–∑–¥–∞–Ω–∏–µ manifest —Å –ª–∏–º–∏—Ç–æ–º {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}...")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /trigger/create_manifest")
    
    def show_statistics(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —ç—Ç–∞–ø–∞–º."""
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —ç—Ç–∞–ø–∞–º ===")
        stats = self.state_manager.get_statistics()
        
        print(f"\n–≠—Ç–∞–ø 1 (uploaded):     {len(list(INPUT_DIR.iterdir()))} —Ñ–∞–π–ª–æ–≤ –≤ input/")
        print(f"–≠—Ç–∞–ø 2 (detected):     {stats['detected']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"  –ü–æ —Ç–∏–ø–∞–º: {stats['detected']['by_type']}")
        print(f"–≠—Ç–∞–ø 3 (extracted):    {stats['extracted']['count']} —Ñ–∞–π–ª–æ–≤ (–∏–∑ {stats['extracted']['archives_processed']} –∞—Ä—Ö–∏–≤–æ–≤)")
        print(f"–≠—Ç–∞–ø 4 (converted):    {stats['converted']['count']} —Ñ–∞–π–ª–æ–≤")
        print(f"–≠—Ç–∞–ø 5 (normalized):   {stats['normalized']['count']} unit'–æ–≤")
        print(f"–≠—Ç–∞–ø 6 (ready):        {stats['ready']['count']} unit'–æ–≤ –≥–æ—Ç–æ–≤—ã –¥–ª—è Docling")
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        limits = get_limits()
        for stage, limit in limits.items():
            print(f"  {stage}: {limit if limit > 0 else '–±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π'}")
    
    def show_metrics(self, stage: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        metrics = get_processing_summary()
        
        if not metrics:
            print("–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return
        
        summary = metrics.get("summary", {})
        print(f"\n–°–µ—Å—Å–∏—è: {metrics.get('session_id', 'N/A')}")
        print(f"–ù–∞—á–∞–ª–æ: {metrics.get('started_at', 'N/A')}")
        print(f"–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: {metrics.get('completed_at', 'N/A')}")
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {summary.get('total_input_files', 0)}")
        print(f"  –í—Å–µ–≥–æ –∞—Ä—Ö–∏–≤–æ–≤: {summary.get('total_archives', 0)}")
        print(f"  –í—Å–µ–≥–æ unit'–æ–≤: {summary.get('total_units', 0)}")
        print(f"  –û—à–∏–±–æ–∫: {summary.get('total_errors', 0)}")
    
    def show_logs(self, filter_by: Optional[str] = None):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –ª–æ–≥–∏."""
        print("\n=== –õ–æ–≥–∏ ===")
        print("–õ–æ–≥–∏ –¥–æ—Å—Ç—É–ø–Ω—ã —á–µ—Ä–µ–∑ API endpoint: GET /metrics/processing")
        print("–ò–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ —Å–µ—Ä–≤–∏—Å–∞ router")
    
    def configure_limits(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–∏–º–∏—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ===")
        limits = get_limits()
        
        print("\n–¢–µ–∫—É—â–∏–µ –ª–∏–º–∏—Ç—ã:")
        print("1. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞:     ", limits.get("detect_type", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("2. –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤:   ", limits.get("extract_archive", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("3. –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC:      ", limits.get("convert_doc", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("4. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è:         ", limits.get("normalize", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        print("5. –°–æ–∑–¥–∞–Ω–∏–µ manifest:    ", limits.get("create_manifest", 0), "(0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π)")
        
        choice = input("\n–ò–∑–º–µ–Ω–∏—Ç—å –ª–∏–º–∏—Ç [1-5] –∏–ª–∏ 0 –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞: ").strip()
        
        if choice == "0":
            return
        
        stage_map = {
            "1": "detect_type",
            "2": "extract_archive",
            "3": "convert_doc",
            "4": "normalize",
            "5": "create_manifest"
        }
        
        if choice in stage_map:
            stage = stage_map[choice]
            new_limit = input(f"–í–≤–µ–¥–∏—Ç–µ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (0 = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            try:
                limit_value = int(new_limit)
                if update_limit(stage, limit_value):
                    print(f"–õ–∏–º–∏—Ç –¥–ª—è {stage} –æ–±–Ω–æ–≤–ª–µ–Ω: {limit_value}")
                else:
                    print("–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞")
            except ValueError:
                print("–ù–µ–≤–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ")
        else:
            print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä")
    
    def run_full_pipeline(self, limits: Optional[Dict[str, int]] = None):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞."""
        print("\n=== –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ ===")
        print("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –∏–∑ input/")
        print("–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ API endpoint: POST /process_now")
        print("–ò–ª–∏ –∑–∞–ø—É—Å—Ç–∏—Ç–µ —á–µ—Ä–µ–∑ API –∫–ª–∏–µ–Ω—Ç")
    
    def handle_cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MongoDB."""
        print("\n=== –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MongoDB ===")
        print("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è —É–¥–∞–ª–∏—Ç:")
        print("  - –í—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê)")
        print("  - –í—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–ª–ª–µ–∫—Ü–∏–π MongoDB")
        print("\n–î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏:")
        print(f"  - {INPUT_DIR}")
        print(f"  - {PENDING_DIR}")
        print(f"  - {READY_DOCLING_DIR}")
        print(f"  - {TEMP_DIR}")
        print("\n–ö–æ–ª–ª–µ–∫—Ü–∏–∏ MongoDB –¥–ª—è –æ—á–∏—Å—Ç–∫–∏:")
        print(f"  - {MONGO_METADATA_DB}.protocols")
        print(f"  - {MONGO_METADATA_DB}.file_detections")
        print(f"  - {MONGO_METADATA_DB}.unit_distributions")
        print(f"  - {MONGO_METADATA_DB}.{MONGO_METADATA_COLLECTION}")
        print(f"  - {MONGO_METADATA_DB}.{MONGO_METRICS_COLLECTION}")
        
        confirm = input("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ—á–∏—Å—Ç–∫—É? (yes/no): ").strip().lower()
        if confirm != "yes":
            print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞.")
            return
        
        print("\n–ù–∞—á–∞–ª–æ –æ—á–∏—Å—Ç–∫–∏...")
        
        # –û—á–∏—Å—Ç–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        directories = [
            INPUT_DIR, PENDING_DIR, READY_DOCLING_DIR, TEMP_DIR
        ]
        
        dirs_cleaned = 0
        files_removed = 0
        
        for directory in directories:
            if not directory.exists():
                continue
            
            try:
                file_count = sum(1 for _ in directory.rglob("*") if _.is_file())
                files_removed += file_count
                
                for item in directory.iterdir():
                    if item.is_dir():
                        shutil.rmtree(item)
                    else:
                        item.unlink()
                
                dirs_cleaned += 1
                print(f"  ‚úì –û—á–∏—â–µ–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {directory.name} ({file_count} —Ñ–∞–π–ª–æ–≤)")
            except Exception as e:
                print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {directory.name}: {e}")
        
        # –û—á–∏—Å—Ç–∫–∞ MongoDB –∫–æ–ª–ª–µ–∫—Ü–∏–π
        client = None
        try:
            print("\n–û—á–∏—Å—Ç–∫–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π MongoDB...")
            client = get_metadata_client()
            if not client:
                print("  ‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ MongoDB")
            else:
                db = client[MONGO_METADATA_DB]
                collections_to_clean = [
                    ("protocols", "–ü—Ä–æ—Ç–æ–∫–æ–ª—ã"),
                    ("file_detections", "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–æ–≤"),
                    ("unit_distributions", "–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è unit'–æ–≤"),
                    (MONGO_METADATA_COLLECTION, "–ú–∞–Ω–∏—Ñ–µ—Å—Ç—ã"),
                    (MONGO_METRICS_COLLECTION, "–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏"),
                ]
                
                for coll_name, description in collections_to_clean:
                    try:
                        coll = db[coll_name]
                        count = coll.count_documents({})
                        if count > 0:
                            coll.delete_many({})
                            print(f"  ‚úì –û—á–∏—â–µ–Ω–∞ –∫–æ–ª–ª–µ–∫—Ü–∏—è {coll_name} ({description}): {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
                        else:
                            print(f"  - –ö–æ–ª–ª–µ–∫—Ü–∏—è {coll_name} —É–∂–µ –ø—É—Å—Ç–∞")
                    except Exception as e:
                        print(f"  ‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ {coll_name}: {e}")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–∏ –∫ MongoDB: {e}")
        finally:
            if client:
                client.close()
        
        print("\n" + "=" * 80)
        print("‚úì –û–ß–ò–°–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê")
        print("=" * 80)
        print(f"  –û—á–∏—â–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {dirs_cleaned}")
        print(f"  –£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {files_removed}")
        print("\n–í—Å–µ –¥–∞–Ω–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã. –ú–æ–∂–Ω–æ –Ω–∞—á–∏–Ω–∞—Ç—å –Ω–æ–≤—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏.")
    
    def handle_check_sorted_units(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units –ø–æ—Å–ª–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤."""
        print("\n=== –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units ===")
        
        try:
            import subprocess
            import sys
            from pathlib import Path
            
            script_path = Path(__file__).parent.parent.parent / "scripts" / "check_sorted_units.py"
            
            if not script_path.exists():
                print(f"‚úó –°–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {script_path}")
                return
            
            print("\n–ó–∞–ø—É—Å–∫ –ø—Ä–æ–≤–µ—Ä–∫–∏...")
            result = subprocess.run(
                [sys.executable, str(script_path)],
                capture_output=False,
                text=True
            )
            
            if result.returncode != 0:
                print("\n‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ")
            else:
                print("\n‚úì –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ: {e}")
            import traceback
            traceback.print_exc()
    
    
    def handle_analyze_detection_issues(self):
        """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–±–ª–µ–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ ===")
        
        session_id = input("ID —Å–µ—Å—Å–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (Enter = –ø–æ—Å–ª–µ–¥–Ω—è—è —Å–µ—Å—Å–∏—è): ").strip()
        session_id = session_id if session_id else None
        
        try:
            import subprocess
            import sys
            from pathlib import Path
            
            script_path = Path(__file__).parent.parent.parent / "scripts" / "analyze_detection_issues.py"
            
            if not script_path.exists():
                print(f"‚úó –°–∫—Ä–∏–ø—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω: {script_path}")
                return
            
            print("\n–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞...")
            cmd = [sys.executable, str(script_path)]
            if session_id:
                cmd.extend(["--session-id", session_id])
            
            result = subprocess.run(
                cmd,
                capture_output=False,
                text=True
            )
            
            if result.returncode != 0:
                print("\n‚ö† –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ")
            else:
                print("\n‚úì –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_convert_doc_to_html(self):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí HTML (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ detected/htmlDOC/)."""
        print("\n=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí HTML ===")
        
        html_doc_dir = DETECTED_DIR / "htmlDOC"
        if not html_doc_dir.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {html_doc_dir}")
            return
        
        from .html_processor import process_fake_doc_html
        
        unit_dirs = [d for d in html_doc_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
        if not unit_dirs:
            print("‚úì –ù–µ—Ç units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(unit_dirs)} units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed = 0
        errors = 0
        
        for unit_dir in unit_dirs:
            unit_id = unit_dir.name
            files_dir = unit_dir / "files"
            
            if not files_dir.exists():
                continue
            
            doc_files = list(files_dir.glob("*.doc"))
            for doc_file in doc_files:
                try:
                    new_path, metadata = process_fake_doc_html(doc_file, unit_id)
                    print(f"‚úì {doc_file.name} ‚Üí {new_path.name}")
                    processed += 1
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {doc_file.name}: {e}")
                    errors += 1
        
        print(f"\n‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}, –æ—à–∏–±–æ–∫: {errors}")
    
    def handle_convert_doc_to_xml(self):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí XML (–¥–ª—è —Ñ–∞–π–ª–æ–≤ –∏–∑ detected/xmlDOC/)."""
        print("\n=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DOC ‚Üí XML ===")
        
        xml_doc_dir = DETECTED_DIR / "xmlDOC"
        if not xml_doc_dir.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {xml_doc_dir}")
            return
        
        from .xml_processor import process_fake_doc_xml
        
        unit_dirs = [d for d in xml_doc_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
        if not unit_dirs:
            print("‚úì –ù–µ—Ç units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return
        
        print(f"\n–ù–∞–π–¥–µ–Ω–æ {len(unit_dirs)} units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        processed = 0
        errors = 0
        
        for unit_dir in unit_dirs:
            unit_id = unit_dir.name
            files_dir = unit_dir / "files"
            
            if not files_dir.exists():
                continue
            
            doc_files = list(files_dir.glob("*.doc"))
            for doc_file in doc_files:
                try:
                    new_path, metadata = process_fake_doc_xml(doc_file, unit_id)
                    print(f"‚úì {doc_file.name} ‚Üí {new_path.name}")
                    processed += 1
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {doc_file.name}: {e}")
                    errors += 1
        
        print(f"\n‚úì –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}, –æ—à–∏–±–æ–∫: {errors}")
    
    def handle_sort_pdf(self):
        """–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ PDF –Ω–∞ text_pdf –∏ scan_pdf."""
        print("\n=== –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ PDF –Ω–∞ text_pdf –∏ scan_pdf ===")
        
        limit_str = input("–õ–∏–º–∏—Ç units –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Enter = –≤—Å–µ): ").strip()
        limit = int(limit_str) if limit_str else None
        
        from .pdf_sorter import sort_pdf_units, cleanup_already_sorted_units
        
        try:
            result = sort_pdf_units(limit=limit)
            
            if result.get("success"):
                stats = result["statistics"]
                print(f"\n‚úì –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
                print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                print(f"  –í—Å–µ–≥–æ units: {stats['total_units']}")
                print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['processed_units']}")
                if stats.get('skipped_units', 0) > 0:
                    print(f"  –ü—Ä–æ–ø—É—â–µ–Ω–æ: {stats['skipped_units']}")
                print(f"  text_pdf: {stats['text_pdf_units']} ({stats['text_pdf_percentage']:.1f}%)")
                print(f"  scan_pdf: {stats['scan_pdf_units']} ({stats['scan_pdf_percentage']:.1f}%)")
                print(f"  –û—à–∏–±–æ–∫: {stats['errors']}")
                
                # –û—á–∏—â–∞–µ–º —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
                print(f"\n–û—á–∏—Å—Ç–∫–∞ —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units...")
                cleanup_result = cleanup_already_sorted_units()
                if cleanup_result.get("success"):
                    removed = cleanup_result.get("removed_count", 0)
                    if removed > 0:
                        print(f"  ‚úì –£–¥–∞–ª–µ–Ω–æ —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units: {removed}")
                    else:
                        print(f"  ‚úì –ù–µ—Ç —É–∂–µ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö units –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è")
                    if cleanup_result.get("errors"):
                        print(f"  ‚ö† –û—à–∏–±–æ–∫ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {len(cleanup_result['errors'])}")
                
                # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö units
                if stats.get('skipped_details'):
                    print(f"\n–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ units:")
                    by_reason = {}
                    for skipped in stats['skipped_details']:
                        reason = skipped.get('reason', 'unknown')
                        if reason not in by_reason:
                            by_reason[reason] = []
                        by_reason[reason].append(skipped['unit_id'])
                    
                    for reason, unit_ids in sorted(by_reason.items()):
                        reason_name = {
                            "no_files_dir": "–ë–µ–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ files/",
                            "no_pdf_files": "–ë–µ–∑ PDF —Ñ–∞–π–ª–æ–≤"
                        }.get(reason, reason)
                        print(f"  {reason_name}: {len(unit_ids)} unit'–æ–≤")
                        if len(unit_ids) <= 10:
                            for uid in unit_ids:
                                print(f"    - {uid}")
                        else:
                            for uid in unit_ids[:5]:
                                print(f"    - {uid}")
                            print(f"    ... –∏ –µ—â–µ {len(unit_ids) - 5} unit'–æ–≤")
            else:
                print(f"\n‚úó –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
        
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–µ: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_pending_directories(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        print("\n=== –ü—Ä–æ—Å–º–æ—Ç—Ä –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ===")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        pending_dirs = {
            "PENDING_NORMALIZE_DIR": PENDING_NORMALIZE_DIR,
            "PENDING_CONVERT_DIR": PENDING_CONVERT_DIR,
            "PENDING_EXTRACT_DIR": PENDING_EXTRACT_DIR
        }
        
        for dir_name, dir_path in pending_dirs.items():
            print(f"\n{dir_name}: {dir_path}")
            if not dir_path.exists():
                print("  ‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                continue
            
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ unit'–æ–≤
            unit_dirs = [d for d in dir_path.rglob("UNIT_*") if d.is_dir()]
            print(f"  –ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {len(unit_dirs)}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 unit'–æ–≤
            if unit_dirs:
                print("  –ü–µ—Ä–≤—ã–µ unit'—ã:")
                for unit_dir in sorted(unit_dirs)[:5]:
                    files_dir = unit_dir / "files"
                    if files_dir.exists():
                        files = [f for f in files_dir.iterdir() if f.is_file()]
                        print(f"    {unit_dir.name}: {len(files)} —Ñ–∞–π–ª–æ–≤")
                    else:
                        print(f"    {unit_dir.name}: –Ω–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ files/")
                
                if len(unit_dirs) > 5:
                    print(f"    ... –∏ –µ—â–µ {len(unit_dirs) - 5} unit'–æ–≤")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ ReadyDocling
        print(f"\nREADY_DOCLING_DIR: {READY_DOCLING_DIR}")
        if READY_DOCLING_DIR.exists():
            # –°—á–∏—Ç–∞–µ–º PDF —Ñ–∞–π–ª—ã
            text_pdf_dir = READY_DOCLING_DIR / "pdf" / "text"
            scan_pdf_dir = READY_DOCLING_DIR / "pdf" / "scan"
            
            text_units = []
            scan_units = []
            
            if text_pdf_dir.exists():
                text_units = [d for d in text_pdf_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            if scan_pdf_dir.exists():
                scan_units = [d for d in scan_pdf_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            
            print(f"  PDF —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º —Å–ª–æ–µ–º: {len(text_units)} unit'–æ–≤")
            print(f"  PDF —Å–∫–∞–Ω—ã (—Ç—Ä–µ–±—É—é—Ç OCR): {len(scan_units)} unit'–æ–≤")
            
            # –°—á–∏—Ç–∞–µ–º –¥—Ä—É–≥–∏–µ —Ç–∏–ø—ã —Ñ–∞–π–ª–æ–≤
            other_types = ["docx", "html", "excel", "rtf", "doc", "zip", "rar", "7z", "unknown", "signature"]
            for file_type in other_types:
                type_dir = READY_DOCLING_DIR / file_type
                if type_dir.exists():
                    units = [d for d in type_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
                    if units:
                        print(f"  {file_type.upper()}: {len(units)} unit'–æ–≤")
        else:
            print("  ‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
    
    def handle_detailed_metrics(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫."""
        print("\n=== –î–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ ===")
        
        try:
            from .metrics import get_current_metrics, get_processing_summary
            
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            current_metrics = get_current_metrics()
            if current_metrics:
                print("\n–¢–µ–∫—É—â–∞—è —Å–µ—Å—Å–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
                print(f"  Session ID: {current_metrics.get('session_id', 'N/A')}")
                started_at = current_metrics.get('started_at')
                if started_at:
                    print(f"  –ù–∞—á–∞–ª–æ: {started_at}")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
                pending_processing = current_metrics.get("pending_processing", {})
                if pending_processing:
                    print("\n  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
                    for stage, items in pending_processing.items():
                        print(f"    {stage}: {len(items)} —Ñ–∞–π–ª–æ–≤")
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
                duplicates = current_metrics.get("duplicates", [])
                if duplicates:
                    print(f"\n  –î—É–±–ª–∏–∫–∞—Ç—ã:")
                    print(f"    –ì—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")
                    total_dups = sum(d.get('duplicate_count', 0) for d in duplicates)
                    print(f"    –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {total_dups}")
            else:
                print("  –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            print("\n–ü–æ—Å–ª–µ–¥–Ω—è—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–∞—è —Å–µ—Å—Å–∏—è:")
            last_metrics = get_processing_summary()
            if last_metrics:
                print(f"  Session ID: {last_metrics.get('session_id', 'N/A')}")
                started_at = last_metrics.get('started_at')
                completed_at = last_metrics.get('completed_at')
                if started_at:
                    print(f"  –ù–∞—á–∞–ª–æ: {started_at}")
                if completed_at:
                    print(f"  –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ: {completed_at}")
                
                # Summary —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
                summary = last_metrics.get("summary", {})
                if summary:
                    print(f"\n  –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
                    print(f"    –í—Ö–æ–¥–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {summary.get('total_input_files', 0)}")
                    print(f"    –ê—Ä—Ö–∏–≤–æ–≤: {summary.get('total_archives', 0)}")
                    print(f"    –ò–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {summary.get('total_extracted', 0)}")
                    print(f"    Unit'–æ–≤: {summary.get('total_units', 0)}")
                    print(f"    –û—à–∏–±–æ–∫: {summary.get('total_errors', 0)}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
                    pending_stats = summary.get("pending_statistics", {})
                    if pending_stats:
                        print(f"\n  –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
                        print(f"    –í pending/normalize: {pending_stats.get('files_in_pending_normalize', 0)}")
                        print(f"    –í pending/convert: {pending_stats.get('files_in_pending_convert', 0)}")
                        print(f"    –í pending/extract: {pending_stats.get('files_in_pending_extract', 0)}")
                        print(f"    –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∏–∑ pending: {pending_stats.get('files_processed_from_pending', 0)}")
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
                    duplicate_stats = summary.get("duplicate_statistics", {})
                    if duplicate_stats:
                        print(f"\n  –î—É–±–ª–∏–∫–∞—Ç—ã:")
                        print(f"    –í—Å–µ–≥–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_stats.get('total_duplicate_files', 0)}")
                        print(f"    –ì—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {duplicate_stats.get('duplicate_groups_count', 0)}")
            else:
                print("  –ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫")
                
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –º–µ—Ç—Ä–∏–∫: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_force_cleanup(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π."""
        print("\n=== –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π ===")
        
        try:
            from .utils import cleanup_all_empty_unit_directories
            
            # –°–ø–∏—Å–æ–∫ –±–∞–∑–æ–≤—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
            base_directories = [
                PENDING_NORMALIZE_DIR,
                PENDING_CONVERT_DIR,
                PENDING_EXTRACT_DIR,
                DETECTED_DIR,
                EXTRACTED_DIR,
                CONVERTED_DIR,
                NORMALIZED_DIR
            ]
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö unit'–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏
            unit_ids = set()
            for base_dir in base_directories:
                if base_dir.exists():
                    for unit_dir in base_dir.rglob("UNIT_*"):
                        if unit_dir.is_dir():
                            unit_ids.add(unit_dir.name)
            
            print(f"–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {len(unit_ids)}")
            
            if not unit_ids:
                print("–ù–µ—Ç unit'–æ–≤ –¥–ª—è –æ—á–∏—Å—Ç–∫–∏")
                return
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            confirm = input(f"–í—ã–ø–æ–ª–Ω–∏—Ç—å –æ—á–∏—Å—Ç–∫—É –ø—É—Å—Ç—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è {len(unit_ids)} unit'–æ–≤? (y/N): ").strip().lower()
            if confirm != 'y':
                print("–û—á–∏—Å—Ç–∫–∞ –æ—Ç–º–µ–Ω–µ–Ω–∞")
                return
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –æ—á–∏—Å—Ç–∫—É –¥–ª—è –∫–∞–∂–¥–æ–≥–æ unit'–∞
            total_removed = 0
            errors = []
            
            for i, unit_id in enumerate(sorted(unit_ids), 1):
                if i % 100 == 0:
                    print(f"[{i}/{len(unit_ids)}] –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ...")
                try:
                    result = cleanup_all_empty_unit_directories(unit_id, base_directories)
                    if result["success"]:
                        total_removed += result["total_removed"]
                    else:
                        errors.extend(result["errors"])
                except Exception as e:
                    errors.append(f"{unit_id}: {e}")
            
            print(f"\n–ò—Ç–æ–≥–∏ –æ—á–∏—Å—Ç–∫–∏:")
            print(f"  –£–¥–∞–ª–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {total_removed}")
            print(f"  –û—à–∏–±–æ–∫: {len(errors)}")
            
            if errors:
                print("–ü–µ—Ä–≤—ã–µ –æ—à–∏–±–∫–∏:")
                for error in errors[:10]:
                    print(f"  {error}")
                if len(errors) > 10:
                    print(f"  ... –∏ –µ—â–µ {len(errors) - 10} –æ—à–∏–±–æ–∫")
                    
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_view_pending_structure(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –Ω–æ–≤–æ–π pending —Å—Ç—Ä—É–∫—Ç—É—Ä—ã."""
        print("\n=== –ù–æ–≤–∞—è Pending –°—Ç—Ä—É–∫—Ç—É—Ä–∞ ===")
        
        try:
            from .unit_distribution_new import get_unit_statistics
            
            stats = get_unit_statistics()
            
            print("\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for category, data in stats.items():
                if data["units"] > 0 or data["files"] > 0:
                    print(f"\n{category.upper()}:")
                    print(f"  Unit'–æ–≤: {data['units']}")
                    print(f"  –§–∞–π–ª–æ–≤: {data['files']}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            from .config import (
                PENDING_DIRECT_DIR, PENDING_NORMALIZE_DIR, PENDING_CONVERT_DIR,
                PENDING_EXTRACT_DIR, PENDING_SPECIAL_DIR
            )
            
            dirs = {
                "DIRECT": PENDING_DIRECT_DIR,
                "NORMALIZE": PENDING_NORMALIZE_DIR,
                "CONVERT": PENDING_CONVERT_DIR,
                "EXTRACT": PENDING_EXTRACT_DIR,
                "SPECIAL": PENDING_SPECIAL_DIR
            }
            
            print("\n\n–ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º:")
            for name, path in dirs.items():
                exists = "‚úì" if path.exists() else "‚úó"
                print(f"{exists} {name}: {path}")
                
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_category_statistics(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ===")
        
        try:
            from .unit_distribution_new import get_unit_statistics
            from .mixed_unit_handler import get_mixed_units_statistics
            from .merge import get_ready_docling_statistics
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ pending
            print("\nüìÅ PENDING (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞):")
            pending_stats = get_unit_statistics()
            
            # –î–æ–±–∞–≤–ª—è–µ–º mixed —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            mixed_stats = get_mixed_units_statistics(include_extraction=True)
            
            total_pending_units = sum(cat["units"] for cat in pending_stats.values())
            total_pending_files = sum(cat["files"] for cat in pending_stats.values())
            
            print(f"\n  –í—Å–µ–≥–æ unit'–æ–≤: {total_pending_units}")
            print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_pending_files}")
            
            print("\n  –ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for category in ["direct", "normalize", "convert", "extract", "special", "mixed"]:
                data = pending_stats.get(category, {"units": 0, "files": 0})
                if data["units"] > 0:
                    print(f"    {category:12} - {data['units']:4} unit'–æ–≤, {data['files']:5} —Ñ–∞–π–ª–æ–≤")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º mixed units –¥–µ—Ç–∞–ª—å–Ω–æ –µ—Å–ª–∏ –µ—Å—Ç—å
            if mixed_stats["total_mixed"]["units"] > 0:
                print(f"\n  üîÄ Mixed units (–¥–µ—Ç–∞–ª—å–Ω–æ):")
                if mixed_stats["detection_mixed"]["units"] > 0:
                    print(f"    ‚îî‚îÄ –∏–∑ detection:  {mixed_stats['detection_mixed']['units']:4} unit'–æ–≤, {mixed_stats['detection_mixed']['files']:5} —Ñ–∞–π–ª–æ–≤")
                if mixed_stats["extraction_mixed"]["units"] > 0:
                    print(f"    ‚îî‚îÄ –∏–∑ extraction: {mixed_stats['extraction_mixed']['units']:4} unit'–æ–≤, {mixed_stats['extraction_mixed']['files']:5} —Ñ–∞–π–ª–æ–≤")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ ready_docling
            print("\n\n‚úÖ READY_DOCLING (–≥–æ—Ç–æ–≤–æ –¥–ª—è Docling):")
            ready_stats = get_ready_docling_statistics()
            
            print(f"\n  –í—Å–µ–≥–æ unit'–æ–≤: {ready_stats['total_units']}")
            print(f"  –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {ready_stats['total_files']}")
            
            if ready_stats['by_type']:
                print("\n  –ü–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤:")
                for file_type, data in sorted(ready_stats['by_type'].items()):
                    print(f"    {file_type:12} - {data['units']:4} unit'–æ–≤, {data['files']:5} —Ñ–∞–π–ª–æ–≤")
            
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_merge_dry_run(self):
        """Merge –≤ ready_docling (DRY RUN —Ä–µ–∂–∏–º)."""
        print("\n=== Merge –≤ ready_docling (DRY RUN) ===")
        print("–†–µ–∂–∏–º –∏–º–∏—Ç–∞—Ü–∏–∏ - —Ñ–∞–π–ª—ã –ù–ï –±—É–¥—É—Ç –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã\n")
        
        try:
            from .merge import merge_to_ready_docling, print_merge_summary
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
            limit_input = input("–õ–∏–º–∏—Ç unit'–æ–≤ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_input) if limit_input else None
            
            print("\n–í—ã–ø–æ–ª–Ω—è—é merge –≤ —Ä–µ–∂–∏–º–µ DRY RUN...")
            result = merge_to_ready_docling(dry_run=True, limit=limit)
            
            print_merge_summary(result)
            
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_merge_real(self):
        """Merge –≤ ready_docling (–†–ï–ê–õ–¨–ù–´–ô —Ä–µ–∂–∏–º)."""
        print("\n=== Merge –≤ ready_docling (–†–ï–ê–õ–¨–ù–´–ô –†–ï–ñ–ò–ú) ===")
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –§–∞–π–ª—ã –±—É–¥—É—Ç –†–ï–ê–õ–¨–ù–û –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã!\n")
        
        try:
            from .merge import merge_to_ready_docling, print_merge_summary
            
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ª–∏–º–∏—Ç
            limit_input = input("–õ–∏–º–∏—Ç unit'–æ–≤ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_input) if limit_input else None
            
            # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
            confirm = input(f"\n–ü–µ—Ä–µ–º–µ—â–∞—Ç—å —Ñ–∞–π–ª—ã –≤ ready_docling? (y/N): ").strip().lower()
            if confirm != 'y':
                print("–û—Ç–º–µ–Ω–µ–Ω–æ")
                return
            
            print("\n–í—ã–ø–æ–ª–Ω—è—é –†–ï–ê–õ–¨–ù–´–ô merge...")
            result = merge_to_ready_docling(dry_run=False, limit=limit)
            
            print_merge_summary(result)
            
            if result['files_moved'] > 0:
                print("\n‚úì Merge –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
                
                # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –æ—á–∏—Å—Ç–∫—É
                cleanup = input("\n–û—á–∏—Å—Ç–∏—Ç—å pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø–æ—Å–ª–µ merge? (y/N): ").strip().lower()
                if cleanup == 'y':
                    from .merge import cleanup_pending_after_merge
                    unit_ids = [f["unit_id"] for f in result.get("distributed_files", [])]
                    cleanup_result = cleanup_pending_after_merge(unit_ids, dry_run=False)
                    print(f"–û—á–∏—â–µ–Ω–æ unit'–æ–≤: {cleanup_result['cleaned_units']}")
                    print(f"–£–¥–∞–ª–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {cleanup_result['cleaned_directories']}")
            
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step1_scan_and_detect(self, limit: Optional[int] = None):
        """–®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ input/ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_detection import detect_file_type
            from pathlib import Path
            from collections import defaultdict
            import time
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            stats = {
                "units_scanned": 0,
                "files_scanned": 0,
                "by_extension": defaultdict(int),
                "by_detected_type": defaultdict(int),
                "extension_mismatches": 0,
                "empty_units": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    stats["empty_units"] += 1
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª(–æ–≤)):")
                stats["units_scanned"] += 1
                
                for file_path in files:
                    try:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø
                        detection = detect_file_type(file_path)
                        
                        ext = file_path.suffix.lower()
                        detected_type = detection.get("detected_type", "unknown")
                        mime = detection.get("mime_type", "unknown")
                        
                        stats["files_scanned"] += 1
                        stats["by_extension"][ext or ".no_ext"] += 1
                        stats["by_detected_type"][detected_type] += 1
                        
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                        mismatch = not detection.get("extension_matches_content", True)
                        if mismatch:
                            stats["extension_mismatches"] += 1
                        
                        # –í—ã–≤–æ–¥
                        mismatch_flag = " ‚ö† MISMATCH" if mismatch else ""
                        print(f"  {file_path.name:40} | {ext:8} ‚Üí {detected_type:12} | {mime:30}{mismatch_flag}")
                        
                    except Exception as e:
                        print(f"  ‚úó {file_path.name}: {str(e)[:40]}")
                
                print()  # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É units
            
            duration = time.time() - start_time
            
            # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–Ø:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['units_scanned']}")
            print(f"Units –ø—É—Å—Ç—ã—Ö: {stats['empty_units']}")
            print(f"–§–∞–π–ª–æ–≤ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ: {stats['files_scanned']}")
            print(f"–ù–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–π —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π: {stats['extension_mismatches']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            print(f"\n–ü–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º:")
            for ext, count in sorted(stats["by_extension"].items(), key=lambda x: -x[1])[:10]:
                print(f"  {ext:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
            
            print(f"\n–ü–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ç–∏–ø–∞–º:")
            for dtype, count in sorted(stats["by_detected_type"].items(), key=lambda x: -x[1])[:10]:
                print(f"  {dtype:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step2_classify(self, limit: Optional[int] = None):
        """–®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
        print("\n=== –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_detection import detect_file_type
            from .file_classifier import classify_file
            from collections import defaultdict
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_classified": 0,
                "files_classified": 0,
                "by_category": defaultdict(int),
                "by_action": defaultdict(int)
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id}:")
                stats["units_classified"] += 1
                
                for file_path in files:
                    try:
                        detection = detect_file_type(file_path)
                        classification = classify_file(file_path, detection)
                        
                        category = classification["category"]
                        action = classification["action"]
                        reason = classification.get("reason", "")
                        
                        stats["files_classified"] += 1
                        stats["by_category"][category] += 1
                        stats["by_action"][action] += 1
                        
                        print(f"  {file_path.name:40} ‚Üí {category:12} | {action:15} | {reason}")
                        
                    except Exception as e:
                        print(f"  ‚úó {file_path.name}: {str(e)[:40]}")
                
                print()
            
            duration = time.time() - start_time
            
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['units_classified']}")
            print(f"–§–∞–π–ª–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {stats['files_classified']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            print(f"\n–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for cat, count in sorted(stats["by_category"].items(), key=lambda x: -x[1]):
                print(f"  {cat:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
            
            print(f"\n–ü–æ –¥–µ–π—Å—Ç–≤–∏—è–º:")
            for act, count in sorted(stats["by_action"].items(), key=lambda x: -x[1]):
                print(f"  {act:15} - {count:4} —Ñ–∞–π–ª(–æ–≤)")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step3_check_duplicates(self, limit: Optional[int] = None):
        """–®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤."""
        print("\n=== –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_detection import detect_file_type
            from .file_classifier import classify_file
            from .duplicate_detection import detect_duplicates_in_unit
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_checked": 0,
                "units_with_duplicates": 0,
                "total_duplicate_groups": 0,
                "total_duplicate_files": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id}:")
                stats["units_checked"] += 1
                
                # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                classified_files = []
                for file_path in files:
                    try:
                        detection = detect_file_type(file_path)
                        classification = classify_file(file_path, detection)
                        classified_files.append({
                            "path": str(file_path),
                            "original_name": file_path.name,
                            **detection,
                            "classification": classification
                        })
                    except Exception as e:
                        print(f"  ‚úó –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path.name}: {e}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                duplicates_map = detect_duplicates_in_unit(classified_files)
                
                if duplicates_map:
                    stats["units_with_duplicates"] += 1
                    stats["total_duplicate_groups"] += len(duplicates_map)
                    
                    print(f"  ‚ö† –ù–∞–π–¥–µ–Ω–æ {len(duplicates_map)} –≥—Ä—É–ø–ø(—ã) –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
                    
                    for hash_value, dup_files in duplicates_map.items():
                        stats["total_duplicate_files"] += len(dup_files)
                        print(f"\n    –ì—Ä—É–ø–ø–∞ (hash: {hash_value[:12]}...):")
                        for dup_file in dup_files:
                            print(f"      - {dup_file.get('original_name')}")
                else:
                    print(f"  ‚úì –î—É–±–ª–∏–∫–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                
                print()
            
            duration = time.time() - start_time
            
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –ü–†–û–í–ï–†–ö–ò –î–£–ë–õ–ò–ö–ê–¢–û–í:")
            print(f"{'='*80}")
            print(f"Units –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['units_checked']}")
            print(f"Units —Å –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏: {stats['units_with_duplicates']}")
            print(f"–í—Å–µ–≥–æ –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['total_duplicate_groups']}")
            print(f"–í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤-–¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {stats['total_duplicate_files']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step4_check_mixed(self, limit: Optional[int] = None):
        """–®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units."""
        print("\n=== –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .file_classifier import classify_unit_files
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_checked": 0,
                "mixed_units": 0,
                "homogeneous_units": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                stats["units_checked"] += 1
                
                # –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ–º unit
                unit_classification = classify_unit_files(files, unit_id)
                
                is_mixed = unit_classification["is_mixed"]
                unit_category = unit_classification["unit_category"]
                type_dist = unit_classification["type_distribution"]
                
                if is_mixed:
                    stats["mixed_units"] += 1
                    print(f"[{idx}/{len(unit_dirs)}] {unit_id}: üîÄ MIXED")
                    print(f"  –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
                    for cat, count in type_dist.items():
                        print(f"    {cat:15} - {count} —Ñ–∞–π–ª(–æ–≤)")
                else:
                    stats["homogeneous_units"] += 1
                    print(f"[{idx}/{len(unit_dirs)}] {unit_id}: ‚úì –û–¥–Ω–æ—Ä–æ–¥–Ω—ã–π ({unit_category})")
                
                print()
            
            duration = time.time() - start_time
            
            print(f"{'='*80}")
            print(f"–ò–¢–û–ì–ò –û–ü–†–ï–î–ï–õ–ï–ù–ò–Ø MIXED UNITS:")
            print(f"{'='*80}")
            print(f"Units –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ: {stats['units_checked']}")
            print(f"Mixed units: {stats['mixed_units']}")
            print(f"–û–¥–Ω–æ—Ä–æ–¥–Ω—ã—Ö units: {stats['homogeneous_units']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_step5_distribute(self, limit: Optional[int] = None):
        """–®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º."""
        print("\n=== –®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .unit_distribution_new import distribute_unit_by_new_structure
            from .mixed_unit_handler import get_mixed_units_statistics
            from collections import defaultdict
            import time
            
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            
            stats = {
                "units_processed": 0,
                "files_moved": 0,
                "by_category": defaultdict(int),
                "mixed_units": 0,
                "errors": 0
            }
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª–æ–≤)...", end=" ", flush=True)
                
                try:
                    files_list = [{"path": str(f)} for f in files]
                    result = distribute_unit_by_new_structure(unit_id, files_list)
                    
                    stats["units_processed"] += 1
                    stats["files_moved"] += result["files_processed"]
                    
                    if result.get("is_mixed"):
                        stats["mixed_units"] += 1
                        print(f"üîÄ MIXED ‚Üí pending/mixed/")
                    else:
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é
                        main_cat = max(result["files_by_category"].items(), key=lambda x: x[1])[0] if result["files_by_category"] else "unknown"
                        stats["by_category"][main_cat] += 1
                        print(f"‚úì ‚Üí pending/{main_cat}/")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –¥–µ—Ç–∞–ª–∏
                    if result.get("errors"):
                        print(f"     ‚ö† –û—à–∏–±–æ–∫: {len(result['errors'])}")
                    if result.get("duplicates_detected"):
                        print(f"     ‚ö† –î—É–±–ª–∏–∫–∞—Ç—ã: {result['duplicate_count']} –≥—Ä—É–ø–ø")
                    
                except Exception as e:
                    print(f"‚úó –û—à–∏–±–∫–∞: {str(e)[:50]}")
                    stats["errors"] += 1
            
            duration = time.time() - start_time
            
            print(f"\n{'='*80}")
            print(f"–ò–¢–û–ì–ò –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['units_processed']}")
            print(f"–§–∞–π–ª–æ–≤ –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ: {stats['files_moved']}")
            print(f"Mixed units: {stats['mixed_units']}")
            print(f"–û—à–∏–±–æ–∫: {stats['errors']}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            print(f"\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for cat, count in sorted(stats["by_category"].items(), key=lambda x: -x[1]):
                print(f"  {cat:15} - {count:4} unit(–æ–≤)")
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ mixed units
            mixed_stats = get_mixed_units_statistics(include_extraction=False)
            if mixed_stats["total_mixed"]["units"] > 0:
                print(f"\nüîÄ Mixed units (–¥–µ—Ç–∞–ª—å–Ω–æ):")
                print(f"  Units: {mixed_stats['total_mixed']['units']}")
                print(f"  –§–∞–π–ª–æ–≤: {mixed_stats['total_mixed']['files']}")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_full_processing(self, limit: Optional[int] = None):
        """–ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (3-7)."""
        print("\n=== –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ ‚Üí –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ) ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç units (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        print(f"\n{'='*80}")
        print("–ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ô –û–ë–†–ê–ë–û–¢–ö–ò")
        print(f"{'='*80}\n")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ —à–∞–≥–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (—Ç–æ–ª—å–∫–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–∂–µ –≤–∫–ª—é—á–µ–Ω—ã)
        self.handle_step5_distribute(limit=limit)
    
    def handle_units_report(self):
        """–û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units."""
        print("\n=== –û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units ===")
        
        try:
            from .config import PENDING_DIR
            import json
            
            categories = {
                "direct": PENDING_DIRECT_DIR,
                "normalize": PENDING_NORMALIZE_DIR,
                "convert": PENDING_CONVERT_DIR,
                "extract": PENDING_EXTRACT_DIR,
                "special": PENDING_SPECIAL_DIR,
                "mixed": PENDING_MIXED_DIR
            }
            
            total_units = 0
            total_files = 0
            
            for category, cat_dir in categories.items():
                if not cat_dir.exists():
                    continue
                
                units = [d for d in cat_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
                
                if not units:
                    continue
                
                print(f"\n{'='*80}")
                print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category.upper()}")
                print(f"{'='*80}")
                print(f"Units: {len(units)}\n")
                
                for unit_dir in units[:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                    unit_id = unit_dir.name
                    files_dir = unit_dir / "files"
                    metadata_file = unit_dir / "metadata.json"
                    
                    files_count = 0
                    if files_dir.exists():
                        files = [f for f in files_dir.iterdir() if f.is_file()]
                        files_count = len(files)
                        total_files += files_count
                    
                    total_units += 1
                    
                    print(f"  {unit_id}: {files_count} —Ñ–∞–π–ª(–æ–≤)")
                    
                    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –µ—Å–ª–∏ –µ—Å—Ç—å
                    if metadata_file.exists():
                        try:
                            with open(metadata_file, 'r') as f:
                                metadata = json.load(f)
                                dist_result = metadata.get("distribution_result", {})
                                if dist_result.get("duplicates_detected"):
                                    print(f"    ‚ö† –î—É–±–ª–∏–∫–∞—Ç—ã: {dist_result.get('duplicate_count', 0)} –≥—Ä—É–ø–ø")
                                if dist_result.get("errors"):
                                    print(f"    ‚úó –û—à–∏–±–æ–∫: {len(dist_result['errors'])}")
                        except:
                            pass
                
                if len(units) > 10:
                    print(f"  ... –∏ –µ—â–µ {len(units) - 10} unit(–æ–≤)")
            
            print(f"\n{'='*80}")
            print(f"–ò–¢–û–ì–û:")
            print(f"{'='*80}")
            print(f"Units –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_units}")
            print(f"–§–∞–π–ª–æ–≤ –≤—Å–µ–≥–æ: {total_files}")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def handle_new_structure_detection(self, limit: Optional[int] = None):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –Ω–æ–≤–æ–π pending —Å—Ç—Ä—É–∫—Ç—É—Ä—ã."""
        print("\n=== –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ (–ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê —Å pending/) ===")
        
        if limit is None:
            limit_str = input(f"–õ–∏–º–∏—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None
        
        try:
            from .unit_distribution_new import distribute_unit_by_new_structure, print_distribution_summary
            from .mixed_unit_handler import get_mixed_units_statistics
            from pathlib import Path
            import time
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ unit'–æ–≤
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            total_units = len(unit_dirs)
            
            if limit:
                unit_dirs = unit_dirs[:limit]
            
            print(f"\n–ù–∞–π–¥–µ–Ω–æ unit'–æ–≤: {total_units}")
            print(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: {len(unit_dirs)}")
            print(f"{'='*80}\n")
            
            start_time = time.time()
            processed = 0
            errors = 0
            
            for idx, unit_dir in enumerate(unit_dirs, 1):
                unit_id = unit_dir.name
                files = [f for f in unit_dir.iterdir() if f.is_file() and not f.name.startswith('.')]
                
                if not files:
                    continue
                
                print(f"[{idx}/{len(unit_dirs)}] {unit_id} ({len(files)} —Ñ–∞–π–ª–æ–≤)...", end=" ", flush=True)
                
                try:
                    files_list = [{"path": str(f)} for f in files]
                    result = distribute_unit_by_new_structure(unit_id, files_list)
                    
                    if result.get("is_mixed"):
                        print(f"üîÄ MIXED")
                    else:
                        print(f"‚úì")
                    
                    processed += 1
                except Exception as e:
                    print(f"‚úó {str(e)[:30]}")
                    errors += 1
            
            duration = time.time() - start_time
            
            print(f"\n{'='*80}")
            print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{len(unit_dirs)}")
            print(f"–û—à–∏–±–æ–∫: {errors}")
            print(f"–í—Ä–µ–º—è: {duration:.2f} —Å–µ–∫")
            
            # –ü–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É mixed units
            mixed_stats = get_mixed_units_statistics(include_extraction=False)
            if mixed_stats["total_mixed"]["units"] > 0:
                print(f"\nüîÄ Mixed units –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ: {mixed_stats['total_mixed']['units']}")
                print(f"  –§–∞–π–ª–æ–≤ –≤ mixed units: {mixed_stats['total_mixed']['files']}")
        
        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
    
    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª CLI."""
        while True:
            try:
                self.show_menu()
                choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ [0-19]: ").strip()
                
                if choice == "0":
                    print("–í—ã—Ö–æ–¥...")
                    break
                
                # === –ó–ê–ì–†–£–ó–ö–ê –ò –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø ===
                elif choice == "1":
                    self.handle_download_protocols()
                elif choice == "2":
                    self.handle_sync_protocols()
                
                # === –ù–û–í–ê–Ø –°–ò–°–¢–ï–ú–ê (PENDING) - –ü–û–®–ê–ì–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===
                elif choice == "3":
                    self.handle_step1_scan_and_detect()
                elif choice == "4":
                    self.handle_step2_classify()
                elif choice == "5":
                    self.handle_step3_check_duplicates()
                elif choice == "6":
                    self.handle_step4_check_mixed()
                elif choice == "7":
                    self.handle_step5_distribute()
                elif choice == "8":
                    self.handle_full_processing()
                
                # === –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò –ü–†–û–°–ú–û–¢–† ===
                elif choice == "9":
                    self.handle_view_pending_structure()
                elif choice == "10":
                    self.handle_category_statistics()
                elif choice == "11":
                    self.handle_units_report()
                
                # === MERGE –í READY_DOCLING ===
                elif choice == "12":
                    self.handle_merge_dry_run()
                elif choice == "13":
                    self.handle_merge_real()
                
                # === –°–õ–£–ñ–ï–ë–ù–´–ï –û–ü–ï–†–ê–¶–ò–ò ===
                elif choice == "14":
                    self.show_statistics()
                elif choice == "15":
                    self.show_metrics()
                elif choice == "16":
                    self.configure_limits()
                elif choice == "17":
                    self.handle_cleanup()
                elif choice == "18":
                    self.handle_check_sorted_units()
                elif choice == "19":
                    self.handle_analyze_detection_issues()
                
                else:
                    print("–ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")
                
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")
            
            except KeyboardInterrupt:
                print("\n\n–í—ã—Ö–æ–¥...")
                break
            except Exception as e:
                print(f"\n–û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")

