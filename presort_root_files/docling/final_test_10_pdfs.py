#!/usr/bin/env python3
"""
–§–ò–ù–ê–õ–¨–ù–´–ô —Ç–µ—Å—Ç: 10 PDF —Ñ–∞–π–ª–æ–≤ —Å –†–ï–ê–õ–¨–ù–´–ú –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ç–µ–∫—Å—Ç–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç:
- pdfplumber –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ —Ç–∞–±–ª–∏—Ü
- pytesseract OCR –¥–ª—è —Å–∫–∞–Ω–æ–≤
- Granite API –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
"""
import sys
sys.path.insert(0, 'docling')

import os
import json
import time
import openai
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List
from processor import DocumentProcessor

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è Granite
GRANITE_API_URL = "https://8cb66180-db3a-4963-8068-51f87e716259.modelrun.inference.cloud.ru/v1"
GRANITE_API_TOKEN = "ZDRhOWQ3OTAtZjU4MC00MzA2LThhNTgtMDU1NGFlMjE4OWRl.85a830f9340966e0ad1fd1642884c7c8"

granite_client = openai.OpenAI(api_key=GRANITE_API_TOKEN, base_url=GRANITE_API_URL)


def find_test_pdfs(limit=10) -> List[Path]:
    """–ù–∞–π—Ç–∏ —Ç–µ—Å—Ç–æ–≤—ã–µ PDF —Ñ–∞–π–ª—ã"""
    base = Path("/root/winners_preprocessor/pilot_winers223/data/pending/direct/pdf")
    all_pdfs = []
    for unit_dir in base.iterdir():
        if unit_dir.is_dir() and unit_dir.name.startswith("UNIT_"):
            files_dir = unit_dir / "files"
            if files_dir.exists():
                all_pdfs.extend(list(files_dir.glob("*.pdf")))
    return all_pdfs[:limit]


def extract_metadata(text: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ Granite"""
    if len(text.strip()) < 100:
        return get_empty_metadata()
    
    text_sample = text[:15000] if len(text) > 15000 else text
    
    prompt = f"""–ò–∑–≤–ª–µ–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –∑–∞–∫—É–ø–∫–∏ –≤ JSON:

{text_sample}

–§–æ—Ä–º–∞—Ç (null –µ—Å–ª–∏ –Ω–µ—Ç):
{{
  "–Ω–æ–º–µ—Ä_–ø—Ä–æ—Ü–µ–¥—É—Ä—ã": "–Ω–æ–º–µ—Ä",
  "–Ω–æ–º–µ—Ä_–ª–æ—Ç–∞": "–ª–æ—Ç",
  "–¥–∞—Ç–∞_–ø—Ä–æ—Ç–æ–∫–æ–ª–∞": "–î–î.–ú–ú.–ì–ì–ì–ì",
  "–ø–æ–±–µ–¥–∏—Ç–µ–ª—å": "–Ω–∞–∑–≤–∞–Ω–∏–µ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è",
  "–ò–ù–ù": "–ò–ù–ù",
  "–ö–ü–ü": "–ö–ü–ü",
  "—Ü–µ–Ω–∞_–ø–æ–±–µ–¥–∏—Ç–µ–ª—è": "—Ü–µ–Ω–∞ —á–∏—Å–ª–æ",
  "–≤–∞–ª—é—Ç–∞": "RUB/USD/EUR",
  "–ø—Ä–µ–¥–º–µ—Ç_–∑–∞–∫—É–ø–∫–∏": "–ø—Ä–µ–¥–º–µ—Ç",
  "–¥–∞—Ç–∞_–Ω–∞—á–∞–ª–∞_–ø–æ–¥–∞—á–∏": "–î–î.–ú–ú.–ì–ì–ì–ì",
  "–¥–∞—Ç–∞_–æ–∫–æ–Ω—á–∞–Ω–∏—è_–ø–æ–¥–∞—á–∏": "–î–î.–ú–ú.–ì–ì–ì–ì",
  "–¥–∞—Ç–∞_–ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è": "–î–î.–ú–ú.–ì–ì–ì–ì",
  "–∑–∞–∫–∞–∑—á–∏–∫": "–∑–∞–∫–∞–∑—á–∏–∫",
  "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä": "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä",
  "—Å–æ—Å—Ç–∞–≤_–∫–æ–º–∏—Å—Å–∏–∏": ["–§–ò–û"],
  "—É—á–∞—Å—Ç–Ω–∏–∫–∏": [{{"–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ": "", "—Å—Ç–∞—Ç—É—Å": "", "—Å—É–º–º–∞": "", "–Ω–æ–º–µ—Ä_–∑–∞—è–≤–∫–∏": ""}}]
}}

–¢–û–õ–¨–ö–û JSON:"""
    
    try:
        response = granite_client.chat.completions.create(
            model="granite-docling",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=4000,
            temperature=0.0
        )
        
        raw = response.choices[0].message.content
        return parse_json(raw)
    except Exception as e:
        print(f"      ‚ö†Ô∏è  –û—à–∏–±–∫–∞ Granite: {e}")
        return get_empty_metadata()


def parse_json(text: str) -> Dict:
    import re
    text = text.strip()
    if text.startswith('```'):
        parts = text.split('```')
        if len(parts) >= 2:
            text = parts[1]
            if text.startswith('json'):
                text = text[4:]
    text = text.strip()
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(0))
        except:
            pass
    return get_empty_metadata()


def get_empty_metadata() -> Dict:
    return {
        "–Ω–æ–º–µ—Ä_–ø—Ä–æ—Ü–µ–¥—É—Ä—ã": None, "–Ω–æ–º–µ—Ä_–ª–æ—Ç–∞": None, "–¥–∞—Ç–∞_–ø—Ä–æ—Ç–æ–∫–æ–ª–∞": None,
        "–ø–æ–±–µ–¥–∏—Ç–µ–ª—å": None, "–ò–ù–ù": None, "–ö–ü–ü": None, "—Ü–µ–Ω–∞_–ø–æ–±–µ–¥–∏—Ç–µ–ª—è": None,
        "–≤–∞–ª—é—Ç–∞": None, "–ø—Ä–µ–¥–º–µ—Ç_–∑–∞–∫—É–ø–∫–∏": None, "–¥–∞—Ç–∞_–Ω–∞—á–∞–ª–∞_–ø–æ–¥–∞—á–∏": None,
        "–¥–∞—Ç–∞_–æ–∫–æ–Ω—á–∞–Ω–∏—è_–ø–æ–¥–∞—á–∏": None, "–¥–∞—Ç–∞_–ø—Ä–æ–≤–µ–¥–µ–Ω–∏—è": None,
        "–∑–∞–∫–∞–∑—á–∏–∫": None, "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä": None, "—Å–æ—Å—Ç–∞–≤_–∫–æ–º–∏—Å—Å–∏–∏": [],
        "—É—á–∞—Å—Ç–Ω–∏–∫–∏": []
    }


def process_pdf(pdf_path: Path, output_dir: Path) -> Dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ PDF"""
    print(f"\n[{pdf_path.name}]")
    start_time = time.time()
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–µ—Ä–µ–∑ DocumentProcessor
    print(f"   üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞...")
    processor = DocumentProcessor(
        unit_id="TEST",
        file_info={
            "path": str(pdf_path),
            "original_name": pdf_path.name,
            "detected_type": "pdf",
            "route": "pdf_text"
        },
        output_dir=output_dir
    )
    
    try:
        result = processor.process()
        
        if not result["success"]:
            print(f"      ‚ùå –û—à–∏–±–∫–∞: {result.get('error')}")
            return {"success": False, "error": result.get("error")}
        
        # –ß–∏—Ç–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ JSON
        output_files = result.get("output_files", [])
        json_file = next((f for f in output_files if f.endswith('.json')), None)
        
        if not json_file or not Path(json_file).exists():
            print(f"      ‚ùå JSON —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {"success": False, "error": "No JSON output"}
        
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        text = data.get("text", "")
        tables = data.get("tables", [])
        
        print(f"      ‚úÖ –¢–µ–∫—Å—Ç: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤, –¢–∞–±–ª–∏—Ü: {len(tables)}")
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        print(f"   üîç –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
        metadata = extract_metadata(text)
        filled = sum(1 for v in metadata.values() if v and str(v).strip())
        print(f"      ‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ –ø–æ–ª–µ–π: {filled}/16")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ Markdown
        md_content = create_final_markdown(pdf_path.name, text, tables, metadata)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        base_name = pdf_path.stem
        final_md = output_dir / f"{base_name}_FINAL.md"
        with open(final_md, 'w', encoding='utf-8') as f:
            f.write(md_content)
        
        final_meta = output_dir / f"{base_name}_metadata.json"
        metadata["–ø–æ–ª–Ω—ã–π_—Ç–µ–∫—Å—Ç"] = text
        metadata["—Ç–∞–±–ª–∏—Ü—ã"] = tables
        with open(final_meta, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        elapsed = time.time() - start_time
        print(f"      ‚è±Ô∏è  {elapsed:.1f}—Å")
        
        return {
            "success": True,
            "text_length": len(text),
            "tables_count": len(tables),
            "metadata_fields": filled,
            "time": elapsed
        }
        
    except Exception as e:
        print(f"      ‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def create_final_markdown(filename: str, text: str, tables: List, metadata: Dict) -> str:
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ Markdown"""
    md = f"# {filename}\n\n"
    md += f"**–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"
    md += "---\n\n"
    
    # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    md += "## üìä –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n\n"
    md += f"- **–ù–æ–º–µ—Ä –ø—Ä–æ—Ü–µ–¥—É—Ä—ã:** {metadata.get('–Ω–æ–º–µ—Ä_–ø—Ä–æ—Ü–µ–¥—É—Ä—ã') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–ù–æ–º–µ—Ä –ª–æ—Ç–∞:** {metadata.get('–Ω–æ–º–µ—Ä_–ª–æ—Ç–∞') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–î–∞—Ç–∞ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞:** {metadata.get('–¥–∞—Ç–∞_–ø—Ä–æ—Ç–æ–∫–æ–ª–∞') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–ü–æ–±–µ–¥–∏—Ç–µ–ª—å:** {metadata.get('–ø–æ–±–µ–¥–∏—Ç–µ–ª—å') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–ò–ù–ù:** {metadata.get('–ò–ù–ù') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–ö–ü–ü:** {metadata.get('–ö–ü–ü') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–¶–µ–Ω–∞:** {metadata.get('—Ü–µ–Ω–∞_–ø–æ–±–µ–¥–∏—Ç–µ–ª—è') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'} {metadata.get('–≤–∞–ª—é—Ç–∞') or ''}\n"
    md += f"- **–ü—Ä–µ–¥–º–µ—Ç –∑–∞–∫—É–ø–∫–∏:** {metadata.get('–ø—Ä–µ–¥–º–µ—Ç_–∑–∞–∫—É–ø–∫–∏') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–ó–∞–∫–∞–∑—á–∏–∫:** {metadata.get('–∑–∞–∫–∞–∑—á–∏–∫') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n"
    md += f"- **–û—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä:** {metadata.get('–æ—Ä–≥–∞–Ω–∏–∑–∞—Ç–æ—Ä') or '–Ω–µ –Ω–∞–π–¥–µ–Ω–æ'}\n\n"
    
    if metadata.get('—Å–æ—Å—Ç–∞–≤_–∫–æ–º–∏—Å—Å–∏–∏'):
        md += "### –°–æ—Å—Ç–∞–≤ –∫–æ–º–∏—Å—Å–∏–∏\n\n"
        for member in metadata['—Å–æ—Å—Ç–∞–≤_–∫–æ–º–∏—Å—Å–∏–∏']:
            md += f"- {member}\n"
        md += "\n"
    
    if metadata.get('—É—á–∞—Å—Ç–Ω–∏–∫–∏'):
        md += f"### –£—á–∞—Å—Ç–Ω–∏–∫–∏ ({len(metadata['—É—á–∞—Å—Ç–Ω–∏–∫–∏'])})\n\n"
        for i, p in enumerate(metadata['—É—á–∞—Å—Ç–Ω–∏–∫–∏'][:5], 1):
            md += f"{i}. **{p.get('–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', 'N/A')}** - {p.get('—Å—Ç–∞—Ç—É—Å', 'N/A')}\n"
        md += "\n"
    
    # –¢–µ–∫—Å—Ç
    md += "## üìÑ –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞\n\n"
    if len(text) > 5000:
        md += text[:5000] + "\n\n_(—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–ª—è —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏)_\n\n"
    else:
        md += text + "\n\n"
    
    # –¢–∞–±–ª–∏—Ü—ã
    if tables:
        md += f"## üìä –¢–∞–±–ª–∏—Ü—ã ({len(tables)})\n\n"
        for i, table in enumerate(tables[:2], 1):
            md += f"### –¢–∞–±–ª–∏—Ü–∞ {i}\n\n"
            if isinstance(table, list) and table:
                for r_idx, row in enumerate(table[:8]):
                    md += "| " + " | ".join(str(c or "") for c in row) + " |\n"
                    if r_idx == 0:
                        md += "|" + "|".join([" --- "] * len(row)) + "|\n"
            md += "\n"
        if len(tables) > 2:
            md += f"_(–ü–æ–∫–∞–∑–∞–Ω—ã 2 –∏–∑ {len(tables)} —Ç–∞–±–ª–∏—Ü)_\n\n"
    
    return md


def main():
    print("="*70)
    print("–§–ò–ù–ê–õ–¨–ù–´–ô –¢–ï–°–¢: 10 PDF —Ñ–∞–π–ª–æ–≤")
    print("="*70)
    print()
    
    # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–æ–≤
    print("1. –ü–æ–∏—Å–∫ PDF —Ñ–∞–π–ª–æ–≤...")
    pdfs = find_test_pdfs(10)
    print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ: {len(pdfs)} —Ñ–∞–π–ª–æ–≤\n")
    
    # Output
    output = Path("output_FINAL_10_pdfs")
    output.mkdir(exist_ok=True)
    print(f"2. Output: {output}\n")
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞
    print("3. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤...")
    results = []
    for i, pdf in enumerate(pdfs, 1):
        print(f"\n[{i}/{len(pdfs)}]", end=" ")
        result = process_pdf(pdf, output)
        results.append({**result, "file": pdf.name})
    
    # –ò—Ç–æ–≥–∏
    print("\n")
    print("="*70)
    print("–ò–¢–û–ì–ò")
    print("="*70)
    
    success = [r for r in results if r.get("success")]
    failed = [r for r in results if not r.get("success")]
    
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {len(success)}/{len(pdfs)}")
    if failed:
        print(f"‚ùå –û—à–∏–±–∫–∏: {len(failed)}")
        for f in failed:
            print(f"   - {f['file']}: {f.get('error', 'unknown')}")
    
    if success:
        total_text = sum(r.get("text_length", 0) for r in success)
        total_tables = sum(r.get("tables_count", 0) for r in success)
        total_meta = sum(r.get("metadata_fields", 0) for r in success)
        total_time = sum(r.get("time", 0) for r in success)
        
        print(f"\nüìä –ò–∑–≤–ª–µ—á–µ–Ω–æ:")
        print(f"   –¢–µ–∫—Å—Ç–∞: {total_text:,} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"   –¢–∞–±–ª–∏—Ü: {total_tables}")
        print(f"   –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {total_meta} –ø–æ–ª–µ–π (—Å—Ä–µ–¥–Ω–µ–µ: {total_meta/len(success):.1f} –Ω–∞ —Ñ–∞–π–ª)")
        print(f"   –í—Ä–µ–º—è: {total_time:.1f}—Å (—Å—Ä–µ–¥–Ω–µ–µ: {total_time/len(success):.1f}—Å –Ω–∞ —Ñ–∞–π–ª)")
    
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {output}")
    print("="*70)


if __name__ == "__main__":
    main()

