#!/usr/bin/env python3
"""
–ü–†–û–î–ê–ö–®–ï–ù –†–ï–®–ï–ù–ò–ï: –û–ë–†–ê–ë–û–¢–ö–ê PDF –ü–†–û–¢–û–ö–û–õ–û–í –ß–ï–†–ï–ó SMOLDOCLING

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –∏ –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π.
"""
import os
import sys
import json
import time
import base64
from pathlib import Path
from datetime import datetime
from PIL import Image
import io

try:
    import openai
    OPENAI_SDK_AVAILABLE = True
except ImportError:
    OPENAI_SDK_AVAILABLE = False
    print("‚ö†Ô∏è  openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")

try:
    from pdf2image import convert_from_path
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False
    print("‚ö†Ô∏è  pdf2image –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pdf2image")
    print("   –¢–∞–∫–∂–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è: sudo apt-get install poppler-utils")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è SmolDocling
API_TOKEN = "ZDRhOWQ3OTAtZjU4MC00MzA2LThhNTgtMDU1NGFlMjE4OWRl.85a830f9340966e0ad1fd1642884c7c8"
BASE_URL = "https://d63e30af-085a-49f0-9724-8162da967af2.modelrun.inference.cloud.ru/v1"
MODEL_NAME = "model-run-4qigw-disease"

class SmolDoclingPDFProcessor:
    def __init__(self, output_dir: str = "/root/winners_preprocessor/output_smoldocling_production"):
        if not OPENAI_SDK_AVAILABLE:
            raise ImportError("openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        self.client = openai.OpenAI(
            api_key=API_TOKEN,
            base_url=BASE_URL,
            timeout=120.0
        )
        self.model = MODEL_NAME
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

    def wait_for_server_ready(self, max_wait_time: int = 60) -> bool:
        """–û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
        print("‚è≥ –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ SmolDocling —Å–µ—Ä–≤–µ—Ä–∞...")

        start_time = time.time()
        while time.time() - start_time < max_wait_time:
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": "Ready?"}],
                    max_tokens=5,
                    temperature=0.0
                )
                if response.choices[0].message.content:
                    print("‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
                    return True
            except Exception as e:
                print(f"    –û–∂–∏–¥–∞–Ω–∏–µ... ({str(e)[:40]}...)")
                time.sleep(3)

        print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
        return False

    def create_optimized_thumbnail(self, pdf_path: Path) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ thumbnail —Å –ª—É—á—à–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
        print(f"üì∑ –°–æ–∑–¥–∞–Ω–∏–µ HQ thumbnail: {pdf_path.name}")

        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        pil_images = convert_from_path(str(pdf_path), dpi=300, first_page=1, last_page=1)
        img = pil_images[0]

        if img.mode != 'RGB':
            img = img.convert('RGB')

        # –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∞ –∫–∞—á–µ—Å—Ç–≤–∞/–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        max_size = 1200  # –ù–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        if max(img.size) > max_size:
            ratio = max_size / max(img.size)
            new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
            img = img.resize(new_size, Image.Resampling.LANCZOS)

        print(f"   –†–∞–∑–º–µ—Ä: {img.size}, –∫–∞—á–µ—Å—Ç–≤–æ: 90%")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ base64
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format='JPEG', quality=90, optimize=True)
        base64_img = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')

        return base64_img

    def extract_text_with_smoldocling(self, base64_thumbnail: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ SmolDocling —Å –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º"""
        print("üß† –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ SmolDocling...")

        # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        prompt = "Convert this document page to structured docling format with full text extraction."

        image_url = f"data:image/jpeg;base64,{base64_thumbnail}"

        messages_content = [
            {"type": "text", "text": prompt},
            {"type": "image_url", "image_url": {"url": image_url}}
        ]

        start_time = time.time()
        response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": messages_content}],
            max_tokens=4000,  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
            temperature=0.0
        )

        processing_time = time.time() - start_time
        tokens_used = response.usage.total_tokens if response.usage else 0

        print(f"   ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –∑–∞ {processing_time:.2f} —Å–µ–∫, —Ç–æ–∫–µ–Ω–æ–≤: {tokens_used}")

        return response.choices[0].message.content

    def parse_doctags_to_text(self, doctags: str) -> str:
        """–ü–∞—Ä—Å–∏–Ω–≥ DocTags –≤ —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç"""
        print("üìù –ü–∞—Ä—Å–∏–Ω–≥ DocTags...")

        lines = doctags.strip().split('\n')
        text_parts = []

        for line in lines:
            if not line.strip():
                continue

            parts = line.split('>')
            if len(parts) >= 5:
                content = parts[-1].strip()
                if content and len(content) > 2:  # –ú–∏–Ω–∏–º—É–º 3 —Å–∏–º–≤–æ–ª–∞
                    text_parts.append(content)

        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∏ –æ—á–∏—Å—Ç–∫–∞
        full_text = ' '.join(text_parts)
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã—Ö OCR –æ—à–∏–±–æ–∫
        full_text = full_text.replace('–∑–∞–∫—É—à–∫–µ', '–∑–∞–∫—É–ø–∫–µ')
        full_text = full_text.replace('—É–±–∞—Ç', '—É—Å–ª—É–≥')
        full_text = full_text.replace('—Ç–æ–≤–∞—Ä,', '—Ç–æ–≤–∞—Ä–æ–≤,')

        return full_text.strip()

    def analyze_protocol_content(self, text: str) -> dict:
        """–ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞ –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–∫—É–ø–∫–∞—Ö"""
        print("üîç –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–∞...")

        text_lower = text.lower()

        analysis = {
            "document_type": "protocol" if "–ø—Ä–æ—Ç–æ–∫–æ–ª" in text_lower else "unknown",
            "has_procurement": any(word in text_lower for word in ["–∑–∞–∫—É–ø–∫", "—Ç–µ–Ω–¥–µ—Ä", "–∫–æ–Ω–∫—É—Ä—Å", "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω"]),
            "has_commission": any(word in text_lower for word in ["–∫–æ–º–∏—Å—Å", "–∑–∞—Å–µ–¥–∞–Ω–∏", "—á–ª–µ–Ω"]),
            "has_winners": any(word in text_lower for word in ["–ø–æ–±–µ–¥–∏—Ç–µ–ª", "–ø–æ–±–µ–¥–∏–ª", "–≤—ã–∏–≥—Ä–∞–ª"]),
            "has_contracts": any(word in text_lower for word in ["–∫–æ–Ω—Ç—Ä–∞–∫—Ç", "–¥–æ–≥–æ–≤–æ—Ä", "—Å–¥–µ–ª–∫"]),
            "has_amounts": any(word in text_lower for word in ["—Ä—É–±–ª", "—Å—É–º–º", "—Ç—ã—Å—è—á", "–º–∏–ª–ª–∏–æ–Ω"]),
            "confidence_score": 0.0,
            "extracted_participants": [],
            "extracted_amounts": [],
            "protocol_number": None
        }

        # –†–∞—Å—á–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        confidence = 0.0
        if analysis["has_procurement"]: confidence += 0.3
        if analysis["has_commission"]: confidence += 0.2
        if analysis["has_winners"]: confidence += 0.2
        if analysis["has_contracts"]: confidence += 0.1
        if len(text) > 50: confidence += 0.2
        if "–ø—Ä–æ—Ç–æ–∫–æ–ª" in text_lower: confidence += 0.3

        analysis["confidence_score"] = min(confidence, 1.0)

        # –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –Ω–æ–º–µ—Ä –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
        import re
        protocol_match = re.search(r'–ø—Ä–æ—Ç–æ–∫–æ–ª[–∞-—è\s]*(\d+[\-\.]?\d*)', text_lower)
        if protocol_match:
            analysis["protocol_number"] = protocol_match.group(1)

        return analysis

    def generate_markdown_report(self, pdf_path: Path, extracted_text: str, analysis: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Ä–æ–±–Ω–æ–≥–æ Markdown –æ—Ç—á–µ—Ç–∞"""
        print("üìÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è Markdown –æ—Ç—á–µ—Ç–∞...")

        markdown_parts = []

        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        header = f"# –ê–ù–ê–õ–ò–ó –ü–†–û–¢–û–ö–û–õ–ê –ó–ê–ö–£–ü–û–ö\n\n"
        header += f"**–§–∞–π–ª:** {pdf_path.name}\n"
        header += f"**–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–µ—Ä–µ–∑:** SmolDocling (Cloud.ru)\n"
        header += f"**–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        header += f"**–†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞:** {pdf_path.stat().st_size} –±–∞–π—Ç\n\n"
        markdown_parts.append(header)

        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞
        markdown_parts.append("## –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ê–ù–ê–õ–ò–ó–ê\n\n")
        markdown_parts.append(f"- **–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞:** {analysis['document_type'].title()}\n")
        markdown_parts.append(f"- **–°–æ–¥–µ—Ä–∂–∏—Ç –∑–∞–∫—É–ø–∫–∏:** {'‚úÖ –î–∞' if analysis['has_procurement'] else '‚ùå –ù–µ—Ç'}\n")
        markdown_parts.append(f"- **–ò–º–µ–µ—Ç –∫–æ–º–∏—Å—Å–∏—é:** {'‚úÖ –î–∞' if analysis['has_commission'] else '‚ùå –ù–µ—Ç'}\n")
        markdown_parts.append(f"- **–°–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π:** {'‚úÖ –î–∞' if analysis['has_winners'] else '‚ùå –ù–µ—Ç'}\n")
        markdown_parts.append(f"- **–ò–º–µ–µ—Ç –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã:** {'‚úÖ –î–∞' if analysis['has_contracts'] else '‚ùå –ù–µ—Ç'}\n")
        markdown_parts.append(f"- **–°–æ–¥–µ—Ä–∂–∏—Ç —Å—É–º–º—ã:** {'‚úÖ –î–∞' if analysis['has_amounts'] else '‚ùå –ù–µ—Ç'}\n")
        markdown_parts.append(f"- **–£—Ä–æ–≤–µ–Ω—å —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏:** {analysis['confidence_score']:.2f}\n")

        if analysis['protocol_number']:
            markdown_parts.append(f"- **–ù–æ–º–µ—Ä –ø—Ä–æ—Ç–æ–∫–æ–ª–∞:** {analysis['protocol_number']}\n")

        markdown_parts.append("\n")

        # –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        markdown_parts.append("## –ò–ó–í–õ–ï–ß–ï–ù–ù–´–ô –¢–ï–ö–°–¢\n\n")
        if extracted_text:
            markdown_parts.append(f"```\n{extracted_text}\n```\n\n")
        else:
            markdown_parts.append("*–¢–µ–∫—Å—Ç –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å*\n\n")

        # –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        markdown_parts.append("## –ú–ï–¢–†–ò–ö–ò –û–ë–†–ê–ë–û–¢–ö–ò\n\n")
        markdown_parts.append(f"- **–î–ª–∏–Ω–∞ –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞:** {len(extracted_text)} —Å–∏–º–≤–æ–ª–æ–≤\n")
        markdown_parts.append(f"- **–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤:** {sum(analysis[key] for key in ['has_procurement', 'has_commission', 'has_winners', 'has_contracts', 'has_amounts'])}\n")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        markdown_parts.append("## –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò\n\n")
        if analysis['confidence_score'] > 0.7:
            markdown_parts.append("‚úÖ **–í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è** - –¥–æ–∫—É–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω\n")
        elif analysis['confidence_score'] > 0.4:
            markdown_parts.append("‚ö†Ô∏è **–°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å** - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n")
        else:
            markdown_parts.append("‚ùå **–ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å** - —Ç—Ä–µ–±—É–µ—Ç—Å—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏\n")

        if analysis['has_procurement'] and analysis['has_winners']:
            markdown_parts.append("‚úÖ **–ù–∞–π–¥–µ–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è—Ö –∑–∞–∫—É–ø–æ–∫** - –º–æ–∂–Ω–æ –∏–∑–≤–ª–µ–∫–∞—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ\n")

        return ''.join(markdown_parts)

    def process_pdf_protocol(self, pdf_path: Path) -> dict:
        """–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ PDF –ø—Ä–æ—Ç–æ–∫–æ–ª–∞"""
        print(f"üöÄ –û–ë–†–ê–ë–û–¢–ö–ê –ü–†–û–¢–û–ö–û–õ–ê: {pdf_path.name}")
        print("=" * 60)

        start_time = time.time()

        try:
            # –®–∞–≥ 1: –°–æ–∑–¥–∞–Ω–∏–µ thumbnail
            base64_thumbnail = self.create_optimized_thumbnail(pdf_path)

            # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            doctags = self.extract_text_with_smoldocling(base64_thumbnail)

            # –®–∞–≥ 3: –ü–∞—Ä—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞
            extracted_text = self.parse_doctags_to_text(doctags)

            # –®–∞–≥ 4: –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
            analysis = self.analyze_protocol_content(extracted_text)

            # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            markdown_report = self.generate_markdown_report(pdf_path, extracted_text, analysis)

            processing_time = time.time() - start_time

            result = {
                "success": True,
                "pdf_file": str(pdf_path),
                "processing_time": processing_time,
                "extracted_text": extracted_text,
                "analysis": analysis,
                "markdown_report": markdown_report,
                "doctags": doctags,
                "thumbnail_size_kb": len(base64_thumbnail) // 1024
            }

        except Exception as e:
            processing_time = time.time() - start_time
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

            result = {
                "success": False,
                "pdf_file": str(pdf_path),
                "processing_time": processing_time,
                "error": str(e)
            }

        return result

    def save_results(self, result: dict, pdf_path: Path):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        if not result["success"]:
            print("‚ùå –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –Ω–µ—É–¥–∞—á–µ–π, —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            return

        base_name = pdf_path.stem

        # Markdown –æ—Ç—á–µ—Ç
        markdown_file = self.output_dir / f"{base_name}_report.md"
        with open(markdown_file, "w", encoding="utf-8") as f:
            f.write(result["markdown_report"])

        # JSON —Å –ø–æ–ª–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        json_file = self.output_dir / f"{base_name}_data.json"
        with open(json_file, "w", encoding="utf-8") as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        # –ò—Å—Ö–æ–¥–Ω—ã–µ DocTags
        doctags_file = self.output_dir / f"{base_name}_doctags.txt"
        with open(doctags_file, "w", encoding="utf-8") as f:
            f.write(result["doctags"])

        print("üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:")
        print(f"   üìÑ –û—Ç—á–µ—Ç: {markdown_file}")
        print(f"   üìä –î–∞–Ω–Ω—ã–µ: {json_file}")
        print(f"   üìù DocTags: {doctags_file}")

    def process_single_file(self, pdf_path: str) -> dict:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ PDF —Ñ–∞–π–ª–∞"""
        pdf_path = Path(pdf_path)

        if not pdf_path.exists():
            raise FileNotFoundError(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_path}")

        if not self.wait_for_server_ready():
            raise ConnectionError("–°–µ—Ä–≤–µ—Ä SmolDocling –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

        result = self.process_pdf_protocol(pdf_path)
        self.save_results(result, pdf_path)

        return result

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    if len(sys.argv) != 2:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python smoldocling_pdf_processor.py <–ø—É—Ç—å_–∫_pdf>")
        print("–ü—Ä–∏–º–µ—Ä: python smoldocling_pdf_processor.py /path/to/protocol.pdf")
        sys.exit(1)

    pdf_file = sys.argv[1]

    try:
        processor = SmolDoclingPDFProcessor()
        result = processor.process_single_file(pdf_file)

        if result["success"]:
            print("\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
            print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {processor.output_dir}")
            print(f"‚è±Ô∏è –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {result['processing_time']:.2f} —Å–µ–∫")
            print(f"üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['analysis']['confidence_score']:.2f}")

            # –ü—Ä–µ–≤—å—é –∏–∑–≤–ª–µ—á–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            text_preview = result['extracted_text'][:200] + "..." if len(result['extracted_text']) > 200 else result['extracted_text']
            print(f"üìù –¢–µ–∫—Å—Ç: {text_preview}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            sys.exit(1)

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
