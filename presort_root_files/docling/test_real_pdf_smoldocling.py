#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∞–ª—å–Ω–æ–≥–æ PDF —Ñ–∞–π–ª–∞ —á–µ—Ä–µ–∑ SmolDocling —Å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–µ–π –≤ Markdown
"""
import os
import sys
import json
import time
import base64
from pathlib import Path
from datetime import datetime
from PIL import Image
import io

try:
    import openai
    OPENAI_SDK_AVAILABLE = True
except ImportError:
    OPENAI_SDK_AVAILABLE = False
    print("‚ö†Ô∏è  openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install openai")

try:
    from pdf2image import convert_from_path
    PDF2IMAGE_AVAILABLE = True
except ImportError:
    PDF2IMAGE_AVAILABLE = False
    print("‚ö†Ô∏è  pdf2image –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install pdf2image")
    print("   –¢–∞–∫–∂–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è: sudo apt-get install poppler-utils")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è SmolDocling
API_TOKEN = "ZDRhOWQ3OTAtZjU4MC00MzA2LThhNTgtMDU1NGFlMjE4OWRl.85a830f9340966e0ad1fd1642884c7c8"
BASE_URL = "https://d63e30af-085a-49f0-9724-8162da967af2.modelrun.inference.cloud.ru/v1"
MODEL_NAME = "model-run-4qigw-disease"

# –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
TEST_FILE = "/root/winners_preprocessor/normalized/UNIT_43a02eedd2bbca86/files/! –ü—Ä–æ—Ç–æ–∫–æ–ª –≠–ú-17.pdf"
OUTPUT_DIR = Path("/root/winners_preprocessor/output_real_pdf_test")

class SmolDoclingProcessor:
    def __init__(self):
        if not OPENAI_SDK_AVAILABLE:
            raise ImportError("openai SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")

        self.client = openai.OpenAI(
            api_key=API_TOKEN,
            base_url=BASE_URL,
            timeout=120.0
        )
        self.model = MODEL_NAME
        OUTPUT_DIR.mkdir(exist_ok=True)

    def wait_for_server_ready(self, max_wait_time: int = 60) -> bool:
        """Wait for the inference server to be ready"""
        print(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞ SmolDocling (–º–∞–∫—Å–∏–º—É–º {max_wait_time} —Å–µ–∫—É–Ω–¥)...")

        start_time = time.time()
        while time.time() - start_time < max_wait_time:
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": "Hello"}],
                    max_tokens=10,
                    temperature=0.5
                )
                if response.choices[0].message.content:
                    print("‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
                    return True
            except Exception as e:
                print(f"    –°–µ—Ä–≤–µ—Ä –µ—â–µ –Ω–µ –≥–æ—Ç–æ–≤... ({str(e)[:50]}...)")
                time.sleep(5)

        print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ —Å—Ç–∞–ª –¥–æ—Å—Ç—É–ø–µ–Ω –≤ —Ç–µ—á–µ–Ω–∏–µ –æ—Ç–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏")
        return False

    def create_optimized_thumbnail(self, pdf_path: Path) -> str:
        """–°–æ–∑–¥–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π thumbnail –¥–ª—è SmolDocling"""
        print(f"   –°–æ–∑–¥–∞–Ω–∏–µ thumbnail –∏–∑ PDF: {pdf_path.name}")

        if not PDF2IMAGE_AVAILABLE:
            raise ImportError("pdf2image not installed")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –í–´–°–û–ö–ò–ú DPI –¥–ª—è –ª—É—á—à–µ–≥–æ OCR
        pil_images = convert_from_path(str(pdf_path), dpi=300, first_page=1, last_page=1)
        img = pil_images[0]

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ RGB –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
        if img.mode != 'RGB':
            img = img.convert('RGB')

        # –°–æ–∑–¥–∞—Ç—å thumbnail –º–∞–∫—Å–∏–º—É–º 1200x1200 –ø–∏–∫—Å–µ–ª–µ–π (—É–≤–µ–ª–∏—á–µ–Ω–æ!)
        img.thumbnail((1200, 1200), Image.Resampling.LANCZOS)

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∫–∞–∫ JPEG —Å –∫–∞—á–µ—Å—Ç–≤–æ–º 85% (—É–≤–µ–ª–∏—á–µ–Ω–æ!)
        img_byte_arr = io.BytesIO()
        img.save(img_byte_arr, format='JPEG', quality=85, optimize=True)
        base64_img = base64.b64encode(img_byte_arr.getvalue()).decode('utf-8')

        print(f"   ‚úÖ Thumbnail —Å–æ–∑–¥–∞–Ω: {img.size}, base64 –¥–ª–∏–Ω–∞: {len(base64_img)}")
        return base64_img

    def process_pdf_with_smoldocling(self, pdf_path: Path) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF —á–µ—Ä–µ–∑ SmolDocling"""
        print(f"\nüß† –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF —á–µ—Ä–µ–∑ SmolDocling: {pdf_path.name}")

        try:
            # –°–æ–∑–¥–∞—Ç—å thumbnail
            base64_thumbnail = self.create_optimized_thumbnail(pdf_path)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è SmolDocling
            prompt = "Convert this document page to structured docling format with full text extraction."
            image_url = f"data:image/jpeg;base64,{base64_thumbnail}"

            messages_content = [
                {"type": "text", "text": prompt},
                {"type": "image_url", "image_url": {"url": image_url}}
            ]

            print("   –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ SmolDocling...")
            start_time = time.time()

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": messages_content}],
                max_tokens=4000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
                temperature=0.0
            )

            processing_time = time.time() - start_time
            tokens_used = response.usage.total_tokens if response.usage else 0

            doctags = response.choices[0].message.content
            print(f"   ‚úÖ –£–°–ü–ï–•! –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω –∑–∞ {processing_time:.2f} —Å–µ–∫—É–Ω–¥")
            print(f"   –¢–æ–∫–µ–Ω–æ–≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {tokens_used}")
            print(f"   –î–ª–∏–Ω–∞ DocTags: {len(doctags)} —Å–∏–º–≤–æ–ª–æ–≤")

            return doctags

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {pdf_path.name}: {e}")
            return None

    def doctags_to_markdown(self, doctags: str, pdf_path: Path) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DocTags –≤ Markdown"""
        print("   –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è DocTags –≤ Markdown...")

        # –†–∞–∑–¥–µ–ª–∏—Ç—å –Ω–∞ —Å—Ç—Ä–æ–∫–∏
        lines = doctags.strip().split('\n')
        markdown_content = []
        current_text = []

        for line in lines:
            if not line.strip():
                continue

            parts = line.split('>')
            if len(parts) >= 5:  # x1>y1>x2>y2>content –∏–ª–∏ type>x1>y1>x2>y2>page>content
                # –ù–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç–æ–≤—É—é —á–∞—Å—Ç—å (–ø–æ—Å–ª–µ–¥–Ω—è—è —á–∞—Å—Ç—å –ø–æ—Å–ª–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç)
                content = parts[-1] if len(parts) > 4 else ""
                if content.strip():
                    current_text.append(content.strip())

        # –û–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ç–µ–∫—Å—Ç –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        if current_text:
            full_text = ' '.join(current_text)
            # –†–∞–∑–±–∏—Ç—å –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏
            sentences = full_text.split('. ')
            for sentence in sentences:
                if sentence.strip():
                    markdown_content.append(sentence.strip() + '.')

        markdown = '\n\n'.join(markdown_content) if markdown_content else "*–¢–µ–∫—Å—Ç –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω*"

        # –î–æ–±–∞–≤–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫
        header = f"# –°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {pdf_path.name}\n\n"
        header += f"**–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —á–µ—Ä–µ–∑ SmolDocling**\n"
        header += f"**–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n"

        return header + markdown

    def extract_winners_info(self, doctags: str) -> dict:
        """–ò–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è—Ö –∏–∑ DocTags"""
        print("   –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è—Ö...")

        # –û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç –æ—Ç –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–ª—å–∫–æ —á–∏—Ç–∞–µ–º—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        text_content = doctags.replace('>', ' ').replace('<', ' ').lower()

        winners_info = {
            "has_protocol": "–ø—Ä–æ—Ç–æ–∫–æ–ª" in text_content,
            "has_winners": any(word in text_content for word in ["–ø–æ–±–µ–¥–∏—Ç–µ–ª", "–ø–æ–±–µ–¥–∏–ª", "–≤—ã–∏–≥—Ä–∞–ª", "–ø–æ–±–µ–¥–∏—Ç"]),
            "has_contract": any(word in text_content for word in ["–∫–æ–Ω—Ç—Ä–∞–∫—Ç", "–¥–æ–≥–æ–≤–æ—Ä", "—Å–¥–µ–ª–∫", "–∑–∞–∫—É–ø–∫"]),
            "has_amount": any(word in text_content for word in ["—Ä—É–±–ª", "—Å—É–º–º", "—Å—Ç–æ–∏–º–æ—Å—Ç", "—Ü–µ–Ω"]),
            "has_commission": any(word in text_content for word in ["–∫–æ–º–∏—Å—Å–∏", "–∑–∞—Å–µ–¥–∞–Ω–∏", "—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏"]),
            "document_type": "protocol" if "–ø—Ä–æ—Ç–æ–∫–æ–ª" in text_content else "unknown",
            "extracted_text_length": len(text_content.strip())
        }

        return winners_info

    def run(self):
        print("üéØ –¢–ï–°–¢ –û–ë–†–ê–ë–û–¢–ö–ò –†–ï–ê–õ–¨–ù–û–ì–û PDF –ß–ï–†–ï–ó SMOLDOCLING")
        print(f"–§–∞–π–ª: {TEST_FILE}")

        if not self.wait_for_server_ready():
            print("‚ùå –°–µ—Ä–≤–µ—Ä –Ω–µ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ.")
            return

        print("‚úÖ –°–µ—Ä–≤–µ—Ä –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")

        pdf_path = Path(TEST_FILE)
        if not pdf_path.exists():
            print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {pdf_path}")
            return

        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å PDF
        doctags = self.process_pdf_with_smoldocling(pdf_path)

        if not doctags:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å DocTags")
            return

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å DocTags
        doctags_file = OUTPUT_DIR / f"{pdf_path.stem}_doctags.txt"
        with open(doctags_file, "w", encoding="utf-8") as f:
            f.write(doctags)
        print(f"üíæ DocTags —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {doctags_file}")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ Markdown
        markdown_content = self.doctags_to_markdown(doctags, pdf_path)

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å Markdown
        markdown_file = OUTPUT_DIR / f"{pdf_path.stem}_content.md"
        with open(markdown_file, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        print(f"üíæ Markdown —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {markdown_file}")

        # –ò–∑–≤–ª–µ—á—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è—Ö
        winners_info = self.extract_winners_info(doctags)

        # –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π
        winners_file = OUTPUT_DIR / f"{pdf_path.stem}_winners_analysis.json"
        with open(winners_file, "w", encoding="utf-8") as f:
            json.dump({
                "pdf_file": str(pdf_path),
                "processing_date": datetime.now().isoformat(),
                "winners_info": winners_info,
                "doctags_preview": doctags[:500] + "..." if len(doctags) > 500 else doctags
            }, f, indent=2, ensure_ascii=False)
        print(f"üíæ –ê–Ω–∞–ª–∏–∑ –ø–æ–±–µ–¥–∏—Ç–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {winners_file}")

        # –í—ã–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print("\nüéâ –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")
        print(f"üìÑ Markdown –¥–ª–∏–Ω–∞: {len(markdown_content)} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"üèÜ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–±–µ–¥–∏—Ç–µ–ª—è—Ö: {winners_info}")

        print("\nüìã –ü–†–ï–í–¨–Æ MARKDOWN:")
        print("-" * 50)
        preview = markdown_content[:1000] + "..." if len(markdown_content) > 1000 else markdown_content
        print(preview)
        print("-" * 50)

if __name__ == "__main__":
    processor = SmolDoclingProcessor()
    processor.run()
