#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF —á–µ—Ä–µ–∑ PaddleOCR-VL ML Inference
–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF —Ñ–∞–π–ª—ã, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É—è –∏—Ö –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—è –Ω–∞ OCR
"""
import os
import sys
import json
import time
import base64
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

import requests
from pdf2image import convert_from_path
from PIL import Image
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ML Inference
ML_INFERENCE_URL = os.getenv(
    "ML_INFERENCE_URL",
    "https://c5b0e67c-1426-48e5-b2cd-c86c0acdb5c3.modelrun.inference.cloud.ru"
).rstrip("/")

# API Key –¥–ª—è –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏
ML_INFERENCE_API_KEY = os.getenv(
    "ML_INFERENCE_API_KEY",
    "ZDRhOWQ3OTAtZjU4MC00MzA2LThhNTgtMDU1NGFlMjE4OWRl.85a830f9340966e0ad1fd1642884c7c8"
)

# –¢–∞–π–º–∞—É—Ç—ã
REQUEST_TIMEOUT = 300  # 5 –º–∏–Ω—É—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
HEALTH_CHECK_TIMEOUT = 10


def get_headers() -> dict:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π"""
    return {
        "Authorization": f"Bearer {ML_INFERENCE_API_KEY}",
        "Accept": "application/json"
    }


def check_health() -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ ML Inference —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        response = requests.get(
            f"{ML_INFERENCE_URL}/health",
            headers=get_headers(),
            timeout=HEALTH_CHECK_TIMEOUT
        )
        if response.status_code == 200:
            health_data = response.json()
            print(f"‚úÖ Health check: {health_data}")
            return health_data.get("status") == "healthy"
        else:
            print(f"‚ùå Health check failed: {response.status_code}")
            print(f"   –û—Ç–≤–µ—Ç: {response.text[:200]}")
            return False
    except Exception as e:
        print(f"‚ùå Health check error: {e}")
        return False


def pdf_to_images(pdf_path: Path, dpi: int = 200) -> list[Image.Image]:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PDF –≤ —Å–ø–∏—Å–æ–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º)"""
    try:
        print(f"üìÑ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {pdf_path.name}")
        images = convert_from_path(str(pdf_path), dpi=dpi)
        print(f"   –ò–∑–≤–ª–µ—á–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {len(images)}")
        return images
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ PDF: {e}")
        raise


def image_to_base64(image: Image.Image) -> str:
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç PIL Image –≤ Base64 —Å—Ç—Ä–æ–∫—É"""
    buffer = io.BytesIO()
    image.save(buffer, format='PNG')
    img_bytes = buffer.getvalue()
    return base64.b64encode(img_bytes).decode('utf-8')


def process_image_via_ocr(image: Image.Image, page_num: int, total_pages: int) -> Optional[Dict[str, Any]]:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–∞ OCR –æ–±—Ä–∞–±–æ—Ç–∫—É"""
    try:
        print(f"   üì§ –û—Ç–ø—Ä–∞–≤–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}/{total_pages} –Ω–∞ OCR...")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ Base64
        image_base64 = image_to_base64(image)
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å
        start_time = time.time()
        response = requests.post(
            f"{ML_INFERENCE_URL}/ocr",
            headers=get_headers(),
            data={"image_base64": f"data:image/png;base64,{image_base64}"},
            timeout=REQUEST_TIMEOUT
        )
        elapsed_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            print(f"      ‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∑–∞ {elapsed_time:.2f}s")
            return {
                "page": page_num,
                "status": "success",
                "processing_time": elapsed_time,
                "result": result
            }
        else:
            print(f"      ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {response.status_code}")
            print(f"         –û—Ç–≤–µ—Ç: {response.text[:200]}")
            return {
                "page": page_num,
                "status": "error",
                "error": f"HTTP {response.status_code}: {response.text[:200]}",
                "processing_time": elapsed_time
            }
            
    except Exception as e:
        print(f"      ‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
        return {
            "page": page_num,
            "status": "error",
            "error": str(e)
        }


def process_pdf_file(pdf_path: Path, max_pages: Optional[int] = None) -> Dict[str, Any]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç PDF —Ñ–∞–π–ª —á–µ—Ä–µ–∑ OCR"""
    print(f"\n{'='*60}")
    print(f"üìÑ –û–ë–†–ê–ë–û–¢–ö–ê PDF: {pdf_path.name}")
    print(f"{'='*60}")
    
    start_time = time.time()
    results = {
        "file": str(pdf_path),
        "file_size": pdf_path.stat().st_size,
        "timestamp": datetime.now().isoformat(),
        "pages": [],
        "summary": {}
    }
    
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º PDF –≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        images = pdf_to_images(pdf_path)
        
        if max_pages:
            images = images[:max_pages]
            print(f"   –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ {len(images)} —Å—Ç—Ä–∞–Ω–∏—Ü")
        
        total_pages = len(images)
        results["summary"]["total_pages"] = total_pages
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        successful = 0
        failed = 0
        total_processing_time = 0
        
        for idx, image in enumerate(images, 1):
            page_result = process_image_via_ocr(image, idx, total_pages)
            if page_result:
                results["pages"].append(page_result)
                if page_result.get("status") == "success":
                    successful += 1
                    total_processing_time += page_result.get("processing_time", 0)
                else:
                    failed += 1
        
        elapsed_time = time.time() - start_time
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        results["summary"].update({
            "successful_pages": successful,
            "failed_pages": failed,
            "total_processing_time": total_processing_time,
            "average_page_time": total_processing_time / successful if successful > 0 else 0,
            "total_elapsed_time": elapsed_time
        })
        
        print(f"\n‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞:")
        print(f"   –£—Å–ø–µ—à–Ω–æ: {successful}/{total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
        print(f"   –û—à–∏–±–æ–∫: {failed}/{total_pages} —Å—Ç—Ä–∞–Ω–∏—Ü")
        print(f"   –û–±—â–µ–µ –≤—Ä–µ–º—è: {elapsed_time:.2f}s")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {total_processing_time/successful:.2f}s" if successful > 0 else "")
        
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        results["error"] = str(e)
        results["summary"]["status"] = "failed"
    
    return results


def save_results(results: Dict[str, Any], output_dir: Path):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON –∏ Markdown"""
    output_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = Path(results["file"]).stem
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º JSON
    json_path = output_dir / f"{timestamp}_{base_name}_results.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {json_path}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º Markdown –æ—Ç—á–µ—Ç
    md_path = output_dir / f"{timestamp}_{base_name}_report.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(f"# –û—Ç—á–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ PDF: {base_name}\n\n")
        f.write(f"**–î–∞—Ç–∞:** {results['timestamp']}\n\n")
        f.write(f"**–§–∞–π–ª:** {results['file']}\n")
        f.write(f"**–†–∞–∑–º–µ—Ä:** {results['file_size'] / 1024:.1f} KB\n\n")
        
        summary = results.get("summary", {})
        f.write("## –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n\n")
        f.write(f"- –í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {summary.get('total_pages', 0)}\n")
        f.write(f"- –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {summary.get('successful_pages', 0)}\n")
        f.write(f"- –û—à–∏–±–æ–∫: {summary.get('failed_pages', 0)}\n")
        f.write(f"- –û–±—â–µ–µ –≤—Ä–µ–º—è: {summary.get('total_elapsed_time', 0):.2f}s\n")
        f.write(f"- –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É: {summary.get('average_page_time', 0):.2f}s\n\n")
        
        f.write("## –î–µ—Ç–∞–ª–∏ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º\n\n")
        for page_result in results.get("pages", []):
            f.write(f"### –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_result.get('page')}\n\n")
            f.write(f"- –°—Ç–∞—Ç—É—Å: {page_result.get('status')}\n")
            if page_result.get("status") == "success":
                result_data = page_result.get("result", {})
                f.write(f"- –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {page_result.get('processing_time', 0):.2f}s\n")
                if "local_files" in result_data:
                    f.write(f"- –õ–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã: {result_data['local_files']}\n")
                if "s3_files" in result_data:
                    f.write(f"- S3 —Ñ–∞–π–ª—ã: {result_data['s3_files']}\n")
            else:
                f.write(f"- –û—à–∏–±–∫–∞: {page_result.get('error', 'Unknown')}\n")
            f.write("\n")
    
    print(f"üíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {md_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("="*60)
    print("üß™ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PADDLEOCR-VL ML INFERENCE")
    print("="*60)
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ health
    print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–∏—Å–∞...")
    if not check_health():
        print("‚ùå –°–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ ML_INFERENCE_URL")
        sys.exit(1)
    
    # –ü—É—Ç–∏ –∫ —Ç–µ—Å—Ç–æ–≤—ã–º —Ñ–∞–π–ª–∞–º
    test_files = [
        Path("/root/winners_preprocessor/pilot_winers223/data/pending/_legacy_ready/–ü—Ä–æ—Ç–æ–∫–æ–ª_–ø–æ–¥–≤–µ–¥–µ–Ω–∏—è_–∏—Ç–æ–≥–æ–≤ ‚Ññ 2323-2503691630.pdf"),
        Path("/root/winners_preprocessor/pilot_winers223/data/pending/_legacy_ready/–ø—Ä–æ—Ç–æ–∫–æ–ª.pdf")
    ]
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤
    existing_files = [f for f in test_files if f.exists()]
    if not existing_files:
        print("‚ùå –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        sys.exit(1)
    
    print(f"\n2. –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(existing_files)}")
    
    # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    output_dir = Path("/root/winners_preprocessor/paddle_docker_servise/test_results")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Ñ–∞–π–ª–∞
    all_results = []
    for pdf_file in existing_files:
        try:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 3 —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è —Ç–µ—Å—Ç–∞
            result = process_pdf_file(pdf_file, max_pages=3)
            all_results.append(result)
            save_results(result, output_dir)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {pdf_file.name}: {e}")
    
    # –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    print(f"\n{'='*60}")
    print("üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print(f"{'='*60}")
    
    total_files = len(all_results)
    total_pages = sum(r.get("summary", {}).get("total_pages", 0) for r in all_results)
    total_successful = sum(r.get("summary", {}).get("successful_pages", 0) for r in all_results)
    total_failed = sum(r.get("summary", {}).get("failed_pages", 0) for r in all_results)
    
    print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {total_files}")
    print(f"–í—Å–µ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {total_pages}")
    print(f"–£—Å–ø–µ—à–Ω–æ: {total_successful}")
    print(f"–û—à–∏–±–æ–∫: {total_failed}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
    summary_path = output_dir / f"summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "ml_inference_url": ML_INFERENCE_URL,
            "total_files": total_files,
            "total_pages": total_pages,
            "successful_pages": total_successful,
            "failed_pages": total_failed,
            "results": all_results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\nüíæ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç: {summary_path}")


if __name__ == "__main__":
    main()

