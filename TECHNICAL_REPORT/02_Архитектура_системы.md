# АРХИТЕКТУРА СИСТЕМЫ

## Микросервисная архитектура

Система Winners223 построена на принципах микросервисной архитектуры, что обеспечивает модульность, масштабируемость и независимость компонентов.

### Принципы архитектуры

**Разделение ответственности:**
Каждый микросервис отвечает за конкретную задачу, что упрощает разработку, тестирование и масштабирование.

**Независимое развертывание:**
Компоненты могут развертываться независимо, что позволяет обновлять отдельные части системы без остановки всей системы.

**Изоляция ошибок:**
Проблемы в одном компоненте не влияют на работу других компонентов, что повышает надежность системы.

**Горизонтальное масштабирование:**
Каждый компонент может масштабироваться независимо в зависимости от нагрузки.

---

## Основные компоненты системы

### 1. Router/Preprocessor

**Назначение:** Классификация и предобработка документов перед передачей в Docling.

**Основные функции:**

**Определение типа файла:**
- Использование трех источников истины (MIME type, Magic Bytes, File Extension)
- Decision Engine с 7 сценариями принятия решений
- Обработка неоднозначных файлов через Ambiguous Handler
- Нормализация расширений файлов

**Распаковка архивов:**
- Поддержка ZIP, RAR (включая RAR5), 7z форматов
- Защита от zip bomb через лимиты размера и количества файлов
- Валидация архивов перед распаковкой
- Санитизация имен файлов для защиты от path traversal

**Классификация PDF:**
- Анализ текстового слоя через pypdf
- Определение необходимости OCR обработки
- Разделение на pdf_text и pdf_scan routes

**Конвертация DOC → DOCX:**
- Автоматическая конвертация через LibreOffice
- Мониторинг директорий на наличие .doc файлов
- Headless режим работы без GUI

**Создание manifest.json:**
- Генерация уникальных unit_id для каждого набора файлов
- Связывание файлов из архивов в единые unit'ы
- Сохранение метаданных для Docling pipeline
- Определение route'ов обработки

**Нормализация unit'ов:**
- Создание отдельных директорий для каждого unit'а
- Копирование файлов в normalized структуру
- Подготовка данных для обработки Docling

**Технологии:**
- FastAPI для REST API
- python-magic для определения типов файлов
- pypdf для проверки PDF text layer
- 7z/unrar для распаковки архивов
- LibreOffice для конвертации DOC → DOCX

**API Endpoints:**
- `GET /health` - проверка здоровья сервиса
- `POST /upload` - загрузка файла для обработки
- `POST /webhook` - webhook для внешних триггеров
- `POST /process_now` - немедленная обработка всех файлов из input/
- `GET /status/{unit_id}` - статус обработки unit'а
- `GET /metrics/processing` - метрики обработки
- `GET /metrics/summary` - сводка метрик

**Метрики производительности:**
- Входных файлов: 60
- Создано unit'ов: 64
- Успешность: 100%
- Время preprocessing: ~2.31 сек
- Ошибок: 0

### 2. Docling Service

**Назначение:** Основной движок обработки документов (OCR, Layout Analysis, Table Extraction).

**Основные функции:**

**OCR обработка:**
- Специализированный Docling OCR для сканированных PDF
- Fallback на pdfplumber и pytesseract для надежности
- Оптимизация параметров OCR для качества и скорости

**Извлечение текста:**
- Text Extraction для PDF с текстовым слоем
- Извлечение текста из DOCX файлов
- Обработка HTML документов

**Layout Analysis:**
- Определение блоков документа (заголовки, параграфы, списки)
- Анализ reading order (порядок чтения)
- Определение структуры документа

**Table Extraction:**
- Извлечение таблиц с сохранением структуры
- Определение заголовков и данных таблиц
- Экспорт таблиц в структурированном формате

**Export форматы:**
- JSON - структурированные данные для программной обработки
- Markdown - читаемый формат для людей
- HTML - веб-совместимый формат

**Route'ы обработки:**

**pdf_scan:**
PDF сканы проходят через OCR pipeline, затем Layout Analysis и Table Extraction. Используется для документов без текстового слоя.

**pdf_text:**
PDF с текстовым слоем обрабатываются через Text Extraction, затем Layout Analysis и Table Extraction. Более быстрая обработка без OCR.

**docx:**
DOCX файлы обрабатываются через Text Extraction, затем Layout Analysis и Table Extraction. Наивысшее качество извлечения.

**html_text:**
HTML документы обрабатываются через парсинг HTML, затем извлечение текста и структуры.

**mixed:**
Смешанные типы файлов обрабатываются по отдельности, затем результаты объединяются.

**Методы обработки:**

**Docling SDK (приоритетный):**
Основной метод для OCR и извлечения текста. Использует специализированные модели для документов.

**pdfplumber (fallback для PDF):**
Используется когда Docling недоступен или для простых PDF файлов.

**python-docx (fallback для DOCX):**
Используется для извлечения текста и таблиц из DOCX файлов.

**BeautifulSoup (для HTML):**
Парсинг HTML документов для извлечения структурированного контента.

**pytesseract (fallback OCR):**
Финальный fallback для OCR когда другие методы недоступны.

**Метрики производительности:**
- Обработано unit'ов: 64/64
- Создано output файлов: 144
- Время обработки: ~15.96 сек
- Среднее время на unit: ~0.53 сек
- Пропускная способность: ~4 unit'ов/сек

### 3. Downloader Service

**Назначение:** Скачивание документов из внешних источников через VPN.

**Основные функции:**

**Скачивание протоколов:**
- Получение протоколов из MongoDB
- Скачивание документов с zakupki.gov.ru через VPN
- Управление статусами протоколов (pending → downloading → downloaded)

**Атомарное резервирование:**
- Использование find_one_and_update для атомарного изменения статуса
- Предотвращение конфликтов при параллельной работе нескольких воркеров
- Гарантия обработки каждого протокола только одним воркером

**Параллельное скачивание:**
- ThreadPoolExecutor с настраиваемым количеством потоков (до 20)
- Rate limiting для предотвращения перегрузки сервера
- Retry механизм с экспоненциальной задержкой

**Обработка ошибок:**
- Timeout: 60 секунд на файл
- Retry: 3 попытки с backoff (1, 2, 4 секунды)
- Логирование всех сбоев для анализа

**Архитектурные решения:**

**Split-tunnel VPN:**
Только трафик к zakupki.gov.ru идет через VPN, остальной трафик (SSH, MongoDB, другие сервисы) идет напрямую. Это обеспечивает безопасность основного трафика, производительность и надежность.

**Автоматическая настройка маршрутов:**
Скрипт route-up-zakupki.sh автоматически вызывается OpenVPN при поднятии туннеля и настраивает маршруты для zakupki.gov.ru.

**Метрики:**
- Протоколов обработано: 200
- Успешно скачано: 200/200 (100%)
- Файлов скачано: 213
- Время выполнения: 698 сек (~11.6 мин)
- Среднее время: 3.49 сек/протокол

### 4. Scheduler

**Назначение:** Автоматический запуск обработки по расписанию.

**Основные функции:**
- Периодический запуск обработки (cron-like)
- Вызов router API для обработки файлов из input/
- Настраиваемое расписание через переменные окружения

**Технологии:**
- APScheduler для планирования задач
- Настраиваемый cron формат расписания

**Конфигурация:**
Расписание настраивается через переменную окружения SCHEDULE_CRON в формате cron. По умолчанию запускается каждые 15 минут.

### 5. Worker

**Назначение:** Обработка протоколов из MongoDB.

**Основные функции:**
- Получение протоколов из MongoDB
- Скачивание документов по URLs
- Отправка в Router для обработки
- Обновление статусов в базе данных

**Интеграция:**
Worker интегрируется с Downloader для скачивания документов и Router для обработки файлов.

---

## Взаимодействие компонентов

### Поток обработки документов

**Шаг 1: Вход в систему**
Файлы попадают в систему двумя способами:
- Через API endpoint POST /upload (загрузка файла)
- Через файловую систему (копирование в input/ директорию)

**Шаг 2: Preprocessing (Router)**
Router получает файл и выполняет предобработку:
- Определение типа файла через Decision Engine
- Распаковка архивов (если нужно)
- Конвертация DOC → DOCX (если нужно)
- Создание manifest.json с route определением
- Сохранение в MongoDB

**Шаг 3: Обработка (Docling)**
Docling Service получает manifest из MongoDB и обрабатывает файлы:
- Выбор pipeline по route (pdf_scan/pdf_text/docx/...)
- Извлечение текста, таблиц, метаданных
- Сохранение результатов в output/ директорию
- Сохранение метрик в MongoDB

**Шаг 4: Метрики и мониторинг**
Метрики обработки сохраняются в MongoDB и доступны через API endpoints для мониторинга и анализа.

### Интеграция с внешними системами

**MongoDB:**
- Хранение manifest'ов для каждого unit'а
- Сохранение метрик обработки
- Хранение статусов протоколов для Downloader

**LibreOffice:**
- Конвертация DOC → DOCX через headless режим
- Мониторинг директорий на наличие .doc файлов

**VPN:**
- Split-tunnel конфигурация для доступа к zakupki.gov.ru
- Автоматическая настройка маршрутов

**Cloud.ru API:**
- Интеграция с Granite-Docling для OCR обработки
- Оптимизация промптов и форматов данных

---

## Форматы данных

### manifest.json структура

Manifest файл содержит всю необходимую информацию для обработки unit'а:

**Основные поля:**
- `unit_id` - уникальный идентификатор unit'а
- `created_at` - время создания unit'а
- `processing.status` - статус обработки (ready/processing/done/error)
- `processing.route` - route обработки (pdf_scan/pdf_text/docx/...)

**Информация о файлах:**
- `files[]` - массив файлов в unit'е
  - `file_id` - уникальный идентификатор файла
  - `original_name` - оригинальное имя файла
  - `path` - путь к файлу в normalized структуре
  - `detected_type` - определенный тип файла
  - `mime_type` - MIME тип файла
  - `needs_ocr` - флаг необходимости OCR
  - `sha256` - хеш файла для дедупликации
  - `size` - размер файла в байтах

**Информация об архивах:**
- `archive.is_archive` - флаг архива
- `archive.archive_id` - идентификатор архива
- `archive.original_path` - оригинальный путь к архиву
- `archive.extracted_count` - количество извлеченных файлов

### Метрики обработки

Метрики сохраняются в MongoDB для анализа производительности:

**Основные поля:**
- `session_id` - идентификатор сессии обработки
- `unit_id` - идентификатор unit'а
- `processing_times` - времена обработки по этапам
  - `total` - общее время обработки
  - `text_extraction` - время извлечения текста
  - `ocr` - время OCR обработки
  - `layout_analysis` - время анализа структуры
- `output_files` - список созданных output файлов
- `method` - использованный метод обработки
- `status` - статус обработки (completed/error)

---

## Безопасность

### Защита от zip bomb

**Лимиты размера:**
Максимальный размер распаковки ограничен через MAX_UNPACK_SIZE_MB (по умолчанию 500 MB). Это предотвращает атаки zip bomb, когда маленький архив распаковывается в огромный объем данных.

**Лимиты количества файлов:**
Максимальное количество файлов в архиве ограничено через MAX_FILES_IN_ARCHIVE (по умолчанию 1000). Это предотвращает создание архивов с миллионами файлов.

**Валидация архивов:**
Архивы проверяются на целостность перед распаковкой. Поврежденные архивы отклоняются без распаковки.

### Санитизация имен файлов

**Защита от path traversal:**
Удаление `../` и других опасных символов из имен файлов предотвращает выход за пределы целевой директории.

**Опасные символы:**
Удаление символов `<`, `>`, `:`, `"`, `|`, `?`, `*` из имен файлов для совместимости с файловыми системами.

### Изоляция контейнеров

**Docker network:**
Компоненты изолированы через Docker network, что предотвращает несанкционированный доступ между сервисами.

**Read-only volumes:**
Где возможно, используются read-only volumes для предотвращения модификации данных.

---

## Масштабирование

### Горизонтальное масштабирование

**Docker Compose:**
Текущая архитектура позволяет масштабировать компоненты через docker-compose scale команду. Например, можно запустить несколько экземпляров Router или Docling для увеличения пропускной способности.

**Ограничения:**
Docker Compose не обеспечивает автоматическое масштабирование и балансировку нагрузки. Для production рекомендуется миграция на Kubernetes.

### Вертикальное масштабирование

**Увеличение ресурсов:**
Увеличение CPU и RAM на сервере позволяет обрабатывать больше файлов одновременно и обрабатывать большие файлы.

**Оптимизация параметров:**
Настройка параметров OCR_THREADS и других параметров позволяет оптимизировать использование ресурсов.

### Асинхронная обработка

**Текущая реализация:**
Обработка происходит последовательно, что ограничивает производительность.

**Планируемые улучшения:**
Добавление Redis для очереди задач и использование RQ или Celery для асинхронной обработки позволит значительно увеличить пропускную способность.

---

## Заключение раздела

Архитектура системы Winners223 демонстрирует профессиональный подход к проектированию микросервисных систем. Разделение ответственности, изоляция компонентов и масштабируемость обеспечивают гибкость и надежность системы.

Ключевые преимущества архитектуры:
- Модульность позволяет независимо разрабатывать и обновлять компоненты
- Масштабируемость обеспечивает обработку больших объемов данных
- Надежность достигается через изоляцию ошибок и fallback механизмы
- Безопасность реализована на всех уровнях системы

Следующий раздел содержит детальный анализ решенных технических проблем, которые демонстрируют сложность задач и качество решений.




