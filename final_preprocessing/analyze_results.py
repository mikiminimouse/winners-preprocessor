#!/usr/bin/env python3
"""
–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏.
"""
import sys
from pathlib import Path
from collections import Counter

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é
sys.path.insert(0, str(Path(__file__).parent))

def analyze_results():
    """–î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏."""
    date = "2025-03-18"
    base_dir = Path(f"Data/{date}")
    
    print("=" * 60)
    print("–î–ï–¢–ê–õ–¨–ù–´–ô –ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Input
    input_dir = base_dir / "Input"
    input_units = [d for d in input_dir.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
    print(f"\nüìÅ Input: {len(input_units)} UNIT")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç—ã–µ UNIT
    empty_units = []
    for unit in input_units:
        files = [f for f in unit.iterdir() if f.is_file() and f.name not in ["manifest.json", "audit.log.jsonl"]]
        if not files:
            empty_units.append(unit.name)
    
    if empty_units:
        print(f"  ‚ö†Ô∏è  –ü—É—Å—Ç—ã–µ UNIT (–±–µ–∑ —Ñ–∞–π–ª–æ–≤): {len(empty_units)}")
        print(f"     –ü—Ä–∏–º–µ—Ä—ã: {', '.join(empty_units[:5])}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Merge
    merge_dir = base_dir / "Merge"
    merge_units = []
    for merge_subdir in merge_dir.rglob("UNIT_*"):
        if merge_subdir.is_dir():
            merge_units.append(merge_subdir)
    
    print(f"\nüìÅ Merge: {len(merge_units)} UNIT")
    
    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
    merge_by_type = Counter()
    for unit in merge_units:
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ Merge
        rel_path = unit.relative_to(merge_dir)
        path_parts = rel_path.parts
        if len(path_parts) >= 2:
            merge_by_type[f"{path_parts[0]}/{path_parts[1]}"] += 1
    
    for merge_type, count in merge_by_type.most_common():
        print(f"  {merge_type}: {count} UNIT")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Processing
    processing_dir = base_dir / "Processing"
    processing_units = []
    for proc_subdir in processing_dir.rglob("UNIT_*"):
        if proc_subdir.is_dir():
            processing_units.append(proc_subdir)
    
    print(f"\nüìÅ Processing: {len(processing_units)} UNIT")
    
    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
    proc_by_type = Counter()
    for unit in processing_units:
        rel_path = unit.relative_to(processing_dir)
        path_parts = rel_path.parts
        if len(path_parts) >= 2:
            proc_by_type[f"{path_parts[0]}/{path_parts[1]}"] += 1
    
    for proc_type, count in proc_by_type.most_common():
        print(f"  {proc_type}: {count} UNIT")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º Exceptions
    exceptions_dir = base_dir / "Exceptions"
    exceptions_units = []
    for exc_subdir in exceptions_dir.rglob("UNIT_*"):
        if exc_subdir.is_dir():
            exceptions_units.append(exc_subdir)
    
    print(f"\nüìÅ Exceptions: {len(exceptions_units)} UNIT")
    
    # –†–∞–∑–±–∏–≤–∫–∞ –ø–æ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
    exc_by_type = Counter()
    for unit in exceptions_units:
        rel_path = unit.relative_to(exceptions_dir)
        path_parts = rel_path.parts
        if len(path_parts) >= 2:
            exc_by_type[f"{path_parts[0]}/{path_parts[1]}"] += 1
    
    for exc_type, count in exc_by_type.most_common():
        print(f"  {exc_type}: {count} UNIT")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π:")
    wrong_dirs = []
    for category in ["Exceptions", "Merge", "Processing"]:
        category_dir = Path(f"Data/{category}/{date}")
        if category_dir.exists():
            wrong_units = len([d for d in category_dir.rglob("UNIT_*") if d.is_dir()])
            wrong_dirs.append((str(category_dir), wrong_units))
    
    if wrong_dirs:
        print(f"  ‚ùå –ù–∞–π–¥–µ–Ω—ã –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
        for dir_path, unit_count in wrong_dirs:
            print(f"    {dir_path}: {unit_count} UNIT")
    else:
        print(f"  ‚úÖ –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    total_processed = len(merge_units) + len(processing_units) + len(exceptions_units)
    total_input = len(input_units)
    
    print(f"\nüìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"  Input: {total_input} UNIT")
    print(f"  –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_processed} UNIT")
    print(f"  –ü—É—Å—Ç—ã–µ (unknown): {len(empty_units)} UNIT")
    print(f"  –†–∞–∑–Ω–∏—Ü–∞: {total_input - total_processed - len(empty_units)} UNIT")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ UNIT —Å —Ñ–∞–π–ª–∞–º–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã
    units_with_files = total_input - len(empty_units)
    if total_processed == units_with_files:
        print(f"\n‚úÖ –í—Å–µ UNIT —Å —Ñ–∞–π–ª–∞–º–∏ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã!")
    else:
        print(f"\n‚ö†Ô∏è  –ù–µ –≤—Å–µ UNIT –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {units_with_files} —Å —Ñ–∞–π–ª–∞–º–∏, {total_processed} –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ")

if __name__ == "__main__":
    analyze_results()
