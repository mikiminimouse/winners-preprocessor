#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ digital units —á–µ—Ä–µ–∑ Docling pipeline.

–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ UNIT (--limit)
- –§–∏–ª—å—Ç—Ä–∞—Ü–∏—é –ø–æ route (--route)
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–ª–∏—á–∏—è contract
- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ OutputDocling —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—ã Ready2Docling
"""
import sys
import logging
import argparse
import json
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime

# –í–ê–ñ–ù–û: –î–æ–±–∞–≤–ª—è–µ–º site-packages –≤ sys.path –ü–ï–†–ï–î –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º –ø—Ä–æ–µ–∫—Ç–∞
# –≠—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ –∏–º–µ–Ω (–ª–æ–∫–∞–ª—å–Ω—ã–π –º–æ–¥—É–ª—å docling_integration –Ω–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç—É–µ—Ç —Å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–º –ø–∞–∫–µ—Ç–æ–º docling)
import site
for site_dir in site.getsitepackages():
    if (Path(site_dir) / 'docling' / '__init__.py').exists():
        if site_dir not in sys.path:
            sys.path.insert(0, site_dir)
        break

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É –ø–æ—Å–ª–µ site-packages
_project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(_project_root))

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏
# –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–æ–¥—É–ª–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø–∞–∫–µ—Ç docling —á–µ—Ä–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É –≤ runner.py –∏ config.py
from docling_integration.pipeline import DoclingPipeline
from docprep.core.contract import load_contract

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–µ–ª–∞–µ–º —ç—Ç–æ –ø–æ—Å–ª–µ –∏–º–ø–æ—Ä—Ç–æ–≤, —á—Ç–æ–±—ã logger –±—ã–ª –¥–æ—Å—Ç—É–ø–µ–Ω)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def check_contracts(ready2docling_dir: Path, limit: Optional[int] = None) -> Dict[str, Any]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ contract —Ñ–∞–π–ª–æ–≤ –≤ UNIT.
    
    Args:
        ready2docling_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è Ready2Docling
        limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã—Ö UNIT
        
    Returns:
        –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∏
    """
    unit_dirs = list(ready2docling_dir.rglob("UNIT_*"))
    unit_dirs = [d for d in unit_dirs if d.is_dir()]
    
    if limit:
        unit_dirs = unit_dirs[:limit]
    
    results = {
        "total": len(unit_dirs),
        "with_contract": 0,
        "without_contract": 0,
        "units_without_contract": [],
    }
    
    for unit_dir in unit_dirs:
        contract_path = unit_dir / "docprep.contract.json"
        if contract_path.exists():
            results["with_contract"] += 1
        else:
            results["without_contract"] += 1
            results["units_without_contract"].append(str(unit_dir.relative_to(ready2docling_dir)))
    
    return results


def filter_units_by_route(unit_dirs: list[Path], route: str) -> list[Path]:
    """
    –§–∏–ª—å—Ç—Ä—É–µ—Ç UNIT –ø–æ route –∏–∑ contract.
    
    Args:
        unit_dirs: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ UNIT –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
        route: Route –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        
    Returns:
        –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ UNIT
    """
    filtered = []
    
    for unit_dir in unit_dirs:
        try:
            contract = load_contract(unit_dir)
            contract_route = contract.get("routing", {}).get("docling_route", "")
            if contract_route == route:
                filtered.append(unit_dir)
        except Exception:
            # –ï—Å–ª–∏ contract –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue
    
    return filtered


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è."""
    parser = argparse.ArgumentParser(
        description="Test Docling pipeline processing for digital units"
    )
    parser.add_argument(
        "--data-dir",
        type=Path,
        required=True,
        help="Path to Data directory (e.g., Data/2025-03-04)",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=20,
        help="Limit number of units to process (default: 20)",
    )
    parser.add_argument(
        "--route",
        type=str,
        default=None,
        help="Filter units by route (e.g., pdf_text, docx, xlsx)",
    )
    parser.add_argument(
        "--skip-check",
        action="store_true",
        help="Skip contract check and proceed anyway",
    )
    parser.add_argument(
        "--no-markdown",
        action="store_true",
        help="Disable markdown export (enabled by default)",
    )
    parser.add_argument(
        "--no-mongodb",
        action="store_true",
        help="Disable MongoDB export",
    )
    
    args = parser.parse_args()
    
    data_dir = Path(args.data_dir).resolve()
    ready2docling_dir = data_dir / "Ready2Docling"
    output_dir = data_dir / "OutputDocling"
    quarantine_dir = data_dir / "Quarantine"
    
    if not ready2docling_dir.exists():
        logger.error(f"Ready2Docling directory not found: {ready2docling_dir}")
        logger.info("üí° Run docprep pipeline first to prepare data")
        return 1
    
    logger.info("=" * 60)
    logger.info("Docling Pipeline Testing")
    logger.info("=" * 60)
    logger.info(f"Data directory: {data_dir}")
    logger.info(f"Ready2Docling: {ready2docling_dir}")
    logger.info(f"Output directory: {output_dir}")
    logger.info(f"Limit: {args.limit}")
    if args.route:
        logger.info(f"Route filter: {args.route}")
    logger.info("=" * 60)
    
    # –ù–∞—Ö–æ–¥–∏–º UNIT –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–Ω–∞—á–∞–ª–∞
    logger.info(f"\nFinding UNIT directories...")
    unit_dirs = list(ready2docling_dir.rglob("UNIT_*"))
    unit_dirs = [d for d in unit_dirs if d.is_dir()]
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ route –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
    if args.route:
        logger.info(f"Filtering by route: {args.route}")
        unit_dirs = filter_units_by_route(unit_dirs, args.route)
        logger.info(f"Found {len(unit_dirs)} unit(s) with route '{args.route}'")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç
    if args.limit:
        unit_dirs = unit_dirs[:args.limit]
    
    if not unit_dirs:
        logger.error("No UNIT directories found to process")
        return 1
    
    logger.info(f"Will process {len(unit_dirs)} unit(s)")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è contract –¥–ª—è UNIT –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
    if not args.skip_check:
        logger.info("Checking for contract files in selected units...")
        contract_check = {
            "total": len(unit_dirs),
            "with_contract": 0,
            "without_contract": 0,
            "units_without_contract": [],
        }
        
        for unit_dir in unit_dirs:
            contract_path = unit_dir / "docprep.contract.json"
            if contract_path.exists():
                contract_check["with_contract"] += 1
            else:
                contract_check["without_contract"] += 1
                contract_check["units_without_contract"].append(str(unit_dir.relative_to(ready2docling_dir)))
        
        logger.info(f"Contract check results:")
        logger.info(f"  Total units to process: {contract_check['total']}")
        logger.info(f"  With contract: {contract_check['with_contract']}")
        logger.info(f"  Without contract: {contract_check['without_contract']}")
        
        if contract_check['without_contract'] > 0:
            logger.warning(f"‚ö†Ô∏è  {contract_check['without_contract']} unit(s) without contract:")
            for unit_path in contract_check['units_without_contract'][:10]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                logger.warning(f"    - {unit_path}")
            if contract_check['without_contract'] > 10:
                logger.warning(f"    ... and {contract_check['without_contract'] - 10} more")
            
            logger.warning("üí° Run generate_contracts_for_ready2docling.py to generate contracts")
            if contract_check['with_contract'] == 0:
                logger.error("‚ùå No units with contracts found. Cannot proceed.")
                return 1
            else:
                logger.warning("‚ö†Ô∏è  Will skip units without contracts...")
                # –§–∏–ª—å—Ç—Ä—É–µ–º UNIT –±–µ–∑ contract
                unit_dirs = [d for d in unit_dirs if (d / "docprep.contract.json").exists()]
                logger.info(f"Proceeding with {len(unit_dirs)} unit(s) that have contracts")
    
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    output_dir.mkdir(parents=True, exist_ok=True)
    if quarantine_dir:
        quarantine_dir.mkdir(parents=True, exist_ok=True)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º pipeline
    pipeline = DoclingPipeline(
        export_json=True,
        export_markdown=not args.no_markdown,  # Markdown –≤–∫–ª—é—á–µ–Ω –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        export_mongodb=not args.no_mongodb,
        base_output_dir=output_dir,
        ready2docling_dir=ready2docling_dir,
        quarantine_dir=quarantine_dir,
        skip_failed=True,
    )
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º UNIT –Ω–∞–ø—Ä—è–º—É—é
    logger.info("\n" + "=" * 60)
    logger.info("Starting pipeline processing...")
    logger.info("=" * 60)
    
    processed_results = {
        "total_units": len(unit_dirs),
        "processed": 0,
        "succeeded": 0,
        "failed": 0,
        "results": [],
    }
    
    for i, unit_dir in enumerate(unit_dirs, 1):
        logger.info(f"\n[{i}/{len(unit_dirs)}] Processing: {unit_dir.name}")
        try:
            result = pipeline.process_unit(unit_dir)
            processed_results["processed"] += 1
            # –£–¥–∞–ª—è–µ–º –Ω–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã –∏–∑ result –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
            result_serializable = {k: v for k, v in result.items() if k != "document"}
            processed_results["results"].append(result_serializable)
            
            if result["success"]:
                processed_results["succeeded"] += 1
                logger.info(f"‚úÖ Success: {result['unit_id']} (route: {result['route']}, time: {result['processing_time']:.2f}s)")
                if result.get("exports"):
                    logger.info(f"   Exports: {list(result['exports'].keys())}")
            else:
                processed_results["failed"] += 1
                logger.error(f"‚ùå Failed: {result['unit_id']}")
                for error in result.get("errors", []):
                    logger.error(f"   Error: {error}")
        except Exception as e:
            logger.error(f"‚ùå Exception processing {unit_dir.name}: {e}", exc_info=True)
            processed_results["failed"] += 1
            error_result = {
                "success": False,
                "unit_id": unit_dir.name,
                "errors": [str(e)],
                "processing_time": 0.0,
            }
            processed_results["results"].append(error_result)
    
    # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    logger.info("\n" + "=" * 60)
    logger.info("Processing Summary")
    logger.info("=" * 60)
    logger.info(f"Total units: {processed_results['total_units']}")
    logger.info(f"Processed: {processed_results['processed']}")
    logger.info(f"‚úÖ Succeeded: {processed_results['succeeded']}")
    logger.info(f"‚ùå Failed: {processed_results['failed']}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report_path = output_dir / f"processing_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    report = {
        "timestamp": datetime.now().isoformat(),
        "data_dir": str(data_dir),
        "ready2docling_dir": str(ready2docling_dir),
        "output_dir": str(output_dir),
        "parameters": {
            "limit": args.limit,
            "route_filter": args.route,
        },
        "results": processed_results,
    }
    
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"\nReport saved to: {report_path}")
    logger.info("=" * 60)
    
    return 0 if processed_results["failed"] == 0 else 1


if __name__ == "__main__":
    sys.exit(main())

