# Производительность и масштабирование Docling Integration

**Дата создания:** 2025-12-25  
**Версия:** 1.0

## Обзор

Данный документ описывает оценку производительности системы Docling Integration, рекомендации по масштабированию и мониторингу для оптимальной работы с большими объемами документов.

---

## 1. Оценка производительности

### 1.1. Производительность по типам документов

#### PDF с текстовым слоем (`pdf_text`)

**Оценка производительности:**
- **Скорость:** ~40-70 PDF/час/CPU
- **Среднее время на документ:** 50-90 секунд
- **Факторы влияния:**
  - Количество страниц (линейная зависимость)
  - Наличие таблиц (увеличивает время на 20-50%)
  - Использование layout detection моделей

**Примерные времена:**
- 10 страниц: ~30-60 секунд
- 50 страниц: ~2-4 минуты
- 100 страниц: ~4-8 минут

#### PDF со сканированным содержимым (`pdf_scan`)

**Оценка производительности:**
- **Скорость:** ~10-20 PDF/час/CPU
- **Среднее время на документ:** 3-6 минут
- **Факторы влияния:**
  - OCR занимает большую часть времени
  - Разрешение изображений (DPI)
  - Качество сканирования

**Примерные времена:**
- 10 страниц: ~1.5-3 минуты
- 50 страниц: ~5-15 минут
- 100 страниц: ~15-30 минут

#### PDF со сканированными таблицами (`pdf_scan_table`)

**Оценка производительности:**
- **Скорость:** ~4-8 PDF/час/CPU (самый медленный)
- **Среднее время на документ:** 7-15 минут
- **Факторы влияния:**
  - OCR + table extraction
  - Cascadetabnet требует больше ресурсов
  - Количество таблиц

**Примерные времена:**
- 10 страниц: ~3-6 минут
- 50 страниц: ~15-30 минут
- 100 страниц: ~30-60 минут

#### Нативные форматы (DOCX, XLSX, PPTX)

**Оценка производительности:**
- **Скорость:** ~80-200 документов/час/CPU
- **Среднее время на документ:** 20-45 секунд
- **Факторы влияния:**
  - Размер файла
  - Количество элементов (таблицы, изображения)

**Примерные времена:**
- Малый документ (< 10 страниц): ~10-30 секунд
- Средний документ (10-50 страниц): ~30-90 секунд
- Большой документ (> 50 страниц): ~1.5-5 минут

#### Веб-форматы (HTML, XML)

**Оценка производительности:**
- **Скорость:** ~150-300 документов/час/CPU
- **Среднее время на документ:** 12-24 секунды
- **Факторы влияния:**
  - Размер HTML/XML
  - Количество вложенных элементов

**Примерные времена:**
- Малый документ: ~5-15 секунд
- Средний документ: ~15-30 секунд
- Большой документ: ~30-60 секунд

#### Изображения с OCR (`image_ocr`)

**Оценка производительности:**
- **Скорость:** ~60-100 изображений/час/CPU
- **Среднее время на изображение:** 36-60 секунд
- **Факторы влияния:**
  - Разрешение изображения
  - Качество изображения
  - Язык текста

**Примерные времена:**
- Одно изображение: ~30-60 секунд
- Пакет из 10 изображений: ~5-10 минут

### 1.2. Влияние настроек на скорость обработки

#### Количество потоков (`threads`)

**Влияние:**
- Увеличение threads → лучше для CPU-bound задач
- Оптимальное значение: количество CPU cores
- Слишком большое значение может снизить производительность

**Рекомендации:**
```yaml
performance:
  threads: 4  # Для 4-ядерного CPU
  threads: 8  # Для 8-ядерного CPU
```

#### Batch pages (`batch_pages`)

**Влияние:**
- Оптимизация для PDF обработки
- Больший batch → лучше для больших документов
- Меньший batch → меньше использование памяти

**Рекомендации:**
```yaml
performance:
  batch_pages: 8   # Для документов до 100 страниц
  batch_pages: 16  # Для больших документов (> 100 страниц)
```

#### OCR включен (`do_ocr=true`)

**Влияние:**
- OCR значительно увеличивает время обработки (в 3-5 раз)
- Требует больше памяти
- CPU-intensive операция

**Сравнение:**
- PDF с текстовым слоем (без OCR): ~50-90 сек
- Тот же PDF с OCR: ~3-6 минут

### 1.3. Оценка ресурсов

#### CPU

**Требования:**
- **Минимальные:** 2 ядра
- **Рекомендуемые:** 4+ ядер
- **Оптимальные:** 8+ ядер

**Использование:**
- Высокая загрузка при обработке (70-100%)
- Параллельная обработка требует больше ядер

#### Память (RAM)

**Требования по типам обработки:**

| Тип обработки | Минимальная память | Рекомендуемая память |
|--------------|-------------------|---------------------|
| pdf_text (без таблиц) | 2 GB | 4 GB |
| pdf_text (с таблицами) | 4 GB | 8 GB |
| pdf_scan | 4 GB | 8 GB |
| pdf_scan_table | 8 GB | 16 GB |
| Нативные форматы | 2 GB | 4 GB |
| Изображения | 2 GB | 4 GB |

**Пиковое использование:**
- Загрузка моделей: +1-2 GB
- Обработка больших документов: +2-4 GB
- Batch обработка: умножить на количество параллельных задач

#### Диск

**Требования:**
- **Временное хранение:** ~2-5x размер исходных файлов
- **Кэш моделей:** ~5-10 GB (один раз)
- **Экспортированные результаты:** ~1-3x размер исходных файлов

**Оценка для 1000 документов (100 MB каждый):**
- Исходные файлы: 100 GB
- Временные файлы: 200-500 GB
- Результаты: 100-300 GB
- **Итого:** ~400-900 GB

#### GPU (опционально)

**Требования:**
- NVIDIA GPU с 4+ GB VRAM
- CUDA 11.8 или выше
- Поддержка в PyTorch

**Ускорение:**
- Layout detection: 2-3x
- Table extraction: 2-4x
- OCR: минимальное ускорение (CPU-bound)

**Общее ускорение:** 2-5x в зависимости от задач

---

## 2. Рекомендации по масштабированию

### 2.1. Batch обработка

#### Группировка UNIT для обработки

**Подход:**
- Группировать UNIT по типу (route) для оптимизации
- Обрабатывать похожие документы вместе
- Использовать общие PipelineOptions для группы

**Пример:**
```python
def process_batch_by_route(units: List[Path], route: str):
    """Обработка батча UNIT с одинаковым route"""
    options = build_pipeline_options(route)
    
    for unit_path in units:
        result = pipeline.process_unit(unit_path, options=options)
        # Обработка результата
```

#### Использование batch методов Docling

**Если поддерживается:**
- Docling может иметь batch методы для обработки нескольких файлов
- Проверить документацию Docling для batch API

**Пример (если доступно):**
```python
# Гипотетический batch API
documents = converter.convert_batch([file1, file2, file3])
```

### 2.2. Параллельная обработка

#### Multithreading для I/O bound операций

**Использование:**
- Загрузка контрактов и файлов
- Экспорт результатов
- Чтение/запись файлов

**Пример:**
```python
from concurrent.futures import ThreadPoolExecutor

def process_units_parallel(units: List[Path], max_workers: int = 4):
    """Параллельная обработка UNIT с использованием ThreadPool"""
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = [executor.submit(pipeline.process_unit, unit) for unit in units]
        results = [f.result() for f in futures]
    return results
```

#### Multiprocessing для CPU-bound операций

**Использование:**
- Обработка документов (Docling conversion)
- CPU-intensive задачи

**Пример:**
```python
from multiprocessing import Pool, cpu_count

def process_unit_wrapper(args):
    """Wrapper для обработки одного UNIT"""
    unit_path, pipeline_config = args
    pipeline = DoclingPipeline(**pipeline_config)
    return pipeline.process_unit(unit_path)

def process_units_multiprocessing(units: List[Path], n_processes: int = None):
    """Параллельная обработка с использованием multiprocessing"""
    if n_processes is None:
        n_processes = cpu_count()
    
    pipeline_config = {"export_json": True, "export_markdown": True}
    args = [(unit, pipeline_config) for unit in units]
    
    with Pool(processes=n_processes) as pool:
        results = pool.map(process_unit_wrapper, args)
    
    return results
```

**Рекомендации:**
- Количество процессов: количество CPU cores
- Учитывать использование памяти (каждый процесс требует памяти)
- Для больших документов: меньше процессов

#### Гибридный подход

**Стратегия:**
- Multiprocessing для обработки документов
- Multithreading для I/O операций внутри каждого процесса

**Пример:**
```python
def hybrid_processing(units: List[Path]):
    """Гибридный подход: multiprocessing + threading"""
    n_processes = cpu_count()
    
    # Разделить UNIT на батчи
    batch_size = len(units) // n_processes
    batches = [units[i:i+batch_size] for i in range(0, len(units), batch_size)]
    
    # Обработать каждый батч в отдельном процессе
    with Pool(processes=n_processes) as pool:
        results = pool.map(process_batch, batches)
    
    return results
```

### 2.3. Оптимизация конфигурации

#### Настройка threads в зависимости от ресурсов

**Рекомендации:**
```yaml
# Для 4-ядерного CPU
performance:
  threads: 4

# Для 8-ядерного CPU
performance:
  threads: 8

# Для систем с ограниченной памятью
performance:
  threads: 2
```

#### Отключение ненужных функций

**Если не нужны таблицы:**
```yaml
models:
  tables: off  # Отключить извлечение таблиц

docling:
  extract_tables: false
```

**Если не нужны изображения:**
```yaml
docling:
  extract_figures: false
```

**Экономия:** 20-40% времени обработки

#### Использование GPU если доступно

**Конфигурация:**
```yaml
processing_constraints:
  allow_gpu: true  # Если GPU доступен
```

**Требования:**
- NVIDIA GPU
- CUDA установлен
- PyTorch с CUDA support

**Ускорение:** 2-5x для layout detection и table extraction

---

## 3. Мониторинг и метрики

### 3.1. Сбор метрик

#### Время обработки на UNIT

**Метрики для сбора:**
```python
metrics = {
    "unit_id": "UNIT_12345",
    "route": "pdf_text",
    "file_size_mb": 2.5,
    "page_count": 50,
    "load_time_sec": 0.5,
    "conversion_time_sec": 120.0,
    "export_time_sec": 2.0,
    "total_time_sec": 122.5
}
```

**Агрегация:**
- Среднее время по route
- Медиана времени
- Перцентили (50, 90, 95, 99)
- Минимум/максимум

#### Успешность обработки

**Метрики:**
```python
success_metrics = {
    "total_units": 1000,
    "successful": 950,
    "failed": 50,
    "success_rate": 0.95,
    "errors_by_type": {
        "ConversionError": 30,
        "FileNotFoundError": 10,
        "UnsupportedFormatError": 10
    }
}
```

#### Использование памяти

**Метрики:**
```python
memory_metrics = {
    "peak_memory_mb": 4096,
    "average_memory_mb": 2048,
    "memory_per_unit_mb": 4.0
}
```

#### Количество обработанных документов

**Метрики:**
```python
throughput_metrics = {
    "units_per_hour": 120,
    "units_per_minute": 2.0,
    "average_time_per_unit_sec": 30.0
}
```

### 3.2. Alerting

#### Высокий процент ошибок

**Триггер:**
- Success rate < 90% за последний час
- Количество ошибок > 10% от общего числа UNIT

**Действия:**
- Отправить alert
- Проверить логи
- Анализировать типы ошибок

#### Превышение времени обработки

**Триггер:**
- Среднее время обработки > 2x от ожидаемого
- P95 время обработки > порогового значения

**Действия:**
- Проверить загрузку системы
- Проверить размер документов
- Оптимизировать конфигурацию

#### Проблемы с памятью

**Триггер:**
- Использование памяти > 90% доступной
- Out of Memory ошибки

**Действия:**
- Уменьшить количество параллельных процессов
- Уменьшить batch_pages
- Проверить утечки памяти

### 3.3. Анализ трендов

#### Тенденции производительности

**Анализ:**
- Изменение среднего времени обработки со временем
- Выявление деградации производительности
- Корреляция с изменениями в коде или конфигурации

**Метрики:**
```python
trend_analysis = {
    "period": "last_30_days",
    "average_time_trend": "increasing",  # increasing/decreasing/stable
    "change_percentage": +15.0,
    "correlation_events": ["model_update", "config_change"]
}
```

#### Распределение по типам документов

**Анализ:**
- Какие типы документов обрабатываются чаще
- Какие типы требуют больше времени
- Оптимизация для часто используемых типов

**Метрики:**
```python
distribution = {
    "pdf_text": {"count": 500, "avg_time_sec": 60, "total_time_hours": 8.3},
    "pdf_scan": {"count": 300, "avg_time_sec": 180, "total_time_hours": 15.0},
    "docx": {"count": 200, "avg_time_sec": 30, "total_time_hours": 1.7}
}
```

#### Эффективность оптимизаций

**Анализ:**
- Сравнение производительности до и после оптимизаций
- Измерение улучшений
- Валидация изменений

**Пример:**
```python
optimization_results = {
    "before": {
        "avg_time_sec": 120,
        "throughput_per_hour": 30
    },
    "after": {
        "avg_time_sec": 90,
        "throughput_per_hour": 40
    },
    "improvement": {
        "time_reduction_percent": 25.0,
        "throughput_increase_percent": 33.3
    }
}
```

---

## 4. Практические рекомендации

### 4.1. Для production использования

1. **Мониторинг:**
   - Настроить сбор метрик
   - Настроить alerting
   - Регулярный анализ производительности

2. **Оптимизация:**
   - Настроить threads в зависимости от CPU
   - Использовать GPU если доступен
   - Отключить ненужные функции

3. **Масштабирование:**
   - Использовать параллельную обработку
   - Разделить нагрузку между несколькими машинами
   - Использовать queue системы для распределения задач

### 4.2. Для разработки и тестирования

1. **Быстрая итерация:**
   - Использовать меньше threads
   - Обрабатывать маленькие батчи
   - Отключить экспорт в MongoDB для тестов

2. **Тестирование производительности:**
   - Использовать репрезентативные данные
   - Замерять время обработки
   - Сравнивать с baseline

### 4.3. Для больших объемов (> 10000 документов)

1. **Архитектура:**
   - Использовать распределенную обработку
   - Queue система (RabbitMQ, Redis, и т.д.)
   - Несколько worker процессов/машин

2. **Оптимизация:**
   - Batch обработка по route
   - Кэширование конфигураций
   - Предварительная загрузка моделей

3. **Мониторинг:**
   - Централизованное логирование
   - Метрики в time-series БД (InfluxDB, Prometheus)
   - Dashboard для визуализации

---

**Связанные документы:**
- [CONFIGURATION.md](CONFIGURATION.md) - Конфигурация системы
- [EXTERNAL_LIBRARIES_AND_MODELS.md](EXTERNAL_LIBRARIES_AND_MODELS.md) - Зависимости и модели
- [TESTING_AND_DIAGNOSTICS.md](TESTING_AND_DIAGNOSTICS.md) - Тестирование
