"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ü–∏–∫–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏ final_receiver.

–ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ 3 —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å —Å–±–æ—Ä–æ–º –º–µ—Ç—Ä–∏–∫ –Ω–∞ –∫–∞–∂–¥–æ–º —ç—Ç–∞–ø–µ.

–ü–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –∏–∑ final_preprocessing/run_final_testing.py –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –æ–±—â—É—é —Å–∏—Å—Ç–µ–º—É —Ç–µ—Å—Ç–æ–≤.
"""
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, Any
import typer
from rich.console import Console
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—é final_preprocessing (—Ç–µ–ø–µ—Ä—å receiver –≤–Ω—É—Ç—Ä–∏ final_preprocessing)
final_preprocessing_path = Path(__file__).parent.parent.parent  # final_preprocessing
sys.path.insert(0, str(final_preprocessing_path))

from docprep.core.config import DATA_BASE_DIR, init_directory_structure
from docprep.engine.classifier import Classifier
from docprep.engine.converter import Converter
from docprep.engine.extractor import Extractor
from docprep.engine.normalizers.extension import ExtensionNormalizer
from docprep.engine.merger import Merger
from docprep.core.unit_processor import find_all_units

app = typer.Typer()
console = Console()


def collect_metrics(cycle: int, date: str) -> Dict[str, Any]:
    """–°–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ü–∏–∫–ª–∞."""
    base_dir = DATA_BASE_DIR / date
    
    metrics = {
        "cycle": cycle,
        "processing": {},
        "merge": {},
        "exceptions": {},
    }
    
    # Processing
    proc_dir = base_dir / "Processing" / f"Processing_{cycle}"
    if proc_dir.exists():
        for category in ["Convert", "Extract", "Normalize"]:
            cat_dir = proc_dir / category
            if cat_dir.exists():
                units = list(cat_dir.rglob("UNIT_*"))
                unit_count = len([d for d in units if d.is_dir()])
                metrics["processing"][category.lower()] = unit_count
    
    # Merge
    merge_dir = base_dir / "Merge" / f"Merge_{cycle}"
    if merge_dir.exists():
        if cycle == 0:
            # Merge_0 –∏–º–µ–µ—Ç —Ç–æ–ª—å–∫–æ Direct
            direct_dir = merge_dir / "Direct"
            if direct_dir.exists():
                units = list(direct_dir.rglob("UNIT_*"))
                unit_count = len([d for d in units if d.is_dir()])
                metrics["merge"]["direct"] = unit_count
        else:
            # Merge_1, Merge_2, Merge_3 –∏–º–µ—é—Ç Converted, Extracted, Normalized
            for category in ["Converted", "Extracted", "Normalized"]:
                cat_dir = merge_dir / category
                if cat_dir.exists():
                    units = list(cat_dir.rglob("UNIT_*"))
                    unit_count = len([d for d in units if d.is_dir()])
                    metrics["merge"][category.lower()] = unit_count
    
    # Exceptions
    exc_dir = base_dir / "Exceptions" / f"Exceptions_{cycle}"
    if exc_dir.exists():
        for category in ["Special", "Mixed", "Ambiguous", "Empty"]:
            cat_dir = exc_dir / category
            if cat_dir.exists():
                units = list(cat_dir.rglob("UNIT_*"))
                unit_count = len([d for d in units if d.is_dir()])
                metrics["exceptions"][category.lower()] = unit_count
    
    return metrics


def print_metrics_table(metrics_list: list):
    """–í—ã–≤–æ–¥–∏—Ç —Ç–∞–±–ª–∏—Ü—É —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏."""
    table = Table(title="–ú–µ—Ç—Ä–∏–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    table.add_column("–¶–∏–∫–ª", style="cyan")
    table.add_column("Processing", style="green")
    table.add_column("Merge", style="blue")
    table.add_column("Exceptions", style="yellow")
    
    for metrics in metrics_list:
        cycle = metrics["cycle"]
        
        # Processing
        proc_str = ", ".join([f"{k}: {v}" for k, v in metrics["processing"].items()])
        if not proc_str:
            proc_str = "-"
        
        # Merge
        merge_str = ", ".join([f"{k}: {v}" for k, v in metrics["merge"].items()])
        if not merge_str:
            merge_str = "-"
        
        # Exceptions
        exc_str = ", ".join([f"{k}: {v}" for k, v in metrics["exceptions"].items()])
        if not exc_str:
            exc_str = "-"
        
        table.add_row(str(cycle), proc_str, merge_str, exc_str)
    
    console.print(table)


@app.command()
def test(
    date: str = typer.Argument(..., help="–î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD"),
    dry_run: bool = typer.Option(False, "--dry-run", help="–¢–æ–ª—å–∫–æ –ø–æ–∫–∞–∑–∞—Ç—å —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ"),
):
    """
    –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö —Ü–∏–∫–ª–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏.
    
    Args:
        date: –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD
        dry_run: –ï—Å–ª–∏ True, —Ç–æ–ª—å–∫–æ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —á—Ç–æ –±—É–¥–µ—Ç —Å–¥–µ–ª–∞–Ω–æ
    """
    base_dir = DATA_BASE_DIR / date
    input_dir = base_dir / "Input"
    
    if not input_dir.exists():
        console.print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è Input –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {input_dir}", style="red")
        raise typer.Exit(1)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
    console.print(f"\nüìÅ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è {date}...")
    init_directory_structure(date)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    classifier = Classifier()
    converter = Converter()
    extractor = Extractor()
    normalizer = ExtensionNormalizer()
    merger = Merger()
    
    all_metrics = []
    
    # –¶–ò–ö–õ 1: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑ Input
    console.print("\n" + "="*60)
    console.print("üîÑ –¶–ò–ö–õ 1: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑ Input", style="bold cyan")
    console.print("="*60)
    
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        console=console,
    ) as progress:
        task = progress.add_task("–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è...", total=None)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        units = find_all_units(input_dir)
        console.print(f"  –ù–∞–π–¥–µ–Ω–æ UNIT –≤ Input: {len(units)}")
        
        if not dry_run:
            for unit_dir in units:
                classifier.classify_unit(
                    unit_path=unit_dir,
                    cycle=1,
                    protocol_date=date,
                    dry_run=dry_run,
                    copy_mode=True,  # –ö–æ–ø–∏—Ä—É–µ–º –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤
                )
        
        progress.update(task, completed=True)
    
    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞ 1
    metrics_1 = collect_metrics(1, date)
    all_metrics.append(metrics_1)
    console.print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞ 1:")
    print_metrics_table([metrics_1])
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ Processing_1
    console.print("\n" + "="*60)
    console.print("‚öôÔ∏è  –û–ë–†–ê–ë–û–¢–ö–ê Processing_1", style="bold green")
    console.print("="*60)
    
    proc_1_dir = base_dir / "Processing" / "Processing_1"
    
    if proc_1_dir.exists() and not dry_run:
        # Convert
        convert_dir = proc_1_dir / "Convert"
        if convert_dir.exists():
            units = find_all_units(convert_dir)
            console.print(f"  Convert: {len(units)} UNIT")
            for unit_dir in units:
                converter.convert_unit(
                    unit_path=unit_dir,
                    cycle=1,
                    protocol_date=date,
                    dry_run=dry_run,
                )
        
        # Extract
        extract_dir = proc_1_dir / "Extract"
        if extract_dir.exists():
            units = find_all_units(extract_dir)
            console.print(f"  Extract: {len(units)} UNIT")
            for unit_dir in units:
                extractor.extract_unit(
                    unit_path=unit_dir,
                    cycle=1,
                    protocol_date=date,
                    dry_run=dry_run,
                )
        
        # Normalize
        normalize_dir = proc_1_dir / "Normalize"
        if normalize_dir.exists():
            units = find_all_units(normalize_dir)
            console.print(f"  Normalize: {len(units)} UNIT")
            for unit_dir in units:
                normalizer.normalize_extensions(
                    unit_path=unit_dir,
                    cycle=1,
                    protocol_date=date,
                    dry_run=dry_run,
                )
    
    # –¶–ò–ö–õ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑ Merge_1
    console.print("\n" + "="*60)
    console.print("üîÑ –¶–ò–ö–õ 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑ Merge_1", style="bold cyan")
    console.print("="*60)
    
    merge_1_dir = base_dir / "Merge" / "Merge_1"
    if merge_1_dir.exists():
        units = find_all_units(merge_1_dir)
        console.print(f"  –ù–∞–π–¥–µ–Ω–æ UNIT –≤ Merge_1: {len(units)}")
        
        if not dry_run:
            for unit_dir in units:
                classifier.classify_unit(
                    unit_path=unit_dir,
                    cycle=2,
                    protocol_date=date,
                    dry_run=dry_run,
                )
    
    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞ 2
    metrics_2 = collect_metrics(2, date)
    all_metrics.append(metrics_2)
    console.print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞ 2:")
    print_metrics_table([metrics_2])
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ Processing_2
    console.print("\n" + "="*60)
    console.print("‚öôÔ∏è  –û–ë–†–ê–ë–û–¢–ö–ê Processing_2", style="bold green")
    console.print("="*60)
    
    proc_2_dir = base_dir / "Processing" / "Processing_2"
    
    if proc_2_dir.exists() and not dry_run:
        # Convert
        convert_dir = proc_2_dir / "Convert"
        if convert_dir.exists():
            units = find_all_units(convert_dir)
            console.print(f"  Convert: {len(units)} UNIT")
            for unit_dir in units:
                converter.convert_unit(
                    unit_path=unit_dir,
                    cycle=2,
                    protocol_date=date,
                    dry_run=dry_run,
                )
        
        # Extract
        extract_dir = proc_2_dir / "Extract"
        if extract_dir.exists():
            units = find_all_units(extract_dir)
            console.print(f"  Extract: {len(units)} UNIT")
            for unit_dir in units:
                extractor.extract_unit(
                    unit_path=unit_dir,
                    cycle=2,
                    protocol_date=date,
                    dry_run=dry_run,
                )
        
        # Normalize
        normalize_dir = proc_2_dir / "Normalize"
        if normalize_dir.exists():
            units = find_all_units(normalize_dir)
            console.print(f"  Normalize: {len(units)} UNIT")
            for unit_dir in units:
                normalizer.normalize_extensions(
                    unit_path=unit_dir,
                    cycle=2,
                    protocol_date=date,
                    dry_run=dry_run,
                )
    
    # –¶–ò–ö–õ 3: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑ Merge_2
    console.print("\n" + "="*60)
    console.print("üîÑ –¶–ò–ö–õ 3: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∏–∑ Merge_2", style="bold cyan")
    console.print("="*60)
    
    merge_2_dir = base_dir / "Merge" / "Merge_2"
    if merge_2_dir.exists():
        units = find_all_units(merge_2_dir)
        console.print(f"  –ù–∞–π–¥–µ–Ω–æ UNIT –≤ Merge_2: {len(units)}")
        
        if not dry_run:
            for unit_dir in units:
                classifier.classify_unit(
                    unit_path=unit_dir,
                    cycle=3,
                    protocol_date=date,
                    dry_run=dry_run,
                )
    
    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞ 3
    metrics_3 = collect_metrics(3, date)
    all_metrics.append(metrics_3)
    console.print(f"\nüìä –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ—Å–ª–µ —Ü–∏–∫–ª–∞ 3:")
    print_metrics_table([metrics_3])
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ Processing_3 (–µ—Å–ª–∏ –µ—Å—Ç—å)
    console.print("\n" + "="*60)
    console.print("‚öôÔ∏è  –û–ë–†–ê–ë–û–¢–ö–ê Processing_3", style="bold green")
    console.print("="*60)
    
    proc_3_dir = base_dir / "Processing" / "Processing_3"
    
    if proc_3_dir.exists() and not dry_run:
        # Convert
        convert_dir = proc_3_dir / "Convert"
        if convert_dir.exists():
            units = find_all_units(convert_dir)
            console.print(f"  Convert: {len(units)} UNIT")
            for unit_dir in units:
                converter.convert_unit(
                    unit_path=unit_dir,
                    cycle=3,
                    protocol_date=date,
                    dry_run=dry_run,
                )
        
        # Extract
        extract_dir = proc_3_dir / "Extract"
        if extract_dir.exists():
            units = find_all_units(extract_dir)
            console.print(f"  Extract: {len(units)} UNIT")
            for unit_dir in units:
                extractor.extract_unit(
                    unit_path=unit_dir,
                    cycle=3,
                    protocol_date=date,
                    dry_run=dry_run,
                )
        
        # Normalize
        normalize_dir = proc_3_dir / "Normalize"
        if normalize_dir.exists():
            units = find_all_units(normalize_dir)
            console.print(f"  Normalize: {len(units)} UNIT")
            for unit_dir in units:
                normalizer.normalize_extensions(
                    unit_path=unit_dir,
                    cycle=3,
                    protocol_date=date,
                    dry_run=dry_run,
                )
    
    # –§–ò–ù–ê–õ–¨–ù–´–ô –°–ë–û–† –í Ready2Docling
    console.print("\n" + "="*60)
    console.print("üì¶ –§–ò–ù–ê–õ–¨–ù–´–ô –°–ë–û–† –í Ready2Docling", style="bold magenta")
    console.print("="*60)
    
    if not dry_run:
        # –°–æ–±–∏—Ä–∞–µ–º UNIT –∏–∑ –≤—Å–µ—Ö Merge_N
        source_dirs = []
        
        # Merge_0/Direct
        merge_0_dir = base_dir / "Merge" / "Merge_0"
        if merge_0_dir.exists():
            source_dirs.append(merge_0_dir)
        
        # Merge_1, Merge_2, Merge_3
        for i in range(1, 4):
            merge_dir = base_dir / "Merge" / f"Merge_{i}"
            if merge_dir.exists():
                source_dirs.append(merge_dir)
        
        if source_dirs:
            ready2docling_dir = base_dir / "Ready2Docling"
            ready2docling_dir.mkdir(parents=True, exist_ok=True)
            
            result = merger.collect_units(
                source_dirs=source_dirs,
                target_dir=ready2docling_dir,
            )
            
            console.print(f"  ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ UNIT: {result['units_processed']}")
            if result['errors']:
                console.print(f"  ‚ö†Ô∏è  –û—à–∏–±–æ–∫: {len(result['errors'])}", style="yellow")
    
    # –§–∏–Ω–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    console.print("\n" + "="*60)
    console.print("üìä –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò", style="bold")
    console.print("="*60)
    print_metrics_table(all_metrics)
    
    # Ready2Docling —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    ready2docling_dir = base_dir / "Ready2Docling"
    if ready2docling_dir.exists():
        units = list(ready2docling_dir.rglob("UNIT_*"))
        unit_count = len([d for d in units if d.is_dir()])
        console.print(f"\n‚úÖ UNIT –≤ Ready2Docling: {unit_count}")
    
    console.print("\n‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")


if __name__ == "__main__":
    app()

