#!/usr/bin/env python3
"""
CLI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —ç—Ç–∞–ø–∞–º–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.

–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ router/main.py –∏ –¥–æ–±–∞–≤–ª—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
–≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ pipeline: –∑–∞–≥—Ä—É–∑–∫–∞, —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∞, –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è, Docling –æ–±—Ä–∞–±–æ—Ç–∫–∞.
"""
import sys
import json
import time
import requests
import shutil
import hashlib
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –∏–∑ router –º–æ–¥—É–ª–µ–π
try:
    from router.config import (
        INPUT_DIR, TEMP_DIR, OUTPUT_DIR, EXTRACTED_DIR, NORMALIZED_DIR, ARCHIVE_DIR,
        DOCLING_API, PENDING_DIR, PENDING_DIRECT_DIR, PENDING_NORMALIZE_DIR,
        PENDING_CONVERT_DIR, PENDING_EXTRACT_DIR, PENDING_SPECIAL_DIR, PENDING_MIXED_DIR,
        READY_DOCLING_DIR, init_directories
    )
    from router.mongo import (
        get_mongo_metadata_client, get_manifest_from_mongo, get_protocols_by_date, get_mongo_client
    )
    from router.api import process_file, download_document
    from router.metrics import (
        init_processing_metrics, save_processing_metrics, get_current_metrics
    )
    from router.file_detection import detect_file_type
    from router.file_classifier import classify_file
    from router.archive import safe_extract_archive
    from router.utils import calculate_sha256, sanitize_filename
    from router.merge import merge_to_ready_docling, get_ready_docling_statistics, print_merge_summary
    from router.unit_distribution_new import distribute_unit_by_new_structure, get_unit_statistics
    
    ROUTER_AVAILABLE = True
    print("‚úì Router –º–æ–¥—É–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    # Fallback –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ router –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω (Docker, etc.)
    import os
    ROUTER_AVAILABLE = False
    INPUT_DIR = Path(os.environ.get("INPUT_DIR", "/app/input"))
    TEMP_DIR = Path(os.environ.get("TEMP_DIR", "/app/temp"))
    OUTPUT_DIR = Path(os.environ.get("OUTPUT_DIR", "/app/output"))
    EXTRACTED_DIR = Path(os.environ.get("EXTRACTED_DIR", "/app/extracted"))
    NORMALIZED_DIR = Path(os.environ.get("NORMALIZED_DIR", "/app/normalized"))
    ARCHIVE_DIR = Path(os.environ.get("ARCHIVE_DIR", "/app/archive"))
    DOCLING_API = os.environ.get("DOCLING_API", "http://localhost:8001/process")
    PENDING_DIR = Path(os.environ.get("PENDING_DIR", "/app/pending"))
    PENDING_DIRECT_DIR = PENDING_DIR / "direct"
    PENDING_NORMALIZE_DIR = PENDING_DIR / "normalize"
    PENDING_CONVERT_DIR = PENDING_DIR / "convert"
    PENDING_EXTRACT_DIR = PENDING_DIR / "extract"
    PENDING_SPECIAL_DIR = PENDING_DIR / "special"
    PENDING_MIXED_DIR = PENDING_DIR / "mixed"
    READY_DOCLING_DIR = Path(os.environ.get("READY_DOCLING_DIR", "/app/ready_docling"))

    def get_protocols_by_date(*args, **kwargs):
        return {}

    def download_document(*args, **kwargs):
        return False

    def process_file(*args, **kwargs):
        return {"status": "error", "message": "Router not available"}

    def init_processing_metrics(*args, **kwargs):
        return {"session_id": "fallback", "started_at": datetime.utcnow().isoformat()}

    def save_processing_metrics(*args, **kwargs):
        pass

    def get_manifest_from_mongo(*args, **kwargs):
        return None

    def get_mongo_metadata_client(*args, **kwargs):
        return None

    def get_mongo_client(*args, **kwargs):
        return None

    def get_current_metrics(*args, **kwargs):
        return None

    def detect_file_type(file_path):
        """Fallback –¥–ª—è detect_file_type."""
        return {"detected_type": "unknown", "mime_type": "application/octet-stream"}

    def classify_file(file_path, detection_result=None):
        """Fallback –¥–ª—è classify_file."""
        return {"category": "special", "detected_type": "unknown"}

    def safe_extract_archive(archive_path, extract_to, archive_id):
        """Fallback –¥–ª—è safe_extract_archive."""
        return [], False

    def calculate_sha256(file_path):
        """Fallback –¥–ª—è calculate_sha256."""
        sha256_hash = hashlib.sha256()
        with open(file_path, "rb") as f:
            for byte_block in iter(lambda: f.read(4096), b""):
                sha256_hash.update(byte_block)
        return sha256_hash.hexdigest()

    def sanitize_filename(filename):
        """Fallback –¥–ª—è sanitize_filename."""
        return Path(filename).name

    def merge_to_ready_docling(*args, **kwargs):
        """Fallback –¥–ª—è merge_to_ready_docling."""
        return {"error": "Router not available"}

    def get_ready_docling_statistics():
        """Fallback –¥–ª—è get_ready_docling_statistics."""
        return {"total_units": 0, "total_files": 0, "by_type": {}}

    def print_merge_summary(result):
        """Fallback –¥–ª—è print_merge_summary."""
        print(f"Merge result: {result}")

    def distribute_unit_by_new_structure(*args, **kwargs):
        """Fallback –¥–ª—è distribute_unit_by_new_structure."""
        return {"error": "Router not available"}

    def get_unit_statistics(*args, **kwargs):
        """Fallback –¥–ª—è get_unit_statistics."""
        return {}

    def init_directories():
        """Fallback –¥–ª—è init_directories."""
        for d in [INPUT_DIR, TEMP_DIR, OUTPUT_DIR, EXTRACTED_DIR, NORMALIZED_DIR, 
                  ARCHIVE_DIR, PENDING_DIR, READY_DOCLING_DIR]:
            d.mkdir(parents=True, exist_ok=True)

    print(f"‚ö†Ô∏è  Router –º–æ–¥—É–ª–∏ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã: {e}")

# –ò–º–ø–æ—Ä—Ç –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤
try:
    from sync_db.service import SyncService
    from downloader.service import ProtocolDownloader
    from downloader.utils import check_zakupki_health
    print("‚úì –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
except ImportError as e:
    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–æ–≤: {e}")
    SyncService = None
    ProtocolDownloader = None
    check_zakupki_health = None


class PreprocessingTestCLI:
    """CLI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞."""

    def __init__(self):
        self.metrics = None
        self.session_id = None
        self.local_metrics_dir = Path(__file__).parent / "local_metrics"
        self.local_metrics_dir.mkdir(exist_ok=True)
    
    @staticmethod
    def find_input_files(limit: Optional[int] = None) -> List[Path]:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ INPUT_DIR, –≤–∫–ª—é—á–∞—è —Ñ–∞–π–ª—ã –≤–Ω—É—Ç—Ä–∏ UNIT_* –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π.
        
        Args:
            limit: –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
        
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º
        """
        # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ INPUT_DIR
        files = list(INPUT_DIR.glob("*"))
        files = [f for f in files if f.is_file() and not f.name.startswith('.')]
        
        # –ï—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç –≤ –∫–æ—Ä–Ω–µ, –∏—â–µ–º –≤–Ω—É—Ç—Ä–∏ UNIT_* –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        if len(files) == 0:
            unit_dirs = [d for d in INPUT_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]
            for unit_dir in unit_dirs:
                unit_files = list(unit_dir.glob("*"))
                unit_files = [f for f in unit_files if f.is_file() and not f.name.startswith('.')]
                files.extend(unit_files)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ª–∏–º–∏—Ç
        if limit:
            files = files[:limit]
        
        return files
    
    def save_metrics_local(self, metrics: Optional[Dict[str, Any]] = None) -> bool:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ –≤ JSON —Ñ–∞–π–ª (fallback –µ—Å–ª–∏ MongoDB –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞)."""
        if metrics is None:
            metrics = self.metrics
        
        if not metrics:
            return False
        
        try:
            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            if not metrics.get("completed_at"):
                metrics["completed_at"] = datetime.utcnow().isoformat()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON —Ñ–∞–π–ª
            session_id = metrics.get("session_id", "unknown")
            metrics_file = self.local_metrics_dir / f"metrics_{session_id}.json"
            
            with open(metrics_file, "w", encoding="utf-8") as f:
                json.dump(metrics, f, ensure_ascii=False, indent=2)
            
            print(f"üíæ –ú–µ—Ç—Ä–∏–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ: {metrics_file}")
            return True
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫: {e}")
            return False
    
    def load_metrics_local(self, session_id: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ JSON —Ñ–∞–π–ª–∞."""
        try:
            if session_id:
                metrics_file = self.local_metrics_dir / f"metrics_{session_id}.json"
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª
                metrics_files = sorted(self.local_metrics_dir.glob("metrics_*.json"), key=lambda p: p.stat().st_mtime)
                if not metrics_files:
                    return None
                metrics_file = metrics_files[-1]
            
            if not metrics_file.exists():
                return None
            
            with open(metrics_file, "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫: {e}")
            return None

    def show_menu(self):
        """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é."""
        print("\n" + "=" * 60)
        print("=== –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì –î–û–ö–£–ú–ï–ù–¢–û–í - CLI –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø ===")
        print("=" * 60)

        print("\n=== –ó–ê–ì–†–£–ó–ö–ê –ò –ü–û–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ù–´–• ===")
        print("1. –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ MongoDB")
        print("2. –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∑–∞ –¥–∞—Ç—É")
        print("3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Ñ–∞–π–ª–æ–≤ –≤ INPUT_DIR")

        print("\n=== –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –≠–¢–ê–ü–û–í –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì–ê ===")
        print("4. –¢–ï–°–¢ 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞")
        print("5. –¢–ï–°–¢ 2: –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤")
        print("6. –¢–ï–°–¢ 3: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è unit'–æ–≤")
        print("7. –¢–ï–°–¢ 4: –°–æ–∑–¥–∞–Ω–∏–µ manifest'–æ–≤")
        print("8. –¢–ï–°–¢ 5: Docling –æ–±—Ä–∞–±–æ—Ç–∫–∞")

        print("\n=== –ü–û–®–ê–ì–û–í–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê ===")
        print("9. –®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤")
        print("10. –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
        print("11. –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        print("12. –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units")
        print("13. –®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º")
        print("14. –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í—Å–µ —à–∞–≥–∏ (1-5)")

        print("\n=== –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
        print("15. –ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π")
        print("16. –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
        print("17. –û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units")

        print("\n=== MERGE –ò –§–ò–ù–ê–õ–ò–ó–ê–¶–ò–Ø ===")
        print("18. Merge (DRY RUN)")
        print("19. Merge (–†–ï–ê–õ–¨–ù–´–ô)")

        print("\n=== –ü–û–õ–ù–û–ï –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï PIPELINE ===")
        print("20. –ü–û–õ–ù–´–ô –¢–ï–°–¢: –í–µ—Å—å pipeline (—à–∞–≥–∏ 1-5)")
        print("21. –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢: Router API")

        print("\n=== –ú–û–ù–ò–¢–û–†–ò–ù–ì –ò –°–¢–ê–¢–ò–°–¢–ò–ö–ê ===")
        print("22. –ü—Ä–æ—Å–º–æ—Ç—Ä —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫ —Å–µ—Å—Å–∏–∏")
        print("23. –ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        print("24. –°—Ç–∞—Ç—É—Å MongoDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π")

        print("\n=== –°–õ–£–ñ–ï–ë–ù–´–ï –§–£–ù–ö–¶–ò–ò ===")
        print("25. –û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        print("26. –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤")
        print("27. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã")

        print("\n0. –í—ã—Ö–æ–¥")
        print("\n" + "-" * 60)

    def handle_sync_protocols(self):
        """–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ —É–¥–∞–ª—ë–Ω–Ω–æ–π MongoDB –≤ –ª–æ–∫–∞–ª—å–Ω—É—é."""
        print("\n=== –°–ò–ù–•–†–û–ù–ò–ó–ê–¶–ò–Ø –ü–†–û–¢–û–ö–û–õ–û–í –ò–ó –£–î–ê–õ–Å–ù–ù–û–ô MONGODB ===")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ SyncService
        if not SyncService:
            print("‚ùå SyncService –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
            print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥—É–ª—å sync_db —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return

        # –í—ã–±–æ—Ä –¥–∞—Ç—ã
        print("\n1. –í—ã–±–æ—Ä –¥–∞—Ç—ã –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:")
        print("  1. –í—á–µ—Ä–∞—à–Ω–∏–π –¥–µ–Ω—å (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)")
        print("  2. –£–∫–∞–∑–∞—Ç—å –¥–∞—Ç—É –≤—Ä—É—á–Ω—É—é (YYYY-MM-DD)")
        choice = input("  –í—ã–±–µ—Ä–∏—Ç–µ [1-2] –∏–ª–∏ Enter –¥–ª—è –≤—á–µ—Ä–∞—à–Ω–µ–≥–æ –¥–Ω—è: ").strip()

        target_date = None
        if choice == "2":
            date_str = input("  –í–≤–µ–¥–∏—Ç–µ –¥–∞—Ç—É (YYYY-MM-DD): ").strip()
            try:
                target_date = datetime.strptime(date_str, "%Y-%m-%d")
            except ValueError:
                print(f"‚úó –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: {date_str}")
                return
        else:
            target_date = datetime.utcnow() - timedelta(days=1)

        # –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤
        limit_str = input(f"\n2. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200

        # –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏
        print(f"\n3. –ó–∞–ø—É—Å–∫ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
        print(f"   –î–∞—Ç–∞: {target_date.date()}")
        print(f"   –õ–∏–º–∏—Ç: {limit}")

        try:
            sync_service = SyncService()
            result = sync_service.sync_protocols_for_date(target_date, limit)
            
            print("\n‚úì –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
            print(f"   –í—Ä–µ–º—è: {result.duration:.2f} —Å–µ–∫")
            print(f"   –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {result.scanned}")
            print(f"   –í—Å—Ç–∞–≤–ª–µ–Ω–æ: {result.inserted}")
            print(f"   –ü—Ä–æ–ø—É—â–µ–Ω–æ: {result.skipped_existing}")
            if result.errors_count > 0:
                print(f"   –û—à–∏–±–æ–∫: {result.errors_count}")
        except Exception as e:
            print(f"\n‚úó –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
            import traceback
            traceback.print_exc()

    def handle_download_protocols(self):
        """–°–∫–∞—á–∏–≤–∞–Ω–∏–µ –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π MongoDB —á–µ—Ä–µ–∑ VPN."""
        print("\n=== –°–ö–ê–ß–ò–í–ê–ù–ò–ï –ü–†–û–¢–û–ö–û–õ–û–í –ò–ó MONGODB (–° VPN) ===")

        if not ProtocolDownloader or not check_zakupki_health:
            print("‚ùå –ú–æ–¥—É–ª–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")
            return

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ VPN –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        print("\n1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ zakupki.gov.ru —á–µ—Ä–µ–∑ VPN...")
        if not check_zakupki_health():
            print("‚úó zakupki.gov.ru –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω–µ—Ç VPN / –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞)")
            print("  –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ VPN –Ω–∞—Å—Ç—Ä–æ–µ–Ω —á–µ—Ä–µ–∑ route-up-zakupki.sh")
            print("  –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ OpenVPN —Ç—É–Ω–Ω–µ–ª—å –∞–∫—Ç–∏–≤–µ–Ω")
            return

        print("‚úì zakupki.gov.ru –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ VPN")

        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input(f"\n2. –õ–∏–º–∏—Ç –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤/units –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 200): ").strip()
        limit = int(limit_str) if limit_str else 200

        if limit <= 0:
            print("‚úó –õ–∏–º–∏—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –±–æ–ª—å—à–µ 0")
            return

        # –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        print(f"\n3. –ó–∞–ø—É—Å–∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤...")
        print(f"   –õ–∏–º–∏—Ç: {limit} –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {INPUT_DIR.absolute()}")

        try:
            # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—ã–π API (SimpleProtocolDownloader)
            downloader = ProtocolDownloader(output_dir=INPUT_DIR)
            result = downloader.process_pending_protocols(limit=limit)
            duration = result.duration

            print("\n‚úì –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            print(f"   –í—Ä–µ–º—è: {duration:.1f} —Å–µ–∫")
            print(f"   –ü—Ä–æ—Ç–æ–∫–æ–ª—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {result.processed}")
            print(f"   –î–æ–∫—É–º–µ–Ω—Ç—ã —Å–∫–∞—á–∞–Ω–æ: {result.downloaded}")
            print(f"   –û—à–∏–±–æ–∫: {result.failed}")

            if result.errors:
                print(f"   –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –æ—à–∏–±–æ–∫: {len(result.errors)} –æ—à–∏–±–æ–∫")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
            import traceback
            traceback.print_exc()

    def handle_check_input_files(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –≤ INPUT_DIR."""
        print("\n=== –ü–†–û–í–ï–†–ö–ê INPUT_DIR ===")

        if not INPUT_DIR.exists():
            print(f"‚ùå –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è {INPUT_DIR} –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
            return

        files = list(INPUT_DIR.glob("*"))
        files = [f for f in files if f.is_file() and not f.name.startswith('.')]

        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")

        if files:
            print("\n–§–∞–π–ª—ã:")
            for i, file_path in enumerate(files[:10], 1):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 10
                size_mb = file_path.stat().st_size / (1024 * 1024)
                print(f"  {i}. {file_path.name} ({size_mb:.1f} MB)")

            if len(files) > 10:
                print(f"... –∏ –µ—â–µ {len(files) - 10} —Ñ–∞–π–ª–æ–≤")
        else:
            print("üì≠ INPUT_DIR –ø—É—Å—Ç")

    def handle_test_file_type_detection(self):
        """–¢–µ—Å—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞."""
        print("\n=== –¢–ï–°–¢: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ò–ü–ê –§–ê–ô–õ–ê ===")

        files = list(INPUT_DIR.glob("*"))
        files = [f for f in files if f.is_file() and not f.name.startswith('.')]

        if not files:
            print("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ INPUT_DIR –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞
        from router.file_detection import detect_file_type

        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ {len(files)} —Ñ–∞–π–ª–∞—Ö...")

        results = {}
        for file_path in files[:5]:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 5 —Ñ–∞–π–ª–æ–≤
            print(f"\nüìÑ {file_path.name}:")
            try:
                detection = detect_file_type(file_path)
                detected_type = detection.get("detected_type", "unknown")
                mime_type = detection.get("mime_type", "")
                needs_ocr = detection.get("needs_ocr", False)
                is_archive = detection.get("is_archive", False)

                print(f"  –¢–∏–ø: {detected_type}")
                print(f"  MIME: {mime_type}")
                print(f"  OCR –Ω—É–∂–µ–Ω: {needs_ocr}")
                print(f"  –ê—Ä—Ö–∏–≤: {is_archive}")

                results[detected_type] = results.get(detected_type, 0) + 1

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º:")
        for file_type, count in results.items():
            print(f"  {file_type}: {count}")

    def handle_test_archive_extraction(self):
        """–¢–µ—Å—Ç —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ –∞—Ä—Ö–∏–≤–æ–≤."""
        print("\n=== –¢–ï–°–¢: –†–ê–°–ü–ê–ö–û–í–ö–ê –ê–†–•–ò–í–û–í ===")

        files = list(INPUT_DIR.glob("*"))
        archive_files = [f for f in files if f.is_file() and f.suffix.lower() in ['.zip', '.rar', '.7z']]

        if not archive_files:
            print("‚ùå –ù–µ—Ç –∞—Ä—Ö–∏–≤–æ–≤ –≤ INPUT_DIR –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return

        from router.archive import safe_extract_archive

        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ {len(archive_files)} –∞—Ä—Ö–∏–≤–æ–≤...")

        for archive_path in archive_files:
            print(f"\nüì¶ {archive_path.name}:")

            extract_dir = EXTRACTED_DIR / f"test_{archive_path.stem}"
            extract_dir.mkdir(parents=True, exist_ok=True)

            try:
                extracted_files, success = safe_extract_archive(archive_path, extract_dir, "test")

                if success:
                    print(f"  ‚úÖ –†–∞—Å–ø–∞–∫–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(extracted_files)}")
                    for ext_file in extracted_files[:3]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                        print(f"    üìÑ {ext_file['original_name']}")
                    if len(extracted_files) > 3:
                        print(f"    ... –∏ –µ—â–µ {len(extracted_files) - 3} —Ñ–∞–π–ª–æ–≤")
                else:
                    print("  ‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏")

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")

    def handle_test_normalization(self):
        """–¢–µ—Å—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ unit'–æ–≤."""
        print("\n=== –¢–ï–°–¢: –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–Ø UNIT'–û–í ===")

        files = list(INPUT_DIR.glob("*"))
        files = [f for f in files if f.is_file() and not f.name.startswith('.')]

        if not files:
            print("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ INPUT_DIR –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è")
            return

        print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ {len(files)} —Ñ–∞–π–ª–æ–≤...")

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é process_file
        processed = 0
        errors = 0

        for file_path in files[:3]:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ñ–∞–π–ª–∞
            print(f"\nüìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {file_path.name}...")

            try:
                result = process_file(file_path, None)  # background_tasks = None –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

                if result.get("status") == "processed":
                    print("  ‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É—Å–ø–µ—à–Ω–æ")
                    if "unit_id" in result:
                        print(f"    Unit ID: {result['unit_id']}")
                    processed += 1
                else:
                    print(f"  ‚ùå –û—à–∏–±–∫–∞: {result.get('message', 'Unknown error')}")
                    errors += 1

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
                errors += 1

        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"  ‚úÖ –£—Å–ø–µ—à–Ω–æ: {processed}")
        print(f"  ‚ùå –û—à–∏–±–æ–∫: {errors}")

    def handle_test_manifest_creation(self):
        """–¢–µ—Å—Ç —Å–æ–∑–¥–∞–Ω–∏—è manifest'–æ–≤."""
        print("\n=== –¢–ï–°–¢: –°–û–ó–î–ê–ù–ò–ï MANIFEST'–û–í ===")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º normalized units
        unit_dirs = [d for d in NORMALIZED_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]

        if not unit_dirs:
            print("‚ùå –ù–µ—Ç normalized units –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è manifest'–æ–≤")
            print("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤")
            return

        print(f"üß™ –ü—Ä–æ–≤–µ—Ä–∫–∞ manifest'–æ–≤ –≤ {len(unit_dirs)} units...")

        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å manifest
        # get_manifest_from_mongo —É–∂–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞

        manifests_found = 0
        manifests_valid = 0

        for unit_dir in unit_dirs[:5]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 5
            unit_id = unit_dir.name
            print(f"\nüìã {unit_id}:")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º MongoDB manifest
            manifest = get_manifest_from_mongo(unit_id)

            if manifest:
                manifests_found += 1
                print("  ‚úÖ Manifest –Ω–∞–π–¥–µ–Ω –≤ MongoDB")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
                required_fields = ["unit_id", "created_at", "processing", "files"]
                valid = all(field in manifest for field in required_fields)

                if valid:
                    manifests_valid += 1
                    status = manifest.get("processing", {}).get("status", "unknown")
                    route = manifest.get("processing", {}).get("route", "unknown")
                    files_count = len(manifest.get("files", []))
                    print(f"    –°—Ç–∞—Ç—É—Å: {status}")
                    print(f"    Route: {route}")
                    print(f"    –§–∞–π–ª–æ–≤: {files_count}")
                else:
                    print("  ‚ö†Ô∏è  –°—Ç—Ä—É–∫—Ç—É—Ä–∞ manifest –Ω–µ–ø–æ–ª–Ω–∞—è")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º JSON —Ñ–∞–π–ª
                manifest_path = unit_dir / "manifest.json"
                if manifest_path.exists():
                    manifests_found += 1
                    print("  ‚úÖ Manifest –Ω–∞–π–¥–µ–Ω –≤ JSON —Ñ–∞–π–ª–µ")

                    try:
                        with open(manifest_path, "r", encoding="utf-8") as f:
                            manifest = json.load(f)
                        manifests_valid += 1
                        print("    ‚úÖ JSON –≤–∞–ª–∏–¥–µ–Ω")
                    except Exception as e:
                        print(f"    ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è JSON: {e}")
                else:
                    print("  ‚ùå Manifest –Ω–µ –Ω–∞–π–¥–µ–Ω")

        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"  üìã Manifest'–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {manifests_found}")
        print(f"  ‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö: {manifests_valid}")

    def handle_test_docling_processing(self):
        """–¢–µ—Å—Ç Docling –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –¢–ï–°–¢: DOCLING –û–ë–†–ê–ë–û–¢–ö–ê ===")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º normalized units
        unit_dirs = [d for d in NORMALIZED_DIR.iterdir() if d.is_dir() and d.name.startswith("UNIT_")]

        if not unit_dirs:
            print("‚ùå –ù–µ—Ç normalized units –¥–ª—è Docling –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            print("–°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é —Ñ–∞–π–ª–æ–≤")
            return

        print(f"üß™ –û—Ç–ø—Ä–∞–≤–∫–∞ {len(unit_dirs)} units –≤ Docling...")

        # –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Docling —á–µ—Ä–µ–∑ API
        processed = 0
        errors = 0

        for unit_dir in unit_dirs[:3]:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3
            unit_id = unit_dir.name
            print(f"\nüöÄ –û—Ç–ø—Ä–∞–≤–∫–∞ {unit_id} –≤ Docling...")

            try:
                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ Docling API
                manifest = get_manifest_from_mongo(unit_id)
                if manifest:
                    response = requests.post(
                        DOCLING_API,
                        json={"unit_id": unit_id, "manifest": manifest},
                        timeout=30
                    )
                    if response.status_code == 200:
                        processed += 1
                        print("  ‚úÖ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
                    else:
                        print(f"  ‚ùå –û—à–∏–±–∫–∞ API: {response.status_code}")
                        errors += 1
                else:
                    print("  ‚ö†Ô∏è  Manifest –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    errors += 1

                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –æ—Ç–ø—Ä–∞–≤–∫–∞–º–∏
                time.sleep(1)

            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
                errors += 1

        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"  üöÄ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {processed}")
        print(f"  ‚ùå –û—à–∏–±–æ–∫: {errors}")

        if processed > 0:
            print("\nüí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ Docling —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

    def handle_full_pipeline_test(self):
        """–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –≤—Å–µ–≥–æ pipeline."""
        print("\n=== –ü–û–õ–ù–´–ô –¢–ï–°–¢ PIPELINE ===")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Å–µ—Å—Å–∏–∏
        self.metrics = init_processing_metrics()
        self.session_id = self.metrics["session_id"]

        print(f"üéØ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π —Å–µ—Å—Å–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {self.session_id}")

        # –≠—Ç–∞–ø 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        print("\nüìã –≠–¢–ê–ü 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        self.handle_check_input_files()

        # –≠—Ç–∞–ø 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
        print("\nüîç –≠–¢–ê–ü 2: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤...")
        self.handle_test_file_type_detection()

        # –≠—Ç–∞–ø 3: –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤
        print("\nüì¶ –≠–¢–ê–ü 3: –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ –∞—Ä—Ö–∏–≤–æ–≤...")
        self.handle_test_archive_extraction()

        # –≠—Ç–∞–ø 4: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        print("\nüîÑ –≠–¢–ê–ü 4: –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è unit'–æ–≤...")
        self.handle_test_normalization()

        # –≠—Ç–∞–ø 5: –°–æ–∑–¥–∞–Ω–∏–µ manifest'–æ–≤
        print("\nüìã –≠–¢–ê–ü 5: –°–æ–∑–¥–∞–Ω–∏–µ manifest'–æ–≤...")
        self.handle_test_manifest_creation()

        # –≠—Ç–∞–ø 6: Docling –æ–±—Ä–∞–±–æ—Ç–∫–∞
        print("\nü§ñ –≠–¢–ê–ü 6: Docling –æ–±—Ä–∞–±–æ—Ç–∫–∞...")
        self.handle_test_docling_processing()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫
        if self.metrics:
            # –ü—ã—Ç–∞–µ–º—Å—è —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ MongoDB
            saved = save_processing_metrics(self.metrics)
            if not saved:
                # Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
                print("‚ö†Ô∏è  MongoDB –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ...")
                self.save_metrics_local(self.metrics)

        print("\nüéâ –ü–û–õ–ù–´–ô –¢–ï–°–¢ –ó–ê–í–ï–†–®–ï–ù!")
        print(f"üìä Session ID: {self.session_id}")

    def handle_integration_test(self):
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç Router API."""
        print("\n=== –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ô –¢–ï–°–¢ ROUTER API ===")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å router
        router_url = "http://router:8080/health"
        try:
            response = requests.get(router_url, timeout=5)
            if response.status_code == 200:
                print("‚úÖ Router API –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                print(f"‚ö†Ô∏è  Router API –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {response.status_code}")
        except Exception as e:
            print(f"‚ùå Router API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
            print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ docker-compose –∑–∞–ø—É—â–µ–Ω")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Docling
        docling_url = DOCLING_API.replace("/process", "/health")
        try:
            response = requests.get(docling_url, timeout=5)
            if response.status_code == 200:
                print("‚úÖ Docling API –¥–æ—Å—Ç—É–ø–µ–Ω")
            else:
                print(f"‚ö†Ô∏è  Docling API –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {response.status_code}")
        except Exception as e:
            print(f"‚ùå Docling API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

        # –¢–µ—Å—Ç process_now endpoint
        print("\nüß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ /process_now endpoint...")
        try:
            response = requests.post("http://router:8080/process_now", timeout=30)
            if response.status_code == 200:
                result = response.json()
                print("‚úÖ process_now –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {result.get('processed_count', 0)}")
                print(f"   Session ID: {result.get('session_id', 'N/A')}")
            else:
                print(f"‚ùå process_now –≤–µ—Ä–Ω—É–ª –∫–æ–¥ {response.status_code}")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è process_now: {e}")

    def handle_view_metrics(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä —Ç–µ–∫—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫ —Å–µ—Å—Å–∏–∏."""
        print("\n=== –¢–ï–ö–£–©–ò–ï –ú–ï–¢–†–ò–ö–ò –°–ï–°–°–ò–ò ===")

        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ MongoDB –∏–ª–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if not self.metrics:
            # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
            if ROUTER_AVAILABLE:
                metrics = get_current_metrics()
                if metrics:
                    self.metrics = metrics
                else:
                    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
                    self.metrics = self.load_metrics_local()
        
        if not self.metrics:
            print("‚ùå –ú–µ—Ç—Ä–∏–∫–∏ —Å–µ—Å—Å–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            print("üí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ—Å—Ç –∏–ª–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫–∏")
            print(f"üí° –õ–æ–∫–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏: {self.local_metrics_dir}")
            return

        print(f"üìä Session ID: {self.metrics['session_id']}")
        print(f"üïê Started: {self.metrics['started_at']}")
        print(f"üèÅ Completed: {self.metrics.get('completed_at', 'In progress')}")

        summary = self.metrics.get("summary", {})
        print("\nüìà Summary:")
        print(f"   Input files: {summary.get('total_input_files', 0)}")
        print(f"   Archives: {summary.get('total_archives', 0)}")
        print(f"   Extracted: {summary.get('total_extracted', 0)}")
        print(f"   Units: {summary.get('total_units', 0)}")
        print(f"   Errors: {summary.get('total_errors', 0)}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –º–µ—Ç—Ä–∏–∫
        if (self.local_metrics_dir / f"metrics_{self.metrics['session_id']}.json").exists():
            print(f"\nüíæ –ú–µ—Ç—Ä–∏–∫–∏ —Ç–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ª–æ–∫–∞–ª—å–Ω–æ: {self.local_metrics_dir}")

    def handle_view_logs(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä –ª–æ–≥–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        print("\n=== –õ–û–ì–ò –û–ë–†–ê–ë–û–¢–ö–ò ===")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–≥–∏ –≤ metrics
        if self.metrics:
            errors = self.metrics.get("errors", [])
            if errors:
                print("‚ùå –û—à–∏–±–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
                for error in errors[-5:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –æ—à–∏–±–æ–∫
                    print(f"   {error['timestamp']}: {error['error']}")
            else:
                print("‚úÖ –û—à–∏–±–æ–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        # –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ª–æ–≥–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤
        print("\nüí° –î–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ø–æ–ª–Ω—ã—Ö –ª–æ–≥–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:")
        print("   docker-compose logs -f router")
        print("   docker-compose logs -f scheduler")
        print("   docker-compose logs -f docling")

    def handle_check_mongodb(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ MongoDB –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π."""
        print("\n=== –ü–†–û–í–ï–†–ö–ê MONGODB –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ô ===")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ protocols MongoDB
        print("üîó –ü—Ä–æ–≤–µ—Ä–∫–∞ MongoDB –¥–ª—è –ø—Ä–æ—Ç–æ–∫–æ–ª–æ–≤...")
        client = get_mongo_client()
        if client:
            try:
                client.admin.command('ping')
                print("‚úÖ Protocols MongoDB: –ø–æ–¥–∫–ª—é—á–µ–Ω–æ")
            except Exception as e:
                print(f"‚ùå Protocols MongoDB: –æ—à–∏–±–∫–∞ {e}")
        else:
            print("‚ùå Protocols MongoDB: –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ metadata MongoDB
        print("üîó –ü—Ä–æ–≤–µ—Ä–∫–∞ MongoDB –¥–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö...")
        client = get_mongo_metadata_client()
        if client:
            try:
                client.admin.command('ping')
                print("‚úÖ Metadata MongoDB: –ø–æ–¥–∫–ª—é—á–µ–Ω–æ")
            except Exception as e:
                print(f"‚ùå Metadata MongoDB: –æ—à–∏–±–∫–∞ {e}")
        else:
            print("‚ùå Metadata MongoDB: –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞")

    def handle_cleanup_test_data(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."""
        print("\n=== –û–ß–ò–°–¢–ö–ê –¢–ï–°–¢–û–í–´–• –î–ê–ù–ù–´–• ===")

        dirs_to_clean = [TEMP_DIR, EXTRACTED_DIR, NORMALIZED_DIR, ARCHIVE_DIR]

        for directory in dirs_to_clean:
            if directory.exists():
                print(f"üßπ –û—á–∏—Å—Ç–∫–∞ {directory}...")
                for item in directory.glob("*"):
                    if item.is_file():
                        item.unlink()
                    elif item.is_dir():
                        import shutil
                        shutil.rmtree(item)
                print(f"   ‚úÖ –û—á–∏—â–µ–Ω–æ")

        print("üéâ –û—á–∏—Å—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    def handle_create_test_files(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –°–û–ó–î–ê–ù–ò–ï –¢–ï–°–¢–û–í–´–• –§–ê–ô–õ–û–í ===")

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        test_file = INPUT_DIR / "test_document.txt"
        test_file.write_text("–≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞.")

        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π PDF (–µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
        print("üìÑ –°–æ–∑–¥–∞–Ω —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: test_document.txt")

        print("‚úÖ –¢–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã —Å–æ–∑–¥–∞–Ω—ã")

    def handle_check_infrastructure(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä—ã."""
        print("\n=== –ü–†–û–í–ï–†–ö–ê –ò–ù–§–†–ê–°–¢–†–£–ö–¢–£–†–´ ===")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        dirs_to_check = [
            ("INPUT_DIR", INPUT_DIR),
            ("TEMP_DIR", TEMP_DIR),
            ("OUTPUT_DIR", OUTPUT_DIR),
            ("EXTRACTED_DIR", EXTRACTED_DIR),
            ("NORMALIZED_DIR", NORMALIZED_DIR),
            ("ARCHIVE_DIR", ARCHIVE_DIR),
        ]

        print("üìÅ –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π:")
        for name, directory in dirs_to_check:
            if directory.exists():
                print(f"  ‚úÖ {name}: {directory}")
            else:
                print(f"  ‚ùå {name}: –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                try:
                    directory.mkdir(parents=True, exist_ok=True)
                    print(f"     üìÅ –°–æ–∑–¥–∞–Ω–∞: {directory}")
                except Exception as e:
                    print(f"     ‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è: {e}")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ MongoDB
        print("\n" + "="*40)
        self.handle_check_mongodb()

        print("\nüéØ –ò–Ω—Ñ—Ä–∞—Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–≤–µ—Ä–µ–Ω–∞")

    def run(self):
        """–ì–ª–∞–≤–Ω—ã–π —Ü–∏–∫–ª CLI."""
        print("\nüöÄ –ó–ê–ü–£–°–ö CLI –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø –ü–†–ï–ü–†–û–¶–ï–°–°–ò–ù–ì–ê")
        print("=" * 60)

        while True:
            try:
                self.show_menu()
                choice = input("\n–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ [0-27]: ").strip()

                if choice == "0":
                    print("üëã –í—ã—Ö–æ–¥...")
                    break

                elif choice == "1":
                    self.handle_sync_protocols()

                elif choice == "2":
                    self.handle_download_protocols()

                elif choice == "3":
                    self.handle_check_input_files()

                elif choice == "4":
                    self.handle_test_file_type_detection()

                elif choice == "5":
                    self.handle_test_archive_extraction()

                elif choice == "6":
                    self.handle_test_normalization()

                elif choice == "7":
                    self.handle_test_manifest_creation()

                elif choice == "8":
                    self.handle_test_docling_processing()

                elif choice == "9":
                    self.handle_step1_scan_and_detect()

                elif choice == "10":
                    self.handle_step2_classify()

                elif choice == "11":
                    self.handle_step3_check_duplicates()

                elif choice == "12":
                    self.handle_step4_check_mixed()

                elif choice == "13":
                    self.handle_step5_distribute()

                elif choice == "14":
                    self.handle_full_processing()

                elif choice == "15":
                    self.handle_view_pending_structure()

                elif choice == "16":
                    self.handle_category_statistics()

                elif choice == "17":
                    self.handle_units_report()

                elif choice == "18":
                    self.handle_merge_dry_run()

                elif choice == "19":
                    self.handle_merge_real()

                elif choice == "20":
                    self.handle_full_pipeline_test()

                elif choice == "21":
                    self.handle_integration_test()

                elif choice == "22":
                    self.handle_view_metrics()

                elif choice == "23":
                    self.handle_view_logs()

                elif choice == "24":
                    self.handle_check_mongodb()

                elif choice == "25":
                    self.handle_cleanup_test_data()

                elif choice == "26":
                    self.handle_create_test_files()

                elif choice == "27":
                    self.handle_check_infrastructure()

                else:
                    print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.")

                input("\n‚èé –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")

            except KeyboardInterrupt:
                print("\n\nüëã –í—ã—Ö–æ–¥...")
                break
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
                import traceback
                traceback.print_exc()
                input("\n‚èé –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è...")


    def handle_step1_scan_and_detect(self, limit: Optional[int] = None):
        """–®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤."""
        print("\n=== –®–ê–ì 1: –°–ö–ê–ù–ò–†–û–í–ê–ù–ò–ï –ò –î–ï–¢–ï–ö–¶–ò–Ø –¢–ò–ü–û–í –§–ê–ô–õ–û–í ===")

        if limit is None:
            limit_str = input("–õ–∏–º–∏—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Enter = –≤—Å–µ): ").strip()
            limit = int(limit_str) if limit_str else None

        print(f"üîç –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ INPUT_DIR: {INPUT_DIR}")

        files = self.find_input_files(limit=limit)

        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")

        processed = 0
        for file_path in files:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é –¥–µ—Ç–µ–∫—Ü–∏–∏
                detection = detect_file_type(file_path)
                detected_type = detection.get("detected_type", "unknown")
                mime_type = detection.get("mime_type", "")
                needs_ocr = detection.get("needs_ocr", False)

                print(f"  üìÑ {file_path.name} ‚Üí {detected_type} ({mime_type})")
                processed += 1

            except Exception as e:
                print(f"  ‚ùå {file_path.name}: {e}")

        print("\n‚úÖ –®–ê–ì 1 –∑–∞–≤–µ—Ä—à–µ–Ω!")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {processed}")

    def handle_step2_classify(self, limit: Optional[int] = None):
        """–®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º."""
        print("\n=== –®–ê–ì 2: –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –§–ê–ô–õ–û–í –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú ===")

        if limit is None:
            limit_str = input("–õ–∏–º–∏—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (Enter = –≤—Å–µ): ").strip()
            limit = int(limit_str) if limit_str else None

        print("üìã –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤...")
        print("   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: direct, normalize, convert, extract, special, mixed")

        files = self.find_input_files(limit=limit)

        categories = {
            "direct": 0,
            "normalize": 0,
            "convert": 0,
            "extract": 0,
            "special": 0
        }

        for file_path in files:
            try:
                detection = detect_file_type(file_path)
                detected_type = detection.get("detected_type", "unknown")

                # –ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                if detected_type in ["pdf", "docx", "txt"]:
                    category = "direct"
                elif detected_type in ["doc", "xls", "ppt"]:
                    category = "convert"
                elif detected_type in ["zip", "rar", "7z"]:
                    category = "extract"
                else:
                    category = "special"

                categories[category] += 1
                print(f"  üìÑ {file_path.name} ‚Üí {category} ({detected_type})")

            except Exception as e:
                print(f"  ‚ùå {file_path.name}: {e}")

        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for category, count in categories.items():
            print(f"   {category}: {count}")

        print("\n‚úÖ –®–ê–ì 2 –∑–∞–≤–µ—Ä—à–µ–Ω!")

    def handle_step3_check_duplicates(self, limit: Optional[int] = None):
        """–®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤."""
        print("\n=== –®–ê–ì 3: –ü–†–û–í–ï–†–ö–ê –î–£–ë–õ–ò–ö–ê–¢–û–í ===")

        if limit is None:
            limit_str = input("–õ–∏–º–∏—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (Enter = –≤—Å–µ): ").strip()
            limit = int(limit_str) if limit_str else None

        print("üîç –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —Ö—ç—à–∞–º...")

        files = self.find_input_files(limit=limit)

        hashes = {}
        duplicates = []

        for file_path in files:
            try:
                file_hash = calculate_sha256(file_path)
                if file_hash in hashes:
                    duplicates.append((file_path, hashes[file_hash]))
                    print(f"  üîÑ –î—É–±–ª–∏–∫–∞—Ç: {file_path.name} == {hashes[file_hash].name}")
                else:
                    hashes[file_hash] = file_path
                    print(f"  ‚úÖ –£–Ω–∏–∫–∞–ª—å–Ω—ã–π: {file_path.name}")

            except Exception as e:
                print(f"  ‚ùå {file_path.name}: {e}")

        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(hashes)}")
        print(f"   –î—É–±–ª–∏–∫–∞—Ç–æ–≤: {len(duplicates)}")

        print("\n‚úÖ –®–ê–ì 3 –∑–∞–≤–µ—Ä—à–µ–Ω!")

    def handle_step4_check_mixed(self, limit: Optional[int] = None):
        """–®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö."""
        print("\n=== –®–ê–ì 4: –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï MIXED UNITS ===")

        if limit is None:
            limit_str = input("–õ–∏–º–∏—Ç units –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ (Enter = –≤—Å–µ): ").strip()
            limit = int(limit_str) if limit_str else None

        print("üîç –ê–Ω–∞–ª–∏–∑ units –Ω–∞ —Å–º–µ—à–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç...")
        print(f"   –ü–æ–∏—Å–∫ –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö: {PENDING_DIR}")

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ units –∏–∑ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
        all_unit_dirs = []
        pending_dirs = [PENDING_DIRECT_DIR, PENDING_NORMALIZE_DIR, PENDING_CONVERT_DIR, 
                        PENDING_EXTRACT_DIR, PENDING_SPECIAL_DIR, PENDING_MIXED_DIR]
        
        for pending_dir in pending_dirs:
            if pending_dir.exists():
                # –ò—â–µ–º units –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –∏ –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
                for item in pending_dir.rglob("UNIT_*"):
                    if item.is_dir():
                        all_unit_dirs.append(item)

        if not all_unit_dirs:
            print("   ‚ÑπÔ∏è  –ù–µ—Ç units –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö")
            print("   üí° –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –®–ê–ì 5 (–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ) –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è units")
            return

        if limit:
            all_unit_dirs = all_unit_dirs[:limit]

        print(f"   –ù–∞–π–¥–µ–Ω–æ units –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {len(all_unit_dirs)}")

        mixed_units = []
        simple_units = []

        for unit_dir in all_unit_dirs:
            try:
                files_dir = unit_dir / "files"
                if not files_dir.exists():
                    continue
                    
                files = [f for f in files_dir.iterdir() if f.is_file()]
                file_types = set()

                for file_path in files:
                    detection = detect_file_type(file_path)
                    file_types.add(detection.get("detected_type", "unknown"))

                if len(file_types) > 1:
                    mixed_units.append((unit_dir.name, file_types))
                    print(f"  üîÄ Mixed: {unit_dir.name} ({', '.join(file_types)})")
                else:
                    simple_units.append(unit_dir.name)
                    file_type = list(file_types)[0] if file_types else 'empty'
                    print(f"  üìÑ Simple: {unit_dir.name} ({file_type})")

            except Exception as e:
                print(f"  ‚ùå {unit_dir.name}: {e}")

        print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   Simple units: {len(simple_units)}")
        print(f"   Mixed units: {len(mixed_units)}")

        print("\n‚úÖ –®–ê–ì 4 –∑–∞–≤–µ—Ä—à–µ–Ω!")

    def handle_step5_distribute(self, limit: Optional[int] = None):
        """–®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ INPUT_DIR –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º units."""
        print("\n=== –®–ê–ì 5: –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–ï –ü–û PENDING –î–ò–†–ï–ö–¢–û–†–ò–Ø–ú ===")

        if limit is None:
            limit_str = input("–õ–∏–º–∏—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è (Enter = –≤—Å–µ): ").strip()
            limit = int(limit_str) if limit_str else None

        print("üì¶ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º —Å —Å–æ–∑–¥–∞–Ω–∏–µ–º units...")
        print(f"   –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {INPUT_DIR}")
        print(f"   –¶–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {PENDING_DIR}")
        print("   –ö–∞—Ç–µ–≥–æ—Ä–∏–∏: direct/, normalize/, convert/, extract/, special/")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        init_directories()

        files = self.find_input_files(limit=limit)

        if not files:
            print("\n   ‚ÑπÔ∏è  –ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –≤ INPUT_DIR –¥–ª—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")
            return

        print(f"\n   –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(files)}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
        init_processing_metrics()

        distributed = {
            "direct": 0,
            "normalize": 0,
            "convert": 0,
            "extract": 0,
            "special": 0,
            "mixed": 0
        }
        errors = 0
        units_created = []

        for file_path in files:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º process_file –∏–∑ router.api –¥–ª—è –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
                result = process_file(file_path)
                
                if result.get("status") == "processed":
                    unit_id = result.get("unit_id", "unknown")
                    category = result.get("category", "special")
                    detected_type = result.get("detected_type", "unknown")
                    
                    if category in distributed:
                        distributed[category] += 1
                    else:
                        distributed["special"] += 1
                    
                    units_created.append(unit_id)
                    print(f"  ‚úÖ {file_path.name} ‚Üí {category}/ [{detected_type}] (unit: {unit_id})")
                else:
                    errors += 1
                    error_msg = result.get("message", "Unknown error")
                    print(f"  ‚ùå {file_path.name}: {error_msg}")

            except Exception as e:
                errors += 1
                print(f"  ‚ùå {file_path.name}: {e}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        saved = save_processing_metrics()
        if not saved:
            # Fallback –Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            print("‚ö†Ô∏è  MongoDB –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ...")
            self.save_metrics_local()

        print("\nüìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for category, count in distributed.items():
            if count > 0:
                print(f"   {category}: {count} —Ñ–∞–π–ª–æ–≤")

        total_distributed = sum(distributed.values())
        print(f"   ---")
        print(f"   –í—Å–µ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–æ: {total_distributed}")
        print(f"   –°–æ–∑–¥–∞–Ω–æ units: {len(units_created)}")
        if errors > 0:
            print(f"   –û—à–∏–±–æ–∫: {errors}")

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ PENDING
        print("\nüìÅ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ PENDING –ø–æ—Å–ª–µ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è:")
        pending_stats = get_unit_statistics(PENDING_DIR)
        for category, stats in pending_stats.items():
            if stats["units"] > 0 or stats["files"] > 0:
                print(f"   {category}: {stats['units']} units, {stats['files']} —Ñ–∞–π–ª–æ–≤")

        print("\n‚úÖ –®–ê–ì 5 –∑–∞–≤–µ—Ä—à–µ–Ω!")

    def handle_full_processing(self, limit: Optional[int] = None):
        """–ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –≤—Å–µ —à–∞–≥–∏ 1-5."""
        print("\n=== –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê: –í–°–ï –®–ê–ì–ò (1-5) ===")

        if limit is None:
            limit_str = input("–õ–∏–º–∏—Ç –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ (Enter = –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π): ").strip()
            limit = int(limit_str) if limit_str else None

        print("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        print("   –®–ê–ì 1: –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –¥–µ—Ç–µ–∫—Ü–∏—è")
        print("   –®–ê–ì 2: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")
        print("   –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")
        print("   –®–ê–ì 4: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ mixed units")
        print("   –®–ê–ì 5: –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ")
        print()

        # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ —à–∞–≥–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        try:
            print("üìã –®–ê–ì 1...")
            self.handle_step1_scan_and_detect(limit)

            print("\nüìã –®–ê–ì 2...")
            self.handle_step2_classify(limit)

            print("\nüìã –®–ê–ì 3...")
            self.handle_step3_check_duplicates(limit)

            print("\nüìã –®–ê–ì 4...")
            self.handle_step4_check_mixed(limit)

            print("\nüìã –®–ê–ì 5...")
            self.handle_step5_distribute(limit)

            print("\nüéâ –ü–û–õ–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê!")

        except Exception as e:
            print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ –ø–æ–ª–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")

    def handle_view_pending_structure(self):
        """–ü—Ä–æ—Å–º–æ—Ç—Ä —Å—Ç—Ä—É–∫—Ç—É—Ä—ã pending –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –∏–∑ config."""
        print("\n=== –ü–†–û–°–ú–û–¢–† –°–¢–†–£–ö–¢–£–†–´ PENDING –î–ò–†–ï–ö–¢–û–†–ò–ô ===")

        if not PENDING_DIR.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è PENDING –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {PENDING_DIR}")
            print("üí° –í—ã–ø–æ–ª–Ω–∏—Ç–µ –®–ê–ì 5 (–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ) –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ç—Ä—É–∫—Ç—É—Ä—ã")
            return

        print(f"üìÅ –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {PENDING_DIR}")

        pending_dirs = {
            "direct": PENDING_DIRECT_DIR,
            "normalize": PENDING_NORMALIZE_DIR,
            "convert": PENDING_CONVERT_DIR,
            "extract": PENDING_EXTRACT_DIR,
            "special": PENDING_SPECIAL_DIR,
            "mixed": PENDING_MIXED_DIR
        }
        
        total_units = 0
        total_files = 0

        for category, cat_dir in pending_dirs.items():
            if cat_dir.exists():
                # –°—á–∏—Ç–∞–µ–º units (–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ UNIT_*)
                units = list(cat_dir.rglob("UNIT_*"))
                units = [u for u in units if u.is_dir()]
                
                # –°—á–∏—Ç–∞–µ–º —Ñ–∞–π–ª—ã –≤ units
                files_count = 0
                for unit_dir in units:
                    files_dir = unit_dir / "files"
                    if files_dir.exists():
                        files_count += len([f for f in files_dir.iterdir() if f.is_file()])
                
                total_units += len(units)
                total_files += files_count

                print(f"\nüìÇ {category}/:")
                print(f"   Units: {len(units)}")
                print(f"   –§–∞–π–ª–æ–≤: {files_count}")

                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã units
                if units:
                    print("   –ü—Ä–∏–º–µ—Ä—ã units:")
                    for i, unit_dir in enumerate(units[:3]):
                        unit_files_dir = unit_dir / "files"
                        unit_files_count = 0
                        if unit_files_dir.exists():
                            unit_files_count = len([f for f in unit_files_dir.iterdir() if f.is_file()])
                        print(f"     {i+1}. {unit_dir.name}: {unit_files_count} —Ñ–∞–π–ª–æ–≤")
            else:
                print(f"\nüìÇ {category}/: –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")

        print(f"\nüìä –ò—Ç–æ–≥–æ:")
        print(f"   Units –≤–æ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö: {total_units}")
        print(f"   –§–∞–π–ª–æ–≤ –≤–æ –≤—Å–µ—Ö units: {total_files}")

    def handle_category_statistics(self):
        """–î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö."""
        print("\n=== –î–ï–¢–ê–õ–¨–ù–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú ===")

        if not PENDING_DIR.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è PENDING –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {PENDING_DIR}")
            return

        pending_dirs = {
            "direct": PENDING_DIRECT_DIR,
            "normalize": PENDING_NORMALIZE_DIR,
            "convert": PENDING_CONVERT_DIR,
            "extract": PENDING_EXTRACT_DIR,
            "special": PENDING_SPECIAL_DIR,
            "mixed": PENDING_MIXED_DIR
        }
        
        stats = {}

        for category, cat_dir in pending_dirs.items():
            if cat_dir.exists():
                # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ units –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                all_files = []
                for unit_dir in cat_dir.rglob("UNIT_*"):
                    if unit_dir.is_dir():
                        files_dir = unit_dir / "files"
                        if files_dir.exists():
                            all_files.extend([f for f in files_dir.iterdir() if f.is_file()])

                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
                extensions = {}
                detected_types = {}
                total_size = 0

                for file_path in all_files:
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º
                    ext = file_path.suffix.lower() or "no_ext"
                    if ext not in extensions:
                        extensions[ext] = {"count": 0, "size": 0}
                    extensions[ext]["count"] += 1
                    file_size = file_path.stat().st_size
                    extensions[ext]["size"] += file_size
                    total_size += file_size
                    
                    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ç–∏–ø–∞–º
                    try:
                        detection = detect_file_type(file_path)
                        detected_type = detection.get("detected_type", "unknown")
                        detected_types[detected_type] = detected_types.get(detected_type, 0) + 1
                    except:
                        detected_types["unknown"] = detected_types.get("unknown", 0) + 1

                stats[category] = {
                    "file_count": len(all_files),
                    "total_size": total_size,
                    "extensions": extensions,
                    "detected_types": detected_types
                }

        # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        total_all_files = 0
        total_all_size = 0
        
        for category, stat in stats.items():
            if stat["file_count"] == 0:
                continue
                
            print(f"\nüìä –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}")
            print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {stat['file_count']}")
            print(f"   –û–±—â–∏–π —Ä–∞–∑–º–µ—Ä: {stat['total_size']:,} bytes ({stat['total_size']/1024/1024:.1f} MB)")
            
            total_all_files += stat["file_count"]
            total_all_size += stat["total_size"]

            if stat["extensions"]:
                print("   –ü–æ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º:")
                for ext, ext_stat in sorted(stat["extensions"].items()):
                    avg_size = ext_stat["size"] / ext_stat["count"] if ext_stat["count"] > 0 else 0
                    print(f"     {ext}: {ext_stat['count']} —Ñ–∞–π–ª–æ–≤, —Å—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {avg_size:,.0f} bytes")
            
            if stat["detected_types"]:
                print("   –ü–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–º —Ç–∏–ø–∞–º:")
                for dtype, count in sorted(stat["detected_types"].items()):
                    print(f"     {dtype}: {count} —Ñ–∞–π–ª–æ–≤")
        
        print(f"\nüìä –ò–¢–û–ì–û –ø–æ –≤—Å–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        print(f"   –§–∞–π–ª–æ–≤: {total_all_files}")
        print(f"   –†–∞–∑–º–µ—Ä: {total_all_size:,} bytes ({total_all_size/1024/1024:.1f} MB)")

    def handle_units_report(self):
        """–û—Ç—á–µ—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–º units –≤ PENDING –∏ READY_DOCLING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö."""
        print("\n=== –û–¢–ß–ï–¢ –ü–û –û–ë–†–ê–ë–û–¢–ê–ù–ù–´–ú UNITS ===")

        # 1. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
        print("\nüìÅ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
        pending_stats = get_unit_statistics(PENDING_DIR)
        
        total_pending_units = 0
        total_pending_files = 0
        for category, stats in pending_stats.items():
            if stats["units"] > 0 or stats["files"] > 0:
                print(f"   {category}: {stats['units']} units, {stats['files']} —Ñ–∞–π–ª–æ–≤")
                total_pending_units += stats["units"]
                total_pending_files += stats["files"]
        
        if total_pending_units == 0:
            print("   (–ø—É—Å—Ç–æ)")
        else:
            print(f"   ---")
            print(f"   –ò—Ç–æ–≥–æ PENDING: {total_pending_units} units, {total_pending_files} —Ñ–∞–π–ª–æ–≤")

        # 2. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ READY_DOCLING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        print("\nüìÅ READY_DOCLING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è:")
        ready_stats = get_ready_docling_statistics()
        
        if ready_stats["total_units"] == 0:
            print("   (–ø—É—Å—Ç–æ)")
        else:
            print(f"   –í—Å–µ–≥–æ units: {ready_stats['total_units']}")
            print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {ready_stats['total_files']}")
            
            if ready_stats["by_type"]:
                print("\n   –ü–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤:")
                for file_type, type_stats in sorted(ready_stats["by_type"].items()):
                    print(f"     {file_type}: {type_stats['units']} units, {type_stats['files']} —Ñ–∞–π–ª–æ–≤")

        # 3. –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ units –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö
        print("\nüìã –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ units –≤ PENDING:")
        
        pending_dirs = {
            "direct": PENDING_DIRECT_DIR,
            "normalize": PENDING_NORMALIZE_DIR,
            "convert": PENDING_CONVERT_DIR,
            "extract": PENDING_EXTRACT_DIR,
            "special": PENDING_SPECIAL_DIR,
            "mixed": PENDING_MIXED_DIR
        }
        
        all_units = []
        file_types = {}
        
        for category, cat_dir in pending_dirs.items():
            if not cat_dir.exists():
                continue
            
            # –ò—â–µ–º units –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (–≤–∫–ª—é—á–∞—è –ø–æ–¥–¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ç–∏–ø–æ–≤ —Ñ–∞–π–ª–æ–≤)
            for item in cat_dir.rglob("UNIT_*"):
                if item.is_dir():
                    files_dir = item / "files"
                    if files_dir.exists():
                        files = [f for f in files_dir.iterdir() if f.is_file()]
                        for file_path in files:
                            try:
                                detection = detect_file_type(file_path)
                                file_type = detection.get("detected_type", "unknown")
                                file_types[file_type] = file_types.get(file_type, 0) + 1
                            except:
                                file_types["unknown"] = file_types.get("unknown", 0) + 1
                        
                        all_units.append({
                            "unit_id": item.name,
                            "category": category,
                            "files_count": len(files),
                            "path": str(item)
                        })
        
        if file_types:
            print("\n   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤:")
            for file_type, count in sorted(file_types.items()):
                print(f"     {file_type}: {count} —Ñ–∞–π–ª–æ–≤")
        
        # –ü—Ä–∏–º–µ—Ä—ã units
        if all_units:
            print(f"\n   –ü—Ä–∏–º–µ—Ä—ã units (–≤—Å–µ–≥–æ {len(all_units)}):")
            for i, unit_info in enumerate(all_units[:5]):
                print(f"     {i+1}. {unit_info['unit_id']} [{unit_info['category']}]: {unit_info['files_count']} —Ñ–∞–π–ª–æ–≤")
        else:
            print("   –ù–µ—Ç units –≤ PENDING –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö")

    def handle_merge_dry_run(self):
        """Merge –≤ ready_docling (DRY RUN) - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç router.merge."""
        print("\n=== MERGE –í READY_DOCLING (DRY RUN) ===")

        if not PENDING_DIR.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è PENDING –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {PENDING_DIR}")
            return

        print(f"üìÅ –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {PENDING_DIR}")
        print(f"üìÅ –¶–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {READY_DOCLING_DIR}")

        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input("–õ–∏–º–∏—Ç units –¥–ª—è merge (Enter = –≤—Å–µ): ").strip()
        limit = int(limit_str) if limit_str else None

        print("\nüîç –ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–æ–≤ –¥–ª—è merge (DRY RUN)...")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º merge –≤ —Ä–µ–∂–∏–º–µ dry_run
        result = merge_to_ready_docling(dry_run=True, limit=limit)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print_merge_summary(result)
        
        print("\n‚ö†Ô∏è  DRY RUN –∑–∞–≤–µ—Ä—à–µ–Ω. –§–∞–π–ª—ã –ù–ï –±—ã–ª–∏ –ø–µ—Ä–µ–º–µ—â–µ–Ω—ã.")
        print("   –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø—É–Ω–∫—Ç 19 'Merge (–†–ï–ê–õ–¨–ù–´–ô)' –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π.")

    def handle_merge_real(self):
        """Merge –≤ ready_docling (–†–ï–ê–õ–¨–ù–´–ô) - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç router.merge."""
        print("\n=== MERGE –í READY_DOCLING (–†–ï–ê–õ–¨–ù–´–ô) ===")

        if not PENDING_DIR.exists():
            print(f"‚úó –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è PENDING –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {PENDING_DIR}")
            return

        print(f"üìÅ –ò—Å—Ö–æ–¥–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {PENDING_DIR}")
        print(f"üìÅ –¶–µ–ª–µ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {READY_DOCLING_DIR}")

        # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
        confirm = input("\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –≠—Ç–∞ –æ–ø–µ—Ä–∞—Ü–∏—è –ü–ï–†–ï–ú–ï–°–¢–ò–¢ —Ñ–∞–π–ª—ã –∏–∑ pending –≤ ready_docling.\n   –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å? (yes/no): ").strip().lower()
        if confirm not in ["yes", "y", "–¥–∞"]:
            print("‚ùå –û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
            return

        # –ó–∞–ø—Ä–æ—Å –ª–∏–º–∏—Ç–∞
        limit_str = input("–õ–∏–º–∏—Ç units –¥–ª—è merge (Enter = –≤—Å–µ): ").strip()
        limit = int(limit_str) if limit_str else None

        print("\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º merge –æ–ø–µ—Ä–∞—Ü–∏–∏...")
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ä–µ–∞–ª—å–Ω—ã–π merge
        result = merge_to_ready_docling(dry_run=False, limit=limit)
        
        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print_merge_summary(result)
        
        print(f"\nüìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤: {READY_DOCLING_DIR}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É ready_docling –ø–æ—Å–ª–µ merge
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ READY_DOCLING –ø–æ—Å–ª–µ merge:")
        ready_stats = get_ready_docling_statistics()
        print(f"   –í—Å–µ–≥–æ units: {ready_stats['total_units']}")
        print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {ready_stats['total_files']}")
        
        if ready_stats["by_type"]:
            print("   –ü–æ —Ç–∏–ø–∞–º:")
            for file_type, type_stats in sorted(ready_stats["by_type"].items()):
                print(f"     {file_type}: {type_stats['units']} units, {type_stats['files']} —Ñ–∞–π–ª–æ–≤")


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –¥–ª—è CLI."""
    cli = PreprocessingTestCLI()
    cli.run()


if __name__ == "__main__":
    main()
