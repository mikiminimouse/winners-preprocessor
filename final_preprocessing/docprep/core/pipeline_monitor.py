"""
Pipeline Monitor - —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ observability –¥–ª—è preprocessing pipeline.

–û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç:
- Real-time monitoring –æ–±—Ä–∞–±–æ—Ç–∫–∏
- Progress tracking –∏ –º–µ—Ç—Ä–∏–∫–∏
- Error reporting –∏ alerting
- Performance metrics collection
"""

import time
import logging
import json
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict, Counter

logger = logging.getLogger(__name__)


@dataclass
class PipelineMetrics:
    """–ú–µ—Ç—Ä–∏–∫–∏ pipeline –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    start_time: float = 0.0
    end_time: Optional[float] = None
    total_files: int = 0
    processed_files: int = 0
    failed_files: int = 0
    skipped_files: int = 0

    # –ü–æ —Å—Ç–∞–¥–∏—è–º
    stage_metrics: Dict[str, Dict[str, Any]] = field(default_factory=dict)

    # –ü–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
    file_type_metrics: Dict[str, int] = field(default_factory=lambda: defaultdict(int))

    # –û—à–∏–±–∫–∏
    error_counts: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    recent_errors: List[Dict[str, Any]] = field(default_factory=list)

    # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
    avg_processing_time: float = 0.0
    peak_memory_usage: int = 0
    total_processing_time: float = 0.0

    @property
    def completion_percentage(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        if self.total_files == 0:
            return 100.0
        processed = self.processed_files + self.failed_files + self.skipped_files
        return (processed / self.total_files) * 100

    @property
    def success_rate(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        total_processed = self.processed_files + self.failed_files
        if total_processed == 0:
            return 100.0
        return (self.processed_files / total_processed) * 100

    @property
    def error_rate(self) -> float:
        """–ü—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        total_processed = self.processed_files + self.failed_files
        if total_processed == 0:
            return 0.0
        return (self.failed_files / total_processed) * 100

    @property
    def elapsed_time(self) -> float:
        """–û–±—â–µ–µ –∑–∞—Ç—Ä–∞—á–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è."""
        if self.end_time:
            return self.end_time - self.start_time
        return time.time() - self.start_time

    @property
    def estimated_completion_time(self) -> Optional[float]:
        """–û—Ü–µ–Ω–∫–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è."""
        if self.completion_percentage >= 100:
            return 0.0

        elapsed = self.elapsed_time
        if elapsed == 0 or self.completion_percentage == 0:
            return None

        total_estimated = elapsed / (self.completion_percentage / 100)
        return total_estimated - elapsed

    def to_dict(self) -> Dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return {
            "start_time": self.start_time,
            "end_time": self.end_time,
            "total_files": self.total_files,
            "processed_files": self.processed_files,
            "failed_files": self.failed_files,
            "skipped_files": self.skipped_files,
            "completion_percentage": self.completion_percentage,
            "success_rate": self.success_rate,
            "error_rate": self.error_rate,
            "elapsed_time": self.elapsed_time,
            "estimated_completion_time": self.estimated_completion_time,
            "stage_metrics": dict(self.stage_metrics),
            "file_type_metrics": dict(self.file_type_metrics),
            "error_counts": dict(self.error_counts),
            "avg_processing_time": self.avg_processing_time,
            "peak_memory_usage": self.peak_memory_usage,
            "total_processing_time": self.total_processing_time,
        }


class PipelineMonitor:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä preprocessing pipeline.

    –û—Ç–≤–µ—á–∞–µ—Ç –∑–∞:
    - –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏
    - Progress tracking
    - Error monitoring –∏ alerting
    - Performance analysis
    """

    def __init__(self, log_dir: Path, enable_alerts: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–Ω–∏—Ç–æ—Ä–∞.

        Args:
            log_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–≥–æ–≤ –∏ –º–µ—Ç—Ä–∏–∫
            enable_alerts: –í–∫–ª—é—á–∏—Ç—å –∞–ª–µ—Ä—Ç—ã –ø—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö
        """
        self.log_dir = log_dir
        self.log_dir.mkdir(parents=True, exist_ok=True)

        self.enable_alerts = enable_alerts
        self.metrics = PipelineMetrics()

        # –§–∞–π–ª—ã –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.metrics_file = log_dir / "pipeline_metrics.json"
        self.alerts_file = log_dir / "alerts.log"

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self._setup_monitoring_logger()

        # –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –µ—Å–ª–∏ –µ—Å—Ç—å
        self._load_previous_metrics()

        logger.info(f"üîß PipelineMonitor initialized (log_dir={log_dir})")

    def _setup_monitoring_logger(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –ª–æ–≥–≥–µ—Ä–∞ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞."""
        self.monitor_logger = logging.getLogger("pipeline_monitor")
        self.monitor_logger.setLevel(logging.INFO)

        # –£–¥–∞–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ handlers
        for handler in self.monitor_logger.handlers[:]:
            self.monitor_logger.removeHandler(handler)

        # File handler –¥–ª—è –º–µ—Ç—Ä–∏–∫
        metrics_handler = logging.FileHandler(self.log_dir / "pipeline_monitor.log")
        metrics_handler.setFormatter(logging.Formatter(
            '%(asctime)s - %(levelname)s - %(stage)s - %(message)s'
        ))
        self.monitor_logger.addHandler(metrics_handler)

        # Console handler –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(logging.Formatter(
            'üìä %(levelname)s - %(stage)s - %(message)s'
        ))
        # –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ WARNING –∏ –≤—ã—à–µ –≤ –∫–æ–Ω—Å–æ–ª—å
        console_handler.setLevel(logging.WARNING)
        self.monitor_logger.addHandler(console_handler)

    def _load_previous_metrics(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –º–µ—Ç—Ä–∏–∫ –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã."""
        if self.metrics_file.exists():
            try:
                with open(self.metrics_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                self.metrics.start_time = data.get('start_time', time.time())
                self.metrics.total_files = data.get('total_files', 0)
                self.metrics.processed_files = data.get('processed_files', 0)
                self.metrics.failed_files = data.get('failed_files', 0)
                self.metrics.skipped_files = data.get('skipped_files', 0)
                logger.info("üìÇ Previous metrics loaded from checkpoint")
            except Exception as e:
                logger.warning(f"Could not load previous metrics: {e}")

    def start_pipeline(self, total_files: int, pipeline_id: str = "default"):
        """
        –ù–∞—á–∞–ª–æ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ pipeline.

        Args:
            total_files: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            pipeline_id: ID pipeline –¥–ª—è –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        self.metrics = PipelineMetrics()
        self.metrics.start_time = time.time()
        self.metrics.total_files = total_files

        self.monitor_logger.info(
            f"Pipeline started: {pipeline_id} with {total_files} files",
            extra={"stage": "start", "pipeline_id": pipeline_id}
        )

        logger.info(f"üöÄ Pipeline monitoring started for {total_files} files")

    def record_file_processed(self, filename: str, success: bool, processing_time: float = 0.0,
                            file_type: str = "", stage: str = "", error: Optional[str] = None):
        """
        –ó–∞–ø–∏—Å—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞.

        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞
            success: –£—Å–ø–µ—à–Ω–æ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω
            processing_time: –í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
            file_type: –¢–∏–ø —Ñ–∞–π–ª–∞ (—Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ)
            stage: –°—Ç–∞–¥–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
            error: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ –µ—Å–ª–∏ –µ—Å—Ç—å
        """
        if success:
            self.metrics.processed_files += 1
        else:
            self.metrics.failed_files += 1

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
        if file_type:
            self.metrics.file_type_metrics[file_type] += 1

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —Å—Ç–∞–¥–∏—è–º
        if stage:
            if stage not in self.metrics.stage_metrics:
                self.metrics.stage_metrics[stage] = {
                    "processed": 0, "failed": 0, "total_time": 0.0, "avg_time": 0.0
                }
            stage_stats = self.metrics.stage_metrics[stage]
            stage_stats["processed" if success else "failed"] += 1
            stage_stats["total_time"] += processing_time

            total_in_stage = stage_stats["processed"] + stage_stats["failed"]
            if total_in_stage > 0:
                stage_stats["avg_time"] = stage_stats["total_time"] / total_in_stage

        # –û–±–Ω–æ–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if processing_time > 0:
            self.metrics.total_processing_time += processing_time
            total_processed = self.metrics.processed_files + self.metrics.failed_files
            if total_processed > 0:
                self.metrics.avg_processing_time = self.metrics.total_processing_time / total_processed

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –µ—Å–ª–∏ –µ—Å—Ç—å
        if error:
            self.metrics.error_counts[error] += 1
            error_record = {
                "timestamp": datetime.now().isoformat(),
                "filename": filename,
                "stage": stage,
                "error": error,
                "file_type": file_type
            }
            self.metrics.recent_errors.append(error_record)

            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 100 –æ—à–∏–±–æ–∫
            if len(self.metrics.recent_errors) > 100:
                self.metrics.recent_errors = self.metrics.recent_errors[-100:]

            # –ê–ª–µ—Ä—Ç –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —á–∞—Å—Ç–æ—Ç–µ –æ—à–∏–±–æ–∫
            if self.enable_alerts and self.metrics.error_rate > 20.0:
                self._alert_high_error_rate()

        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        if (self.metrics.processed_files + self.metrics.failed_files) % 10 == 0:
            self._save_metrics_checkpoint()

    def record_stage_start(self, stage_name: str):
        """–ó–∞–ø–∏—Å—å –Ω–∞—á–∞–ª–∞ —Å—Ç–∞–¥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        self.monitor_logger.info(
            f"Stage started: {stage_name}",
            extra={"stage": stage_name}
        )

    def record_stage_end(self, stage_name: str, duration: float):
        """–ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å—Ç–∞–¥–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
        self.monitor_logger.info(
            ".2f",
            extra={"stage": stage_name, "duration": duration}
        )

    def end_pipeline(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ pipeline."""
        self.metrics.end_time = time.time()

        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
        self._generate_final_report()

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫
        self._save_metrics_checkpoint()

        self.monitor_logger.info(
            "Pipeline completed",
            extra={"stage": "end", "duration": self.metrics.elapsed_time}
        )

        logger.info(f"üèÅ Pipeline completed in {self.metrics.elapsed_time:.1f}s")
    def get_progress_report(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–≥—Ä–µ—Å—Å–µ.

        Returns:
            –ü–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç—á–µ—Ç –æ —Ç–µ–∫—É—â–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–∏
        """
        return {
            "timestamp": datetime.now().isoformat(),
            "metrics": self.metrics.to_dict(),
            "status": "active" if not self.metrics.end_time else "completed",
            "alerts": self._check_alerts(),
        }

    def get_performance_report(self) -> Dict[str, Any]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.

        Returns:
            –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        report = {
            "overall_performance": {
                "total_files": self.metrics.total_files,
                "completion_percentage": self.metrics.completion_percentage,
                "success_rate": self.metrics.success_rate,
                "error_rate": self.metrics.error_rate,
                "elapsed_time": self.metrics.elapsed_time,
                "avg_processing_time": self.metrics.avg_processing_time,
                "estimated_completion": self.metrics.estimated_completion_time,
            },
            "stage_performance": {},
            "file_type_distribution": dict(self.metrics.file_type_metrics),
            "top_errors": sorted(
                self.metrics.error_counts.items(),
                key=lambda x: x[1],
                reverse=True
            )[:10]
        }

        # –ê–Ω–∞–ª–∏–∑ –ø–æ —Å—Ç–∞–¥–∏—è–º
        for stage, stats in self.metrics.stage_metrics.items():
            report["stage_performance"][stage] = {
                "efficiency": (stats["processed"] / (stats["processed"] + stats["failed"])) * 100
                if (stats["processed"] + stats["failed"]) > 0 else 0,
                "avg_time": stats["avg_time"],
                "total_processed": stats["processed"],
                "total_failed": stats["failed"]
            }

        return report

    def _check_alerts(self) -> List[str]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å–ª–æ–≤–∏–π –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤."""
        alerts = []

        # –í—ã—Å–æ–∫–∏–π –ø—Ä–æ—Ü–µ–Ω—Ç –æ—à–∏–±–æ–∫
        if self.metrics.error_rate > 15.0:
            alerts.append(f"High error rate: {self.metrics.error_rate:.1f}%")

        # –î–æ–ª–≥–æ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if self.metrics.elapsed_time > 3600 and self.metrics.completion_percentage < 50:
            alerts.append(f"Slow progress: {self.metrics.completion_percentage:.1f}% in {self.metrics.elapsed_time:.0f}s")

        # –ú–Ω–æ–≥–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        if self.metrics.skipped_files > self.metrics.total_files * 0.1:
            alerts.append(f"High skip rate: {self.metrics.skipped_files}/{self.metrics.total_files} files")

        return alerts

    def _alert_high_error_rate(self):
        """–ê–ª–µ—Ä—Ç—ã –ø—Ä–∏ –≤—ã—Å–æ–∫–æ–π —á–∞—Å—Ç–æ—Ç–µ –æ—à–∏–±–æ–∫."""
        if not self.enable_alerts:
            return

        alert_msg = f"üö® HIGH ERROR RATE: {self.metrics.error_rate:.1f}% ({self.metrics.failed_files}/{self.metrics.processed_files + self.metrics.failed_files})"

        # –õ–æ–≥–∏—Ä—É–µ–º –∞–ª–µ—Ä—Ç
        with open(self.alerts_file, 'a', encoding='utf-8') as f:
            f.write(f"{datetime.now().isoformat()} - {alert_msg}\n")

        self.monitor_logger.warning(alert_msg, extra={"stage": "alert"})

    def _save_metrics_checkpoint(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –≤ checkpoint —Ñ–∞–π–ª."""
        try:
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(self.metrics.to_dict(), f, indent=2, ensure_ascii=False)
        except Exception as e:
            logger.warning(f"Could not save metrics checkpoint: {e}")

    def _generate_final_report(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞."""
        report_file = self.log_dir / "final_report.json"

        report = {
            "pipeline_summary": self.metrics.to_dict(),
            "performance_analysis": self.get_performance_report(),
            "error_analysis": {
                "total_errors": self.metrics.failed_files,
                "error_rate": self.metrics.error_rate,
                "top_errors": self.metrics.error_counts,
                "recent_errors": self.metrics.recent_errors[-10:]  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 –æ—à–∏–±–æ–∫
            },
            "stage_analysis": dict(self.metrics.stage_metrics),
            "file_type_analysis": dict(self.metrics.file_type_metrics),
            "alerts": self._check_alerts(),
            "generated_at": datetime.now().isoformat()
        }

        try:
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            logger.info(f"üìã Final report saved: {report_file}")
        except Exception as e:
            logger.error(f"Could not save final report: {e}")

    def __str__(self) -> str:
        """–°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è."""
        return (f"PipelineMonitor("
                f"files={self.metrics.processed_files}/{self.metrics.total_files} "
                f"({self.metrics.completion_percentage:.1f}%), "
                f"success={self.metrics.success_rate:.1f}%, "
                f"errors={self.metrics.failed_files})")